{
  "title": "Research on the technology of deep learning based face image recognition",
  "outline": [
    {
      "level": "H1",
      "text": "See discussions, stats, and author profiles for this publication at:",
      "page": 1
    },
    {
      "level": "H1",
      "text": "https://www.researchgate.net/publication/334470173",
      "page": 1
    },
    {
      "level": "H1",
      "text": "Research on the technology of deep learning based face image recognition",
      "page": 1
    },
    {
      "level": "H1",
      "text": "Thesis",
      "page": 1
    },
    {
      "level": "H1",
      "text": "· July 2019",
      "page": 1
    },
    {
      "level": "H1",
      "text": "DOI: 10.13140/RG.2.2.20515.40487",
      "page": 1
    },
    {
      "level": "H1",
      "text": "CITATIONS",
      "page": 1
    },
    {
      "level": "H1",
      "text": "READS",
      "page": 1
    },
    {
      "level": "H1",
      "text": "404",
      "page": 1
    },
    {
      "level": "H1",
      "text": "1 author:",
      "page": 1
    },
    {
      "level": "H1",
      "text": "Xiaofeng Liu",
      "page": 1
    },
    {
      "level": "H1",
      "text": "Harvard University",
      "page": 1
    },
    {
      "level": "H1",
      "text": "175",
      "page": 1
    },
    {
      "level": "H1",
      "text": "PUBLICATIONS",
      "page": 1
    },
    {
      "level": "H1",
      "text": "3,746",
      "page": 1
    },
    {
      "level": "H1",
      "text": "SEE PROFILE",
      "page": 1
    },
    {
      "level": "H1",
      "text": "All content following this page was uploaded by",
      "page": 1
    },
    {
      "level": "H1",
      "text": "on 15 July 2019.",
      "page": 1
    },
    {
      "level": "H1",
      "text": "The user has requested enhancement of the downloaded file.",
      "page": 1
    },
    {
      "level": "H1",
      "text": "博士学位论文",
      "page": 2
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 2
    },
    {
      "level": "H1",
      "text": "作者姓名：",
      "page": 2
    },
    {
      "level": "H1",
      "text": "刘小沣",
      "page": 2
    },
    {
      "level": "H1",
      "text": "指导教师",
      "page": 2
    },
    {
      "level": "H1",
      "text": "贾平研究员",
      "page": 2
    },
    {
      "level": "H1",
      "text": "香港理工大学",
      "page": 2
    },
    {
      "level": "H1",
      "text": "中科院长春光机所",
      "page": 2
    },
    {
      "level": "H1",
      "text": "学位类别",
      "page": 2
    },
    {
      "level": "H1",
      "text": "工学博士",
      "page": 2
    },
    {
      "level": "H1",
      "text": "学科专业",
      "page": 2
    },
    {
      "level": "H1",
      "text": "机械电子工程",
      "page": 2
    },
    {
      "level": "H1",
      "text": "培养单位",
      "page": 2
    },
    {
      "level": "H1",
      "text": "中国科学院长春光学精密机械与物理研究所",
      "page": 2
    },
    {
      "level": "H1",
      "text": "2019",
      "page": 2
    },
    {
      "level": "H1",
      "text": "RESEARCH ON THE TECHNOLOGY OF DEEP",
      "page": 4
    },
    {
      "level": "H1",
      "text": "LEARNING BASED FACE IMAGE   RECOGNITION",
      "page": 4
    },
    {
      "level": "H1",
      "text": "A dissertation submitted to",
      "page": 4
    },
    {
      "level": "H1",
      "text": "University of Chinese Academy of Sciences",
      "page": 4
    },
    {
      "level": "H1",
      "text": "in partial fulfillment of the requirement",
      "page": 4
    },
    {
      "level": "H1",
      "text": "for the degree of",
      "page": 4
    },
    {
      "level": "H1",
      "text": "Doctor of Philosophy",
      "page": 4
    },
    {
      "level": "H1",
      "text": "in Mechatronic Engineering",
      "page": 4
    },
    {
      "level": "H1",
      "text": "Xiaofeng Liu",
      "page": 4
    },
    {
      "level": "H1",
      "text": "Supervisor: Professor Jane (Jia) You",
      "page": 4
    },
    {
      "level": "H1",
      "text": "Professor Ping Jia",
      "page": 4
    },
    {
      "level": "H1",
      "text": "Professor B. V. K. Vijaya Kumar",
      "page": 4
    },
    {
      "level": "H1",
      "text": "Changchun Institute of Optics, Fine Mechanics and Physics,",
      "page": 4
    },
    {
      "level": "H1",
      "text": "Chinese Academy of Sciences",
      "page": 4
    },
    {
      "level": "H1",
      "text": "June 2019",
      "page": 4
    },
    {
      "level": "H1",
      "text": "中国科学院大学",
      "page": 6
    },
    {
      "level": "H1",
      "text": "研究生学位论文原创性声明",
      "page": 6
    },
    {
      "level": "H1",
      "text": "本人郑重声明：所呈交的学位论文是本人在导师的指导下独立进行研究工作",
      "page": 6
    },
    {
      "level": "H1",
      "text": "所取得的成果。尽我所知，除文中已经注明引用的内容外，本论文不包含任何其",
      "page": 6
    },
    {
      "level": "H1",
      "text": "他个人或集体已经发表或撰写过的研究成果。对论文所涉及的研究工作做出贡献",
      "page": 6
    },
    {
      "level": "H1",
      "text": "的其他个人和集体，均已在文中以明确方式标明或致谢。",
      "page": 6
    },
    {
      "level": "H1",
      "text": "作者签名：",
      "page": 6
    },
    {
      "level": "H1",
      "text": "学位论文授权使用声明",
      "page": 6
    },
    {
      "level": "H1",
      "text": "本人完全了解并同意遵守中国科学院有关保存和使用学位论文的规定，即中",
      "page": 6
    },
    {
      "level": "H1",
      "text": "国科学院有权保留送交学位论文的副本，允许该论文被查阅，可以按照学术研究",
      "page": 6
    },
    {
      "level": "H1",
      "text": "公开原则和保护知识产权的原则公布该论文的全部或部分内容，可以采用影印、",
      "page": 6
    },
    {
      "level": "H1",
      "text": "缩印或其他复制手段保存、汇编本学位论文。",
      "page": 6
    },
    {
      "level": "H1",
      "text": "涉密及延迟公开的学位论文在解密或延迟期后适用本声明。",
      "page": 6
    },
    {
      "level": "H1",
      "text": "导师签名：",
      "page": 6
    },
    {
      "level": "H1",
      "text": "随着人工智能（",
      "page": 8
    },
    {
      "level": "H1",
      "text": "Artificial intelligence",
      "page": 8
    },
    {
      "level": "H1",
      "text": "）和计算机视觉（",
      "page": 8
    },
    {
      "level": "H1",
      "text": "Computer vision",
      "page": 8
    },
    {
      "level": "H1",
      "text": "）等技",
      "page": 8
    },
    {
      "level": "H1",
      "text": "术的飞速发展，让机器或计算设备拥有感知图像内容的能力日益成为当今热点研",
      "page": 8
    },
    {
      "level": "H1",
      "text": "究课题。其中人脸图像因其丰富的信息和广阔的应用前景更是一个活跃的分支。",
      "page": 8
    },
    {
      "level": "H1",
      "text": "人脸图像识别只要是指通过对人的面部图像、视频或图片和视频的集合进行分析，",
      "page": 8
    },
    {
      "level": "H1",
      "text": "自动的推断其身份、表情以及年龄、性别等属性。",
      "page": 8
    },
    {
      "level": "H1",
      "text": "人脸图片通常糅合了包括身份、表情、年龄、性别、光照、角度等各种信",
      "page": 8
    },
    {
      "level": "H1",
      "text": "息，如何提取与识别任务相关的特征（例如身份信息对应人脸识别，表情信息对",
      "page": 8
    },
    {
      "level": "H1",
      "text": "应表情识别）是当前基于深度学习的模式识别算法的主要研究方向。本文进一步",
      "page": 8
    },
    {
      "level": "H1",
      "text": "的探究了如何可控的引入对某些不相关属性的不变性先验知识，使得提取出的",
      "page": 8
    },
    {
      "level": "H1",
      "text": "针对主识别任务的特征有更好的可辨别性和泛化能力。例如表情识别的特征应",
      "page": 8
    },
    {
      "level": "H1",
      "text": "该对身份变化鲁棒，而身份识别的特征应该对表情、光照、化妆等变化鲁棒。",
      "page": 8
    },
    {
      "level": "H1",
      "text": "针对这一目标以及人脸表情识别和人脸识别这两个重要应用，本文提出了自适",
      "page": 8
    },
    {
      "level": "H1",
      "text": "应深度度量学习以及对抗训练两种方法用以解构表情与身份信息或身份与某些",
      "page": 8
    },
    {
      "level": "H1",
      "text": "属性信息。",
      "page": 8
    },
    {
      "level": "H1",
      "text": "随着数字媒体内容的爆炸性增长，使用图片和视频的集合进行身份识别更符",
      "page": 8
    },
    {
      "level": "H1",
      "text": "合实际的生物特征识别应用。例如查询图片或视频帧可以从多个摄像头所拍摄到",
      "page": 8
    },
    {
      "level": "H1",
      "text": "的某人所获得，而候选图片或视频帧也可由该人历史上各种证件照和其他场合所",
      "page": 8
    },
    {
      "level": "H1",
      "text": "拍摄照片组成。相较于传统的图片与图片，或视频与视频的相似度对比，该设定",
      "page": 8
    },
    {
      "level": "H1",
      "text": "可以提供更丰富的信息，但也给信息融合带来了挑战。本文提出了一种基于增强",
      "page": 8
    },
    {
      "level": "H1",
      "text": "学习算法的图片集人脸识别方案。",
      "page": 8
    },
    {
      "level": "H1",
      "text": "本文的主要贡献可概括为：",
      "page": 8
    },
    {
      "level": "H1",
      "text": "人类的面部表情是传递情感信息的重要途径。基于自适应度量学习的去",
      "page": 8
    },
    {
      "level": "H1",
      "text": "除身份信息干扰的人脸（图片",
      "page": 8
    },
    {
      "level": "H1",
      "text": "视频）表情识别特征提取。第二章提出了一种新的",
      "page": 8
    },
    {
      "level": "H1",
      "text": "深度尺度学习算法",
      "page": 8
    },
    {
      "level": "H1",
      "text": "N+M",
      "page": 8
    },
    {
      "level": "H1",
      "text": "元组簇损失，解决了该领域长期存在的锚点选择问题并",
      "page": 8
    },
    {
      "level": "H1",
      "text": "大大减少了运算量。其阈值参数可自适应学习。通过合理的设置负样本为同一个",
      "page": 8
    },
    {
      "level": "H1",
      "text": "体的其他表情图像能有效地实现难样本挖掘，并明确的消除身份信息的干扰。在",
      "page": 9
    },
    {
      "level": "H1",
      "text": "CK+",
      "page": 9
    },
    {
      "level": "H1",
      "text": "MMI",
      "page": 9
    },
    {
      "level": "H1",
      "text": "SFEW",
      "page": 9
    },
    {
      "level": "H1",
      "text": "数据集上的实验结果表明其可以有效的利用人脸表情数据",
      "page": 9
    },
    {
      "level": "H1",
      "text": "库中常有的身份标记从而有效地提高表情识别任务的精度。",
      "page": 9
    },
    {
      "level": "H1",
      "text": "考虑到来自同一个个体的中性表情图片是较好的参考图像，但不是所有",
      "page": 9
    },
    {
      "level": "H1",
      "text": "数据集中都普遍存在，第三章提出了一种难样本生成方法并配以径向度量学习。",
      "page": 9
    },
    {
      "level": "H1",
      "text": "通过将查询图片与基于其生成的同身份中性脸参考图片进行比较而去除身份信",
      "page": 9
    },
    {
      "level": "H1",
      "text": "息的影响。其难样本生成是基于像素级对抗生成网络以去除表情、姿态等属性干",
      "page": 9
    },
    {
      "level": "H1",
      "text": "扰的身份不变归一化脸生成。通过在",
      "page": 9
    },
    {
      "level": "H1",
      "text": "数据集上的实验表明",
      "page": 9
    },
    {
      "level": "H1",
      "text": "难样本生成可以利用远大于表情识别库的人脸身份识别库中的正面中性图片以",
      "page": 9
    },
    {
      "level": "H1",
      "text": "形成参考图像的先验知识，其不仅能提升识别效果，还能相较于传统的度量学习",
      "page": 9
    },
    {
      "level": "H1",
      "text": "大大缩短训练时间。",
      "page": 9
    },
    {
      "level": "H1",
      "text": "第四章系统性的总结了人脸图片中各因素之间的关系，并定义到更广泛",
      "page": 9
    },
    {
      "level": "H1",
      "text": "的多标签数据上。提出了一种基于特征级对抗训练的解构网络，将输入图片分解",
      "page": 9
    },
    {
      "level": "H1",
      "text": "为对主识别任务（例如身份识别）具有辨识力的特征，期望对其鲁棒的有标签语",
      "page": 9
    },
    {
      "level": "H1",
      "text": "义属性（如可表情、光照、化妆等属性），以及期望对其鲁棒的无标签或难以量",
      "page": 9
    },
    {
      "level": "H1",
      "text": "化的因素（如背景等）。三者互补而又互相边际独立。",
      "page": 9
    },
    {
      "level": "H1",
      "text": "第五章提出了一种基于深度增强学习的算法用于探索集中各图片的重要",
      "page": 9
    },
    {
      "level": "H1",
      "text": "性以及互补性。通过在",
      "page": 9
    },
    {
      "level": "H1",
      "text": "IJB-A/B/C",
      "page": 9
    },
    {
      "level": "H1",
      "text": "系列基于集的人脸识别数据集，基于视频的",
      "page": 9
    },
    {
      "level": "H1",
      "text": "Celebrity-1000",
      "page": 9
    },
    {
      "level": "H1",
      "text": "数据集，以及行人重试别任务上的实验证实了该算法的有效性。",
      "page": 9
    },
    {
      "level": "H1",
      "text": "关键词：人脸表情识别，人脸识别，度量学习，增强学习，对抗生成网络",
      "page": 9
    },
    {
      "level": "H1",
      "text": "III",
      "page": 10
    },
    {
      "level": "H1",
      "text": "Abstract",
      "page": 10
    },
    {
      "level": "H1",
      "text": "With the development of artificial intelligence and computer vision technology,",
      "page": 10
    },
    {
      "level": "H1",
      "text": "making a machine to understand the image has become an important research topic.",
      "page": 10
    },
    {
      "level": "H1",
      "text": "Among them, face image analysis is an active branch because of its rich information",
      "page": 10
    },
    {
      "level": "H1",
      "text": "and broad application prospects. Face image recognition refers to automatically",
      "page": 10
    },
    {
      "level": "H1",
      "text": "inferring the identity, expression, and age, gender etc., by analyzing a person's facial",
      "page": 10
    },
    {
      "level": "H1",
      "text": "image, video, or a collection of pictures and videos.",
      "page": 10
    },
    {
      "level": "H1",
      "text": "Face images usually combine various factors including identity, expression, age,",
      "page": 10
    },
    {
      "level": "H1",
      "text": "gender, illumination, angle, etc. How to extract a feature representation related to the",
      "page": 10
    },
    {
      "level": "H1",
      "text": "recognition task (for example, identity information corresponding to face recognition,",
      "page": 10
    },
    {
      "level": "H1",
      "text": "expression information corresponding to expression recognition) is currently the main",
      "page": 10
    },
    {
      "level": "H1",
      "text": "research direction of deep learning pattern recognition algorithms. This dissertation",
      "page": 10
    },
    {
      "level": "H1",
      "text": "further explores how to introduce the invariant prior knowledge of certain unrelated",
      "page": 10
    },
    {
      "level": "H1",
      "text": "attributes, so that the extracted features for the main recognition task is more",
      "page": 10
    },
    {
      "level": "H1",
      "text": "discriminative and has generalization ability. For example, features of expression",
      "page": 10
    },
    {
      "level": "H1",
      "text": "recognition should be robust to identity changes, while features of identity recognition",
      "page": 10
    },
    {
      "level": "H1",
      "text": "should be robust to changes of expression, lighting, makeup etc. Target on this goal and",
      "page": 10
    },
    {
      "level": "H1",
      "text": "based on two important face related applications, i.e., facial expression recognition and",
      "page": 10
    },
    {
      "level": "H1",
      "text": "face identity recognition, this paper proposes an adaptive deep metric learning and a",
      "page": 10
    },
    {
      "level": "H1",
      "text": "feature-level adversarial training method to disentangle the expression and identity",
      "page": 10
    },
    {
      "level": "H1",
      "text": "information, or identity and some attributes information. Besides, a deep reinforcement",
      "page": 10
    },
    {
      "level": "H1",
      "text": "learning algorithm is introduced for set-based face recognition.",
      "page": 10
    },
    {
      "level": "H1",
      "text": "The main contributions of this dissertation can be summarized as:",
      "page": 10
    },
    {
      "level": "H1",
      "text": "emotional state. Adaptive metric learning is introduced to remove identity information",
      "page": 10
    },
    {
      "level": "H1",
      "text": "to extract a more pure facial (picture/video) expression feature. The second chapter",
      "page": 10
    },
    {
      "level": "H1",
      "text": "proposes a novel deep metric learning algorithm, i.e., (",
      "page": 10
    },
    {
      "level": "H1",
      "text": "N+M",
      "page": 10
    },
    {
      "level": "H1",
      "text": ") tuple cluster loss, which",
      "page": 10
    },
    {
      "level": "H3",
      "text": "1. Facial expression is one of the most expressive way for humans to convey their",
      "page": 10
    },
    {
      "level": "H1",
      "text": "not only alleviates the difficulty of threshold validation and anchor selection, but also",
      "page": 11
    },
    {
      "level": "H1",
      "text": "reduces the computational burden of deep metric learning. Its threshold parameters can",
      "page": 11
    },
    {
      "level": "H1",
      "text": "be learned adaptively. By properly selecting the negative samples as other expression",
      "page": 11
    },
    {
      "level": "H1",
      "text": "images of the same person, it can clearly eliminate the identity information, and the",
      "page": 11
    },
    {
      "level": "H1",
      "text": "mining of the difficult sample can be efficiently. Experiments on the CK+, MMI and",
      "page": 11
    },
    {
      "level": "H1",
      "text": "SFEW datasets show that the algorithm can effectively improve the recognition",
      "page": 11
    },
    {
      "level": "H1",
      "text": "accuracy by using the identity tags usually exist in the expression recognition dataset.",
      "page": 11
    },
    {
      "level": "H1",
      "text": "important reference sample, but may not exist in several datasets. Chapter 3 proposes a",
      "page": 11
    },
    {
      "level": "H1",
      "text": "hard negative generation scheme with radial metric learning. The identity information",
      "page": 11
    },
    {
      "level": "H1",
      "text": "can be removed by comparing the query picture with the same identity neutral face",
      "page": 11
    },
    {
      "level": "H1",
      "text": "reference image generated based on it. The hard negative generation is based on the",
      "page": 11
    },
    {
      "level": "H1",
      "text": "pixel-level adversarial-generation network to remove the attributes such as expression",
      "page": 11
    },
    {
      "level": "H1",
      "text": "and pose to inference the identity-invariant normalized face. Experiments on the CK+,",
      "page": 11
    },
    {
      "level": "H1",
      "text": "MMI and SFEW datasets evidence that hard negative generation can take advantage of",
      "page": 11
    },
    {
      "level": "H1",
      "text": "frontal neutral face images in the face recognition dataset which much larger than the",
      "page": 11
    },
    {
      "level": "H1",
      "text": "expression recognition datasets to incorporate the priori knowledge of the reference",
      "page": 11
    },
    {
      "level": "H1",
      "text": "image. It not only enhances the recognition effect, but also largely reduces the training",
      "page": 11
    },
    {
      "level": "H1",
      "text": "time compared to traditional metric learning.",
      "page": 11
    },
    {
      "level": "H1",
      "text": "factors in the face image and defines them on a more general case of multi-label data.",
      "page": 11
    },
    {
      "level": "H1",
      "text": "A disentangle network based on feature-level adversarial training is proposed. The input",
      "page": 11
    },
    {
      "level": "H1",
      "text": "picture is decomposed into three features that are discriminative feature for the main",
      "page": 11
    },
    {
      "level": "H1",
      "text": "recognition task (such as identification), which is expected to be robust to the semantic",
      "page": 11
    },
    {
      "level": "H1",
      "text": "attributes (such as expressive, illumination, etc.), and the unnamed or unquantifiable",
      "page": 11
    },
    {
      "level": "H1",
      "text": "factors (such as backgrounds) that are expected to be removed. The three complement",
      "page": 11
    },
    {
      "level": "H1",
      "text": "each other and are independent of each other.",
      "page": 11
    },
    {
      "level": "H1",
      "text": "pictures and videos for verification/identification is more align with the actual biometric",
      "page": 11
    },
    {
      "level": "H3",
      "text": "2. Considering that the neutral expression of the same person could be the most",
      "page": 11
    },
    {
      "level": "H3",
      "text": "3. Chapter 4 systematically summarizes the relationships between the various",
      "page": 11
    },
    {
      "level": "H3",
      "text": "4. With the explosive growth of digital media content, the use of a collection of",
      "page": 11
    },
    {
      "level": "H1",
      "text": "applications. For example, several query pictures or video frames of a person can be",
      "page": 12
    },
    {
      "level": "H1",
      "text": "obtained from multiple cameras, and the gallary pictures or video frames can also be",
      "page": 12
    },
    {
      "level": "H1",
      "text": "composed of various history ID photos and taken from the other places or published in",
      "page": 12
    },
    {
      "level": "H1",
      "text": "social media. Compared with comparing the similarity of a single image or video, this",
      "page": 12
    },
    {
      "level": "H1",
      "text": "setting can provide more information, but it also brings challenges to information fusion.",
      "page": 12
    },
    {
      "level": "H1",
      "text": "The fifth chapter proposes an algorithm based on deep reinforcement learning to",
      "page": 12
    },
    {
      "level": "H1",
      "text": "explore the importance and complementarity among images. The effectiveness of the",
      "page": 12
    },
    {
      "level": "H1",
      "text": "algorithm is verified on the IJB-A/B/C series set-based face recognition data set, the",
      "page": 12
    },
    {
      "level": "H1",
      "text": "video-based Celebrity-1000 data set, and the pedestrian re-identification task.",
      "page": 12
    },
    {
      "level": "H1",
      "text": "Key Words:",
      "page": 12
    },
    {
      "level": "H1",
      "text": "Facial expression recognition, Face recognition, Metric learning,",
      "page": 12
    },
    {
      "level": "H1",
      "text": "Reinforcement learning, Adversarial generation network",
      "page": 12
    },
    {
      "level": "H1",
      "text": "……………………………………………………………………..………I",
      "page": 14
    },
    {
      "level": "H1",
      "text": "Abstract",
      "page": 14
    },
    {
      "level": "H1",
      "text": "…………………………………………………………….…………..III",
      "page": 14
    },
    {
      "level": "H1",
      "text": "…………………………………………………………….……1",
      "page": 14
    },
    {
      "level": "H1",
      "text": "1.1",
      "page": 14
    },
    {
      "level": "H1",
      "text": "研究背景及意义",
      "page": 14
    },
    {
      "level": "H1",
      "text": "…………………………………………………….….…1",
      "page": 14
    },
    {
      "level": "H1",
      "text": "1.2",
      "page": 14
    },
    {
      "level": "H1",
      "text": "研究现状",
      "page": 14
    },
    {
      "level": "H1",
      "text": "…………………………………...……………………….……..3",
      "page": 14
    },
    {
      "level": "H1",
      "text": "1.2.1",
      "page": 14
    },
    {
      "level": "H1",
      "text": "人脸识别技术的发展",
      "page": 14
    },
    {
      "level": "H1",
      "text": "…………………………………………...……3",
      "page": 14
    },
    {
      "level": "H1",
      "text": "1.2.2",
      "page": 14
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸身份识别",
      "page": 14
    },
    {
      "level": "H1",
      "text": "………………………………...……6",
      "page": 14
    },
    {
      "level": "H1",
      "text": "1.2.3",
      "page": 14
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸表情识别",
      "page": 14
    },
    {
      "level": "H1",
      "text": "………………………………...……8",
      "page": 14
    },
    {
      "level": "H1",
      "text": "1.3",
      "page": 14
    },
    {
      "level": "H1",
      "text": "论文主要内容与篇章结构",
      "page": 14
    },
    {
      "level": "H1",
      "text": "………………………………………………11",
      "page": 14
    },
    {
      "level": "H1",
      "text": "基于深度度量学习的身份感知人脸表情识别",
      "page": 14
    },
    {
      "level": "H1",
      "text": "……......……14",
      "page": 14
    },
    {
      "level": "H1",
      "text": "2.1",
      "page": 14
    },
    {
      "level": "H1",
      "text": "相关工作",
      "page": 14
    },
    {
      "level": "H1",
      "text": "…………………………………………………………………16",
      "page": 14
    },
    {
      "level": "H1",
      "text": "2.1.1",
      "page": 14
    },
    {
      "level": "H1",
      "text": "人脸表情识别",
      "page": 14
    },
    {
      "level": "H1",
      "text": "……….………………………………………………16",
      "page": 14
    },
    {
      "level": "H1",
      "text": "2.1.2",
      "page": 14
    },
    {
      "level": "H1",
      "text": "深度卷及网络",
      "page": 14
    },
    {
      "level": "H1",
      "text": "……….………………………………………………17",
      "page": 14
    },
    {
      "level": "H1",
      "text": "2.1.3",
      "page": 14
    },
    {
      "level": "H1",
      "text": "度量学习",
      "page": 14
    },
    {
      "level": "H1",
      "text": "…………………….………………………………………17",
      "page": 14
    },
    {
      "level": "H1",
      "text": "2.2",
      "page": 14
    },
    {
      "level": "H1",
      "text": "基于深度度量学习的人脸表情识别算法",
      "page": 14
    },
    {
      "level": "H1",
      "text": "………………………………20",
      "page": 14
    },
    {
      "level": "H1",
      "text": "2.2.1",
      "page": 14
    },
    {
      "level": "H1",
      "text": "N+M",
      "page": 14
    },
    {
      "level": "H1",
      "text": "元组簇损失的深度度量学习",
      "page": 14
    },
    {
      "level": "H1",
      "text": "……………………..……20",
      "page": 14
    },
    {
      "level": "H1",
      "text": "2.2.2",
      "page": 14
    },
    {
      "level": "H1",
      "text": "自适应深度度量学习",
      "page": 14
    },
    {
      "level": "H1",
      "text": "……….………………………………………22",
      "page": 14
    },
    {
      "level": "H1",
      "text": "2.2.3",
      "page": 14
    },
    {
      "level": "H1",
      "text": "双分支联合优化网络",
      "page": 14
    },
    {
      "level": "H1",
      "text": "………………….……………………………24",
      "page": 14
    },
    {
      "level": "H1",
      "text": "2.3",
      "page": 14
    },
    {
      "level": "H1",
      "text": "………………………………………………………………………25",
      "page": 14
    },
    {
      "level": "H1",
      "text": "2.3.1",
      "page": 14
    },
    {
      "level": "H1",
      "text": "预处理及训练流程",
      "page": 14
    },
    {
      "level": "H1",
      "text": "………….………………………………………25",
      "page": 14
    },
    {
      "level": "H1",
      "text": "2.3.2",
      "page": 14
    },
    {
      "level": "H1",
      "text": "实验结果",
      "page": 14
    },
    {
      "level": "H1",
      "text": "……………………………….……………………………26",
      "page": 14
    },
    {
      "level": "H1",
      "text": "2.4",
      "page": 14
    },
    {
      "level": "H1",
      "text": "本章小结",
      "page": 14
    },
    {
      "level": "H1",
      "text": "…………………………………………………………………30",
      "page": 14
    },
    {
      "level": "H1",
      "text": "基于难样本生成的人脸表情识别",
      "page": 14
    },
    {
      "level": "H1",
      "text": "…….............................……31",
      "page": 14
    },
    {
      "level": "H1",
      "text": "3.1",
      "page": 14
    },
    {
      "level": "H1",
      "text": "…………………………………………………………………33",
      "page": 14
    },
    {
      "level": "H1",
      "text": "3.2",
      "page": 14
    },
    {
      "level": "H1",
      "text": "难样本生成",
      "page": 14
    },
    {
      "level": "H1",
      "text": "………………………………………………………………34",
      "page": 14
    },
    {
      "level": "H1",
      "text": "VII",
      "page": 15
    },
    {
      "level": "H1",
      "text": "3.2.1",
      "page": 15
    },
    {
      "level": "H1",
      "text": "特征空间语义感知损失",
      "page": 15
    },
    {
      "level": "H1",
      "text": "……….……………………………………35",
      "page": 15
    },
    {
      "level": "H1",
      "text": "3.2.2",
      "page": 15
    },
    {
      "level": "H1",
      "text": "对称性损失",
      "page": 15
    },
    {
      "level": "H1",
      "text": "………….………………………………………………36",
      "page": 15
    },
    {
      "level": "H1",
      "text": "3.2.3",
      "page": 15
    },
    {
      "level": "H1",
      "text": "对抗性损失",
      "page": 15
    },
    {
      "level": "H1",
      "text": "………………….………………………………………37",
      "page": 15
    },
    {
      "level": "H1",
      "text": "3.2.4",
      "page": 15
    },
    {
      "level": "H1",
      "text": "身份保持损失",
      "page": 15
    },
    {
      "level": "H1",
      "text": "……….………………………………………………38",
      "page": 15
    },
    {
      "level": "H1",
      "text": "3.2.5",
      "page": 15
    },
    {
      "level": "H1",
      "text": "像素级相似",
      "page": 15
    },
    {
      "level": "H1",
      "text": "………………….………………………………………39",
      "page": 15
    },
    {
      "level": "H1",
      "text": "3.2.6",
      "page": 15
    },
    {
      "level": "H1",
      "text": "优化目标融合",
      "page": 15
    },
    {
      "level": "H1",
      "text": "……………….………………………………………39",
      "page": 15
    },
    {
      "level": "H1",
      "text": "3.3",
      "page": 15
    },
    {
      "level": "H1",
      "text": "径向度量学习",
      "page": 15
    },
    {
      "level": "H1",
      "text": "……………………………………………………………40",
      "page": 15
    },
    {
      "level": "H1",
      "text": "3.4",
      "page": 15
    },
    {
      "level": "H1",
      "text": "………………………………………………………………………44",
      "page": 15
    },
    {
      "level": "H1",
      "text": "3.4.1",
      "page": 15
    },
    {
      "level": "H1",
      "text": "数据集",
      "page": 15
    },
    {
      "level": "H1",
      "text": "…………………………………...……………………..……44",
      "page": 15
    },
    {
      "level": "H1",
      "text": "3.4.2",
      "page": 15
    },
    {
      "level": "H1",
      "text": "预处理及训练流程",
      "page": 15
    },
    {
      "level": "H1",
      "text": "………….………………………………………45",
      "page": 15
    },
    {
      "level": "H1",
      "text": "3.4.3",
      "page": 15
    },
    {
      "level": "H1",
      "text": "辅助网络的烧蚀研究",
      "page": 15
    },
    {
      "level": "H1",
      "text": "………………….……………………………47",
      "page": 15
    },
    {
      "level": "H1",
      "text": "3.4.4",
      "page": 15
    },
    {
      "level": "H1",
      "text": "实验结果",
      "page": 15
    },
    {
      "level": "H1",
      "text": "……………………………….……………………………48",
      "page": 15
    },
    {
      "level": "H1",
      "text": "3.5",
      "page": 15
    },
    {
      "level": "H1",
      "text": "本章小结",
      "page": 15
    },
    {
      "level": "H1",
      "text": "…………………………………………………………………53",
      "page": 15
    },
    {
      "level": "H1",
      "text": "基于对抗训练的人脸身份与属性特征剥离及识别",
      "page": 15
    },
    {
      "level": "H1",
      "text": "….……54",
      "page": 15
    },
    {
      "level": "H1",
      "text": "4.1",
      "page": 15
    },
    {
      "level": "H1",
      "text": "相关工作",
      "page": 15
    },
    {
      "level": "H1",
      "text": "…………………………………………………………………56",
      "page": 15
    },
    {
      "level": "H1",
      "text": "4.2",
      "page": 15
    },
    {
      "level": "H1",
      "text": "特征级弗兰肯斯坦框架",
      "page": 15
    },
    {
      "level": "H1",
      "text": "…………………………………………………57",
      "page": 15
    },
    {
      "level": "H1",
      "text": "4.2.1",
      "page": 15
    },
    {
      "level": "H1",
      "text": "问题定义",
      "page": 15
    },
    {
      "level": "H1",
      "text": "………………………………………………...……..……57",
      "page": 15
    },
    {
      "level": "H1",
      "text": "4.2.2",
      "page": 15
    },
    {
      "level": "H1",
      "text": "框架结构",
      "page": 15
    },
    {
      "level": "H1",
      "text": "…………………….………………………………………58",
      "page": 15
    },
    {
      "level": "H1",
      "text": "4.2.3",
      "page": 15
    },
    {
      "level": "H1",
      "text": "独立性分析",
      "page": 15
    },
    {
      "level": "H1",
      "text": "…………………………….……………………………61",
      "page": 15
    },
    {
      "level": "H1",
      "text": "4.2.4",
      "page": 15
    },
    {
      "level": "H1",
      "text": "平衡条件",
      "page": 15
    },
    {
      "level": "H1",
      "text": "…………………………….………………………………61",
      "page": 15
    },
    {
      "level": "H1",
      "text": "4.3",
      "page": 15
    },
    {
      "level": "H1",
      "text": "………………………………………………………………………63",
      "page": 15
    },
    {
      "level": "H1",
      "text": "4.3.1",
      "page": 15
    },
    {
      "level": "H1",
      "text": "对光照鲁棒的人脸识别",
      "page": 15
    },
    {
      "level": "H1",
      "text": "…………………………...…………..……63",
      "page": 15
    },
    {
      "level": "H1",
      "text": "4.3.2",
      "page": 15
    },
    {
      "level": "H1",
      "text": "化妆人脸识别",
      "page": 15
    },
    {
      "level": "H1",
      "text": "………….……………………………………………64",
      "page": 15
    },
    {
      "level": "H1",
      "text": "4.3.3",
      "page": 15
    },
    {
      "level": "H1",
      "text": "人脸身份与属性识别",
      "page": 15
    },
    {
      "level": "H1",
      "text": "………………….……………………………66",
      "page": 15
    },
    {
      "level": "H1",
      "text": "4.3.4",
      "page": 15
    },
    {
      "level": "H1",
      "text": "伪装人脸识别",
      "page": 15
    },
    {
      "level": "H1",
      "text": "………………………….……………………………66",
      "page": 15
    },
    {
      "level": "H1",
      "text": "4.4",
      "page": 15
    },
    {
      "level": "H1",
      "text": "…………………………………………………………………67",
      "page": 15
    },
    {
      "level": "H1",
      "text": "基于增强学习的人脸图片集身份识别",
      "page": 15
    },
    {
      "level": "H1",
      "text": ".…….……………..…68",
      "page": 15
    },
    {
      "level": "H1",
      "text": "5.1",
      "page": 15
    },
    {
      "level": "H1",
      "text": "…………………………………………………………………71",
      "page": 15
    },
    {
      "level": "H1",
      "text": "5.2",
      "page": 15
    },
    {
      "level": "H1",
      "text": "集内依赖性控制",
      "page": 15
    },
    {
      "level": "H1",
      "text": "…………………………………………………………73",
      "page": 15
    },
    {
      "level": "H1",
      "text": "5.2.1",
      "page": 15
    },
    {
      "level": "H1",
      "text": "基于演员",
      "page": 15
    },
    {
      "level": "H1",
      "text": "评论家增强学习的图片集人脸识别",
      "page": 15
    },
    {
      "level": "H1",
      "text": "………….…..……74",
      "page": 15
    },
    {
      "level": "H1",
      "text": "5.2.2",
      "page": 16
    },
    {
      "level": "H1",
      "text": "具有经验重播的异策略演员",
      "page": 16
    },
    {
      "level": "H1",
      "text": "评论家增强学习",
      "page": 16
    },
    {
      "level": "H1",
      "text": "……..……..………76",
      "page": 16
    },
    {
      "level": "H1",
      "text": "5.2.3",
      "page": 16
    },
    {
      "level": "H1",
      "text": "与时序注意力模型相结合",
      "page": 16
    },
    {
      "level": "H1",
      "text": "…………………………….……………77",
      "page": 16
    },
    {
      "level": "H1",
      "text": "5.3",
      "page": 16
    },
    {
      "level": "H1",
      "text": "姿态引导的集合间依赖模型",
      "page": 16
    },
    {
      "level": "H1",
      "text": "……………………………………………78",
      "page": 16
    },
    {
      "level": "H1",
      "text": "5.3.1",
      "page": 16
    },
    {
      "level": "H1",
      "text": "无参数的姿态引导表示",
      "page": 16
    },
    {
      "level": "H1",
      "text": "…………………………...…………..……79",
      "page": 16
    },
    {
      "level": "H1",
      "text": "5.3.2",
      "page": 16
    },
    {
      "level": "H1",
      "text": "基于尺度学习的姿态引导表示",
      "page": 16
    },
    {
      "level": "H1",
      "text": "………….…………………………79",
      "page": 16
    },
    {
      "level": "H1",
      "text": "5.4",
      "page": 16
    },
    {
      "level": "H1",
      "text": "………………………………………………………………………81",
      "page": 16
    },
    {
      "level": "H1",
      "text": "4.3.1",
      "page": 16
    },
    {
      "level": "H1",
      "text": "IJB-A/B/C",
      "page": 16
    },
    {
      "level": "H1",
      "text": "数据集的测试结果",
      "page": 16
    },
    {
      "level": "H1",
      "text": "………….….…………………81",
      "page": 16
    },
    {
      "level": "H1",
      "text": "4.3.2",
      "page": 16
    },
    {
      "level": "H1",
      "text": "YouTube Face",
      "page": 16
    },
    {
      "level": "H1",
      "text": "……………………………85",
      "page": 16
    },
    {
      "level": "H1",
      "text": "4.3.3",
      "page": 16
    },
    {
      "level": "H1",
      "text": "Celebrity-1000",
      "page": 16
    },
    {
      "level": "H1",
      "text": "……………...……………86",
      "page": 16
    },
    {
      "level": "H1",
      "text": "5.5",
      "page": 16
    },
    {
      "level": "H1",
      "text": "本章小结",
      "page": 16
    },
    {
      "level": "H1",
      "text": "…………………………………………………………………89",
      "page": 16
    },
    {
      "level": "H1",
      "text": "总结与展望",
      "page": 16
    },
    {
      "level": "H1",
      "text": "……………………………",
      "page": 16
    },
    {
      "level": "H1",
      "text": ".…….……………..…90",
      "page": 16
    },
    {
      "level": "H1",
      "text": "6.1",
      "page": 16
    },
    {
      "level": "H1",
      "text": "本文要点总结",
      "page": 16
    },
    {
      "level": "H1",
      "text": "……………………………………………………………90",
      "page": 16
    },
    {
      "level": "H1",
      "text": "6.2",
      "page": 16
    },
    {
      "level": "H1",
      "text": "研究展望",
      "page": 16
    },
    {
      "level": "H1",
      "text": "…………………………………………………………………91",
      "page": 16
    },
    {
      "level": "H1",
      "text": "参考文献",
      "page": 16
    },
    {
      "level": "H1",
      "text": "………………………………………………...…….………………93",
      "page": 16
    },
    {
      "level": "H1",
      "text": "…………………………………………………………………..….....…108",
      "page": 16
    },
    {
      "level": "H1",
      "text": "作者简历及攻读学位期间发表的学术论文与研究成果",
      "page": 16
    },
    {
      "level": "H1",
      "text": "……...…..109",
      "page": 16
    },
    {
      "level": "H1",
      "text": "1.1",
      "page": 18
    },
    {
      "level": "H1",
      "text": "研究背景及意义",
      "page": 18
    },
    {
      "level": "H1",
      "text": "近年来以深度学习（",
      "page": 18
    },
    {
      "level": "H1",
      "text": "Deep learning",
      "page": 18
    },
    {
      "level": "H1",
      "text": "[1]",
      "page": 18
    },
    {
      "level": "H1",
      "text": "为代表的一系列人工智能（",
      "page": 18
    },
    {
      "level": "H1",
      "text": "Artificial",
      "page": 18
    },
    {
      "level": "H1",
      "text": "Intelligence",
      "page": 18
    },
    {
      "level": "H1",
      "text": "[2]",
      "page": 18
    },
    {
      "level": "H1",
      "text": "算法得到了飞速发展，并有望引领下一次科学技术革命的浪潮。",
      "page": 18
    },
    {
      "level": "H1",
      "text": "虽然目前人类尚不完全清楚人脑的思维方式而难以进行精确模仿做到向人一样",
      "page": 18
    },
    {
      "level": "H1",
      "text": "思考（",
      "page": 18
    },
    {
      "level": "H1",
      "text": "Thinking humanly",
      "page": 18
    },
    {
      "level": "H1",
      "text": "），也暂时难以实现通过图灵测试的通用人工智能去像人",
      "page": 18
    },
    {
      "level": "H1",
      "text": "一样行为（",
      "page": 18
    },
    {
      "level": "H1",
      "text": "Acting humanly",
      "page": 18
    },
    {
      "level": "H1",
      "text": "）。但目前在合理性为（",
      "page": 18
    },
    {
      "level": "H1",
      "text": "Acting rationally",
      "page": 18
    },
    {
      "level": "H1",
      "text": "）这一人工智",
      "page": 18
    },
    {
      "level": "H1",
      "text": "能研究方向上取得了长足的进展，并有希望能将人类从许多繁复的工作中解脱出",
      "page": 18
    },
    {
      "level": "H1",
      "text": "来。其并不要求计算设备完全的模拟人的思考方式或行为方式以及人的外观，而",
      "page": 18
    },
    {
      "level": "H1",
      "text": "是希望通过学习先前的经验数据能够实现或完成某些特定的任务。",
      "page": 18
    },
    {
      "level": "H1",
      "text": "自上世纪末以来，数字媒体的产生量一直在逐步上升，到",
      "page": 18
    },
    {
      "level": "H1",
      "text": "2011-2012",
      "page": 18
    },
    {
      "level": "H1",
      "text": "后，随着可用训练数据的积累与图形处理器并行计算性能的进步，使得通过基于",
      "page": 18
    },
    {
      "level": "H1",
      "text": "统计学归纳偏置的机器学习算法有了广阔的用武之地",
      "page": 18
    },
    {
      "level": "H1",
      "text": "[3]",
      "page": 18
    },
    {
      "level": "H1",
      "text": "。深度神经网络继而在物",
      "page": 18
    },
    {
      "level": "H1",
      "text": "体识别、物体定位等领域大大超越了传统手工特征提取方法，并使得相关应用达",
      "page": 18
    },
    {
      "level": "H1",
      "text": "到商业化水平。随后人脸身份识别技术更是超越了人类水平",
      "page": 18
    },
    {
      "level": "H1",
      "text": "[4]",
      "page": 18
    },
    {
      "level": "H1",
      "text": "。业务需求与投资",
      "page": 18
    },
    {
      "level": "H1",
      "text": "又反过来促进了深度学习的快速发展，实现了产学研的良性循环。",
      "page": 18
    },
    {
      "level": "H1",
      "text": "生物特征识别（",
      "page": 18
    },
    {
      "level": "H1",
      "text": "Biometrics",
      "page": 18
    },
    {
      "level": "H1",
      "text": "[5]",
      "page": 18
    },
    {
      "level": "H1",
      "text": "是利用机器学习算法对生物个体，尤其是人",
      "page": 18
    },
    {
      "level": "H1",
      "text": "类本身的某些特性进行分析和识别的技术。其不仅限于利用人体所固有的指纹、",
      "page": 18
    },
    {
      "level": "H1",
      "text": "掌纹、面部、虹膜等生理特征",
      "page": 18
    },
    {
      "level": "H1",
      "text": "[6]",
      "page": 18
    },
    {
      "level": "H1",
      "text": "，也包括使用步态、打字习惯等个人行为进行身",
      "page": 18
    },
    {
      "level": "H1",
      "text": "份鉴定",
      "page": 18
    },
    {
      "level": "H1",
      "text": "[7]",
      "page": 18
    },
    {
      "level": "H1",
      "text": "。近年来广义的定义也将表情等图片属性归为软生物特征识别（",
      "page": 18
    },
    {
      "level": "H1",
      "text": "Soft",
      "page": 18
    },
    {
      "level": "H1",
      "text": "biometrics",
      "page": 18
    },
    {
      "level": "H1",
      "text": "）一类。事实上生物特征识别是机器学习较早的落地方向，并且近十年",
      "page": 18
    },
    {
      "level": "H1",
      "text": "来仍然是计算机视觉领域的研究热点。",
      "page": 18
    },
    {
      "level": "H1",
      "text": "相较于其他模态，人脸具有非常丰富的信息",
      "page": 18
    },
    {
      "level": "H1",
      "text": "[8]",
      "page": 18
    },
    {
      "level": "H1",
      "text": "。人类判别身份（",
      "page": 18
    },
    {
      "level": "H1",
      "text": "Identity, ID",
      "page": 18
    },
    {
      "level": "H1",
      "text": "信息主要依靠的就是面部形态",
      "page": 18
    },
    {
      "level": "H1",
      "text": "[9]",
      "page": 18
    },
    {
      "level": "H1",
      "text": "。相较于行为识别与声音识别，其精度较高速度",
      "page": 18
    },
    {
      "level": "H1",
      "text": "快，可满足大部分安防需求。此外，人脸身份识别属于非接触性的被动式技术，",
      "page": 18
    },
    {
      "level": "H1",
      "text": "对正常工作影响小，而且无需被识别者主动配合，可操作性高。而掌纹指纹等侵",
      "page": 18
    },
    {
      "level": "H1",
      "text": "入性识别往往在实施中容易遇到阻力。摄像头的广泛部署以及在移动终端上的普",
      "page": 18
    },
    {
      "level": "H1",
      "text": "遍使用，使得其无需配置专用采集设备，可节省购置费用、降低推广阻力。",
      "page": 18
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 19
    },
    {
      "level": "H1",
      "text": "虽然人脸识别方便快捷，但也伴随着许多随之而来的挑战。例如被动式识别",
      "page": 19
    },
    {
      "level": "H1",
      "text": "往往难以像静态摆拍一样捕捉到没有动作模糊完美对焦的图片，光照条件、表情",
      "page": 19
    },
    {
      "level": "H1",
      "text": "也常常变化。值得注意的是，由于现代生活水平逐渐提高，发色发式经常变换，",
      "page": 19
    },
    {
      "level": "H1",
      "text": "尤其是女性常有化妆需求，使得系统需要对化妆鲁棒更具挑战性",
      "page": 19
    },
    {
      "level": "H1",
      "text": "[10]",
      "page": 19
    },
    {
      "level": "H1",
      "text": "。除了对单一",
      "page": 19
    },
    {
      "level": "H1",
      "text": "的图片进行处理，随着拍摄设备日益普及和存储成本的降低，大量视频可用于人",
      "page": 19
    },
    {
      "level": "H1",
      "text": "脸分析。更进一步的，基于集的人脸识别使用同一个人的任意张图片或视频帧进",
      "page": 19
    },
    {
      "level": "H1",
      "text": "行识别，引入了更丰富的信息也带来了更复杂的类内变化而不易进行信息融合",
      "page": 19
    },
    {
      "level": "H1",
      "text": "[11]",
      "page": 19
    },
    {
      "level": "H1",
      "text": "除身份信息外，人脸的表情（",
      "page": 19
    },
    {
      "level": "H1",
      "text": "Facial expression",
      "page": 19
    },
    {
      "level": "H1",
      "text": "）是人类传递情绪和情感的主",
      "page": 19
    },
    {
      "level": "H1",
      "text": "要渠道之一。心理学家",
      "page": 19
    },
    {
      "level": "H1",
      "text": "Mehrabian",
      "page": 19
    },
    {
      "level": "H1",
      "text": "的研究",
      "page": 19
    },
    {
      "level": "H1",
      "text": "[12]",
      "page": 19
    },
    {
      "level": "H1",
      "text": "表明在面对面交谈时，言词和声音分",
      "page": 19
    },
    {
      "level": "H1",
      "text": "别只占",
      "page": 19
    },
    {
      "level": "H1",
      "text": "38%",
      "page": 19
    },
    {
      "level": "H1",
      "text": "的情感信息，而剩余的",
      "page": 19
    },
    {
      "level": "H1",
      "text": "55%",
      "page": 19
    },
    {
      "level": "H1",
      "text": "则是由面部表情来实现的。实现自",
      "page": 19
    },
    {
      "level": "H1",
      "text": "动表情识别对人机交互有着重要意义。尤其是近年来虚拟现实技术和在智能助手",
      "page": 19
    },
    {
      "level": "H1",
      "text": "的蓬勃发展使得鼠标键盘不再是主要输入设备，而相关应用正逐步重视用户反馈。",
      "page": 19
    },
    {
      "level": "H1",
      "text": "此外，其相关技术也可用于判断公共场所群体的情绪变化以预判形势，或判断驾",
      "page": 19
    },
    {
      "level": "H1",
      "text": "驶者精神状况以提示驾驶风险。",
      "page": 19
    },
    {
      "level": "H1",
      "text": "1.1",
      "page": 19
    },
    {
      "level": "H1",
      "text": "）使用像素级表达的特征空间分布与（",
      "page": 19
    },
    {
      "level": "H1",
      "text": "）期望得到的表情特征分布。",
      "page": 19
    },
    {
      "level": "H1",
      "text": "Figure 1.1 Illustration of the feature space (a) using the pixel-level representation,",
      "page": 19
    },
    {
      "level": "H1",
      "text": "and (b) using the desired expression feature represetation.",
      "page": 19
    },
    {
      "level": "H1",
      "text": "人脸图片通常糅合了包括身份、表情、年龄、性别、光照、角度等各种信息，",
      "page": 20
    },
    {
      "level": "H1",
      "text": "如何提取与识别任务相关的特征（例如身份特征对应人脸识别，表情特征对应表",
      "page": 20
    },
    {
      "level": "H1",
      "text": "情识别）是当前基于深度学习的模式识别算法的主要研究方向。如图",
      "page": 20
    },
    {
      "level": "H1",
      "text": "1.1",
      "page": 20
    },
    {
      "level": "H1",
      "text": "所示，",
      "page": 20
    },
    {
      "level": "H1",
      "text": "是快乐（",
      "page": 20
    },
    {
      "level": "H1",
      "text": "Happy",
      "page": 20
    },
    {
      "level": "H1",
      "text": "）表情，而",
      "page": 20
    },
    {
      "level": "H1",
      "text": "不属于快乐表情。",
      "page": 20
    },
    {
      "level": "H1",
      "text": "𝑓(𝑥",
      "page": 20
    },
    {
      "level": "H1",
      "text": "是从图像",
      "page": 20
    },
    {
      "level": "H1",
      "text": "中提取的特征表示。对于面部表情识别，我们希望具有相同表情标签的两个面",
      "page": 20
    },
    {
      "level": "H1",
      "text": "部图像在特征空间中彼此接近，而具有不同表情的面部图像彼此相距更远，即示",
      "page": 20
    },
    {
      "level": "H1",
      "text": "之间的距离",
      "page": 20
    },
    {
      "level": "H1",
      "text": "应该比",
      "page": 20
    },
    {
      "level": "H1",
      "text": "更小，如图",
      "page": 20
    },
    {
      "level": "H1",
      "text": "）所示。然而，在不",
      "page": 20
    },
    {
      "level": "H1",
      "text": "明确告知机器学习算法去除身份因素时，学习的特征表示通常也包含不相关的身",
      "page": 20
    },
    {
      "level": "H1",
      "text": "份信息，如图",
      "page": 20
    },
    {
      "level": "H1",
      "text": "）所示。身份间差别往往具有较大的外观变化，",
      "page": 20
    },
    {
      "level": "H1",
      "text": "通常具有",
      "page": 20
    },
    {
      "level": "H1",
      "text": "较大的值，而",
      "page": 20
    },
    {
      "level": "H1",
      "text": "相对较小，而这不利于表情识别。",
      "page": 20
    },
    {
      "level": "H1",
      "text": "本文进一步的探究了如何可控的引入对某些不相关属性的不变性先验知识，",
      "page": 20
    },
    {
      "level": "H1",
      "text": "使得提取出的针对主识别任务的特征有更好的可辨别性和泛化能力。例如表情识",
      "page": 20
    },
    {
      "level": "H1",
      "text": "别的特征应该对身份变化鲁棒，而身份识别的特征应该对表情、光照、化妆等变",
      "page": 20
    },
    {
      "level": "H1",
      "text": "化鲁棒。针对这一目标以及人脸表情识别和人脸识别这两个重要应用，本文提出",
      "page": 20
    },
    {
      "level": "H1",
      "text": "了自适应深度度量学习，以及对抗训练两种方法用以解构（",
      "page": 20
    },
    {
      "level": "H1",
      "text": "Disentangle",
      "page": 20
    },
    {
      "level": "H1",
      "text": "）表情与",
      "page": 20
    },
    {
      "level": "H1",
      "text": "身份信息，或身份与某些属性信息，以及一种深度增强学习算法用于基于图片集",
      "page": 20
    },
    {
      "level": "H1",
      "text": "Image-set",
      "page": 20
    },
    {
      "level": "H1",
      "text": "）的人脸身份识别系统。",
      "page": 20
    },
    {
      "level": "H1",
      "text": "1.2",
      "page": 20
    },
    {
      "level": "H1",
      "text": "研究现状",
      "page": 20
    },
    {
      "level": "H1",
      "text": "1.2.1",
      "page": 20
    },
    {
      "level": "H1",
      "text": "人脸识别技术的发展",
      "page": 20
    },
    {
      "level": "H1",
      "text": "1888",
      "page": 20
    },
    {
      "level": "H1",
      "text": "Nature",
      "page": 20
    },
    {
      "level": "H1",
      "text": "》发表人脸身份识别论文“",
      "page": 20
    },
    {
      "level": "H1",
      "text": "Personal identification and",
      "page": 20
    },
    {
      "level": "H1",
      "text": "description",
      "page": 20
    },
    {
      "level": "H1",
      "text": "[13]",
      "page": 20
    },
    {
      "level": "H1",
      "text": "起，人脸图像识别已成为计算机视觉领域最为成功的应用之一。",
      "page": 20
    },
    {
      "level": "H1",
      "text": "其早期研究主要采用全局特征对人脸进行描述，例如使用无监督的主成份分",
      "page": 20
    },
    {
      "level": "H1",
      "text": "Principal Component Analysis, PCA",
      "page": 20
    },
    {
      "level": "H1",
      "text": "[14]",
      "page": 20
    },
    {
      "level": "H1",
      "text": "保留较高能量的信息或有监督的线性",
      "page": 20
    },
    {
      "level": "H1",
      "text": "区分分析（",
      "page": 20
    },
    {
      "level": "H1",
      "text": "Linear Discriminative Analysis, LDA",
      "page": 20
    },
    {
      "level": "H1",
      "text": "[15]",
      "page": 20
    },
    {
      "level": "H1",
      "text": "将样本投影到类内（",
      "page": 20
    },
    {
      "level": "H1",
      "text": "Inner-class",
      "page": 20
    },
    {
      "level": "H1",
      "text": "散度较小而类间（",
      "page": 20
    },
    {
      "level": "H1",
      "text": "Inter-class",
      "page": 20
    },
    {
      "level": "H1",
      "text": "）散度较大的的空间中。但考虑到局部特征在应对光",
      "page": 20
    },
    {
      "level": "H1",
      "text": "照与表情等变化时有更好的鲁棒性，随后的研究重心逐渐转为人脸局部特征的描",
      "page": 20
    },
    {
      "level": "H1",
      "text": "述。局部二值模型（",
      "page": 20
    },
    {
      "level": "H1",
      "text": "Local Binary Pattern",
      "page": 20
    },
    {
      "level": "H1",
      "text": "[16]",
      "page": 20
    },
    {
      "level": "H1",
      "text": "能有效的记录人脸的纹理特征。其",
      "page": 20
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 21
    },
    {
      "level": "H1",
      "text": "仅提取某像素周边区域的特征。此外",
      "page": 21
    },
    {
      "level": "H1",
      "text": "Gabor",
      "page": 21
    },
    {
      "level": "H1",
      "text": "[17]",
      "page": 21
    },
    {
      "level": "H1",
      "text": "则适用于以较粗的尺度对形",
      "page": 21
    },
    {
      "level": "H1",
      "text": "状编码。而随着压缩感知理论被引入人脸识别",
      "page": 21
    },
    {
      "level": "H1",
      "text": "[18]",
      "page": 21
    },
    {
      "level": "H1",
      "text": "，主流的研究热点又转向了全局",
      "page": 21
    },
    {
      "level": "H1",
      "text": "分析。其对特征提取的效果并不十分依赖，即使是随机提取的特征依旧能取得较",
      "page": 21
    },
    {
      "level": "H1",
      "text": "好的分类效果。此外",
      "page": 21
    },
    {
      "level": "H1",
      "text": "Haar",
      "page": 21
    },
    {
      "level": "H1",
      "text": "，方向梯度直方图（",
      "page": 21
    },
    {
      "level": "H1",
      "text": "Histogram of Oriented Gradient, HOG",
      "page": 21
    },
    {
      "level": "H1",
      "text": "尺度不变特征变化（",
      "page": 21
    },
    {
      "level": "H1",
      "text": "Scale-invariant feature transform, SIFT",
      "page": 21
    },
    {
      "level": "H1",
      "text": "）等局部特征模型在随",
      "page": 21
    },
    {
      "level": "H1",
      "text": "后数十年中逐步发展起来",
      "page": 21
    },
    {
      "level": "H1",
      "text": "[8]",
      "page": 21
    },
    {
      "level": "H1",
      "text": "。用上述方法所提取的特征描述，通常可使用支持向",
      "page": 21
    },
    {
      "level": "H1",
      "text": "量机（",
      "page": 21
    },
    {
      "level": "H1",
      "text": "Support Vector Machine, SVM",
      "page": 21
    },
    {
      "level": "H1",
      "text": "）进行分类操作",
      "page": 21
    },
    {
      "level": "H1",
      "text": "[19]",
      "page": 21
    },
    {
      "level": "H1",
      "text": "SVM",
      "page": 21
    },
    {
      "level": "H1",
      "text": "是一种基于统计学",
      "page": 21
    },
    {
      "level": "H1",
      "text": "习中的",
      "page": 21
    },
    {
      "level": "H1",
      "text": "维和最小化结构风险理论的一种浅层模型。其在解决小样本学习任务",
      "page": 21
    },
    {
      "level": "H1",
      "text": "时通常有较为优秀的表现。事实上长期关注于特征提取算子的研究都很难大幅超",
      "page": 21
    },
    {
      "level": "H1",
      "text": "越基本的",
      "page": 21
    },
    {
      "level": "H1",
      "text": "SIFT",
      "page": 21
    },
    {
      "level": "H1",
      "text": "算子水平，从而逐渐开始转向新的方向。在稀疏表示或协同表示",
      "page": 21
    },
    {
      "level": "H1",
      "text": "中，若特征维度足够大，甚至连随机提取的特征都能提供足够的信息量。这大大",
      "page": 21
    },
    {
      "level": "H1",
      "text": "降低了特征提取的要求。此外，其对遮挡以及人脸配准（",
      "page": 21
    },
    {
      "level": "H1",
      "text": "Face alignment",
      "page": 21
    },
    {
      "level": "H1",
      "text": "[20]",
      "page": 21
    },
    {
      "level": "H1",
      "text": "具有良好的鲁棒性。",
      "page": 21
    },
    {
      "level": "H1",
      "text": "值得注意的是，以上方法普遍适用于人脸身份和人脸表情识别等多种任务。",
      "page": 21
    },
    {
      "level": "H1",
      "text": "考虑到表情主要涉及到肌肉变化所引起的结构化形变，主动形状模型（",
      "page": 21
    },
    {
      "level": "H1",
      "text": "Active",
      "page": 21
    },
    {
      "level": "H1",
      "text": "Shape Model, ASM",
      "page": 21
    },
    {
      "level": "H1",
      "text": "[21]",
      "page": 21
    },
    {
      "level": "H1",
      "text": "被提出来使用多个特征点的相对位置构成向量序列。主动",
      "page": 21
    },
    {
      "level": "H1",
      "text": "外观模型（",
      "page": 21
    },
    {
      "level": "H1",
      "text": "Active Appearance Model, AAM",
      "page": 21
    },
    {
      "level": "H1",
      "text": "[22]",
      "page": 21
    },
    {
      "level": "H1",
      "text": "ASM",
      "page": 21
    },
    {
      "level": "H1",
      "text": "基础上将全局的形状特",
      "page": 21
    },
    {
      "level": "H1",
      "text": "征和局部的纹理特征相结合进行综合分析。",
      "page": 21
    },
    {
      "level": "H1",
      "text": "而随着训练数据的增长，通过数据驱动的机器学习（",
      "page": 21
    },
    {
      "level": "H1",
      "text": "Machine Learning",
      "page": 21
    },
    {
      "level": "H1",
      "text": "）算法",
      "page": 21
    },
    {
      "level": "H1",
      "text": "逐渐成为主流。深度学习（",
      "page": 21
    },
    {
      "level": "H1",
      "text": "Deep Learning",
      "page": 21
    },
    {
      "level": "H1",
      "text": "）或人工神经网络（",
      "page": 21
    },
    {
      "level": "H1",
      "text": "Artificial Neural",
      "page": 21
    },
    {
      "level": "H1",
      "text": "Network, ANN",
      "page": 21
    },
    {
      "level": "H1",
      "text": "[23]",
      "page": 21
    },
    {
      "level": "H1",
      "text": "是目前人脸识别与分析的主流技术。",
      "page": 21
    },
    {
      "level": "H1",
      "text": "ANN",
      "page": 21
    },
    {
      "level": "H1",
      "text": "通过模拟大脑神经",
      "page": 21
    },
    {
      "level": "H1",
      "text": "元结构，对多个简单运算模块进行叠加实现对复杂函数的拟合。其通常包含一个",
      "page": 21
    },
    {
      "level": "H1",
      "text": "输入层（",
      "page": 21
    },
    {
      "level": "H1",
      "text": "Input Layer",
      "page": 21
    },
    {
      "level": "H1",
      "text": "），一个或多个隐藏层（",
      "page": 21
    },
    {
      "level": "H1",
      "text": "Hidden Layer",
      "page": 21
    },
    {
      "level": "H1",
      "text": "）和一个输出层（",
      "page": 21
    },
    {
      "level": "H1",
      "text": "Output",
      "page": 21
    },
    {
      "level": "H1",
      "text": "Layer",
      "page": 21
    },
    {
      "level": "H1",
      "text": "）。由于输入层只用来放置输入数据，并不进行计算，因此不计入神经网络",
      "page": 21
    },
    {
      "level": "H1",
      "text": "的层数。",
      "page": 21
    },
    {
      "level": "H1",
      "text": "的层数为其隐藏层数量加输出层组成。每层运算单元通常由一个",
      "page": 21
    },
    {
      "level": "H1",
      "text": "线性函数（即",
      "page": 21
    },
    {
      "level": "H1",
      "text": "𝑧= 𝑤𝑥+ 𝑏",
      "page": 21
    },
    {
      "level": "H1",
      "text": "，其中",
      "page": 21
    },
    {
      "level": "H1",
      "text": "是该层的输入，",
      "page": 21
    },
    {
      "level": "H1",
      "text": "分别是线性函数的斜率和",
      "page": 21
    },
    {
      "level": "H1",
      "text": "偏置项）和一个非线性函数叠加组合而成。常见的非线性函数有",
      "page": 21
    },
    {
      "level": "H1",
      "text": "Tanh",
      "page": 21
    },
    {
      "level": "H1",
      "text": "与修正线",
      "page": 21
    },
    {
      "level": "H1",
      "text": "性单元（",
      "page": 21
    },
    {
      "level": "H1",
      "text": "Rectified Linear Unit, ReLU",
      "page": 21
    },
    {
      "level": "H1",
      "text": "），以及",
      "page": 21
    },
    {
      "level": "H1",
      "text": "LeakyReLU",
      "page": 21
    },
    {
      "level": "H1",
      "text": "Tanh(z) =",
      "page": 21
    },
    {
      "level": "H1",
      "text": "1.1",
      "page": 21
    },
    {
      "level": "H1",
      "text": "ReLu(z) =",
      "page": 22
    },
    {
      "level": "H1",
      "text": "𝑧, if 𝑧> 0",
      "page": 22
    },
    {
      "level": "H1",
      "text": "0, 𝑖𝑓 𝑧≤0",
      "page": 22
    },
    {
      "level": "H1",
      "text": "1.2",
      "page": 22
    },
    {
      "level": "H1",
      "text": "LeakyReLu(z) =",
      "page": 22
    },
    {
      "level": "H1",
      "text": "𝑧,     if 𝑧> 0",
      "page": 22
    },
    {
      "level": "H1",
      "text": "𝑎𝑧, 𝑖𝑓 𝑧≤0",
      "page": 22
    },
    {
      "level": "H1",
      "text": "1.3",
      "page": 22
    },
    {
      "level": "H1",
      "text": "为线性单元的输出值。",
      "page": 22
    },
    {
      "level": "H1",
      "text": "tanh",
      "page": 22
    },
    {
      "level": "H1",
      "text": "函数在",
      "page": 22
    },
    {
      "level": "H1",
      "text": "附近很短一段区域内可看做线性的。",
      "page": 22
    },
    {
      "level": "H1",
      "text": "很大或很小时，其梯度很小，权重更新非常缓慢，即存在梯度消失问题。",
      "page": 22
    },
    {
      "level": "H1",
      "text": "ReLU",
      "page": 22
    },
    {
      "level": "H1",
      "text": "是一种分段线性函数，其在输入为正数的时候（对于大多数输入",
      "page": 22
    },
    {
      "level": "H1",
      "text": "空间来说），不",
      "page": 22
    },
    {
      "level": "H1",
      "text": "存在梯度消失问题，计算速度要快很多。",
      "page": 22
    },
    {
      "level": "H1",
      "text": "LeakyReLU",
      "page": 22
    },
    {
      "level": "H1",
      "text": "函数解决了",
      "page": 22
    },
    {
      "level": "H1",
      "text": "函数在输",
      "page": 22
    },
    {
      "level": "H1",
      "text": "入为负的情况下产生的梯度消失问题。",
      "page": 22
    },
    {
      "level": "H1",
      "text": "针对分类（",
      "page": 22
    },
    {
      "level": "H1",
      "text": "Classification",
      "page": 22
    },
    {
      "level": "H1",
      "text": "）问题，输出层的线性单元后往往连接的是",
      "page": 22
    },
    {
      "level": "H1",
      "text": "softmax",
      "page": 22
    },
    {
      "level": "H1",
      "text": "函数以对线性单元的激活值进行归一化。",
      "page": 22
    },
    {
      "level": "H1",
      "text": "Softmax",
      "page": 22
    },
    {
      "level": "H1",
      "text": "函数可写为：",
      "page": 22
    },
    {
      "level": "H1",
      "text": "单元的输入向量，是上一层的输出值，",
      "page": 22
    },
    {
      "level": "H1",
      "text": "为其每一维度的元素",
      "page": 22
    },
    {
      "level": "H1",
      "text": "值。在多元分类问题中，",
      "page": 22
    },
    {
      "level": "H1",
      "text": "往往取为数据库中类别的数量。",
      "page": 22
    },
    {
      "level": "H1",
      "text": "而对于回归（",
      "page": 22
    },
    {
      "level": "H1",
      "text": "Regression",
      "page": 22
    },
    {
      "level": "H1",
      "text": "）问题，则往往连接",
      "page": 22
    },
    {
      "level": "H1",
      "text": "sigmoid",
      "page": 22
    },
    {
      "level": "H1",
      "text": "函数，其输出的取值范",
      "page": 22
    },
    {
      "level": "H1",
      "text": "的连续值。",
      "page": 22
    },
    {
      "level": "H1",
      "text": "Sigmoid",
      "page": 22
    },
    {
      "level": "H1",
      "text": "函数可表示为：",
      "page": 22
    },
    {
      "level": "H1",
      "text": "Sigmoid(𝑥) =",
      "page": 22
    },
    {
      "level": "H1",
      "text": "ଵାୣ",
      "page": 22
    },
    {
      "level": "H1",
      "text": "1.5",
      "page": 22
    },
    {
      "level": "H1",
      "text": "函数的输入，也是上一层的输出。其通常为一个标量。",
      "page": 22
    },
    {
      "level": "H1",
      "text": "而各层的线性函数中的斜率和偏置项可通过反向传播（",
      "page": 22
    },
    {
      "level": "H1",
      "text": "Back propagation",
      "page": 22
    },
    {
      "level": "H1",
      "text": "据梯度进行更新。",
      "page": 22
    },
    {
      "level": "H1",
      "text": "ANN",
      "page": 22
    },
    {
      "level": "H1",
      "text": "要拟合更复杂的函数则需通过叠加更多层构建深度模型，因此深度学",
      "page": 22
    },
    {
      "level": "H1",
      "text": "习的发展和应用是",
      "page": 22
    },
    {
      "level": "H1",
      "text": "的必然发展之路。但更多的参数需要更大的训练数据以",
      "page": 22
    },
    {
      "level": "H1",
      "text": "及更大的运算量。幸运的是近年来数据的积累以及",
      "page": 22
    },
    {
      "level": "H1",
      "text": "GPU",
      "page": 22
    },
    {
      "level": "H1",
      "text": "运算能力的增长使得这",
      "page": 22
    },
    {
      "level": "H1",
      "text": "成为了可能。目前基于深度残差网络（",
      "page": 22
    },
    {
      "level": "H1",
      "text": "Deep Residual Networks",
      "page": 22
    },
    {
      "level": "H1",
      "text": "[31]",
      "page": 22
    },
    {
      "level": "H1",
      "text": "结构已能实现",
      "page": 22
    },
    {
      "level": "H1",
      "text": "上千层的网络结构。尽管依靠数据和网络参数的增加，各种识别系统的性能仍在",
      "page": 22
    },
    {
      "level": "H1",
      "text": "不断增长，但如何结合任务重的先验知识或常识仍是值得研究的问题。",
      "page": 22
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 23
    },
    {
      "level": "H1",
      "text": "1.2.2",
      "page": 23
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸身份识别",
      "page": 23
    },
    {
      "level": "H1",
      "text": "2014",
      "page": 23
    },
    {
      "level": "H1",
      "text": "DeepFace",
      "page": 23
    },
    {
      "level": "H1",
      "text": "[24]",
      "page": 23
    },
    {
      "level": "H1",
      "text": "第一次在著名的",
      "page": 23
    },
    {
      "level": "H1",
      "text": "LFW",
      "page": 23
    },
    {
      "level": "H1",
      "text": "Labeled Face in-the-Wild",
      "page": 23
    },
    {
      "level": "H1",
      "text": "[25]",
      "page": 23
    },
    {
      "level": "H1",
      "text": "个无约束条件下拍摄的人脸身份识别数据集上取得接近人类的表现。其使用了超",
      "page": 23
    },
    {
      "level": "H1",
      "text": "400",
      "page": 23
    },
    {
      "level": "H1",
      "text": "万张面部图像对",
      "page": 23
    },
    {
      "level": "H1",
      "text": "层的卷积神经网络（",
      "page": 23
    },
    {
      "level": "H1",
      "text": "Convolutional Neural Network, CNN",
      "page": 23
    },
    {
      "level": "H1",
      "text": "模型进行训练。受这项工作启发，近年的研究重点已转向基于深度学习的方法，",
      "page": 23
    },
    {
      "level": "H1",
      "text": "并且准确度大幅提升至",
      "page": 23
    },
    {
      "level": "H1",
      "text": "99.80",
      "page": 23
    },
    {
      "level": "H1",
      "text": "％以上。深度学习技术几乎在算法设计、训练",
      "page": 23
    },
    {
      "level": "H1",
      "text": "数据集划分、应用场景、评价标准等方面重塑了人脸身份识别的研究。",
      "page": 23
    },
    {
      "level": "H1",
      "text": "）人脸身份识别步骤",
      "page": 23
    },
    {
      "level": "H1",
      "text": "一个人脸身份识别的系统往往包含三个主要模块。第一步是进行面部检测",
      "page": 23
    },
    {
      "level": "H1",
      "text": "Face detection",
      "page": 23
    },
    {
      "level": "H1",
      "text": "），即定位图像或视频中的人脸位置并进行截图。随后使用面部",
      "page": 23
    },
    {
      "level": "H1",
      "text": "标志检测（",
      "page": 23
    },
    {
      "level": "H1",
      "text": "Face landmark detector",
      "page": 23
    },
    {
      "level": "H1",
      "text": "）进行面部配准（",
      "page": 23
    },
    {
      "level": "H1",
      "text": "Face alignment",
      "page": 23
    },
    {
      "level": "H1",
      "text": "）。最后再使用",
      "page": 23
    },
    {
      "level": "H1",
      "text": "人脸身份识别模块",
      "page": 23
    },
    {
      "level": "H1",
      "text": "[26]",
      "page": 23
    },
    {
      "level": "H1",
      "text": "。本论文专注于人脸身份识别模块部分。",
      "page": 23
    },
    {
      "level": "H1",
      "text": "）人脸身份识别任务的分类",
      "page": 23
    },
    {
      "level": "H1",
      "text": "此外，人脸身份的识别（",
      "page": 23
    },
    {
      "level": "H1",
      "text": "Face recognition",
      "page": 23
    },
    {
      "level": "H1",
      "text": "）可以归类为人脸验证（",
      "page": 23
    },
    {
      "level": "H1",
      "text": "Face",
      "page": 23
    },
    {
      "level": "H1",
      "text": "verification",
      "page": 23
    },
    {
      "level": "H1",
      "text": "）和人脸鉴别（",
      "page": 23
    },
    {
      "level": "H1",
      "text": "Face identification",
      "page": 23
    },
    {
      "level": "H1",
      "text": "[27]",
      "page": 23
    },
    {
      "level": "H1",
      "text": "。人脸验证进行的是比较查询样",
      "page": 23
    },
    {
      "level": "H1",
      "text": "Probe sample",
      "page": 23
    },
    {
      "level": "H1",
      "text": "）和候选样本（",
      "page": 23
    },
    {
      "level": "H1",
      "text": "Gallery sample",
      "page": 23
    },
    {
      "level": "H1",
      "text": "）两个样本间的相似度从而判断",
      "page": 23
    },
    {
      "level": "H1",
      "text": "两者是否为同一个人。人脸鉴别则是找出查询样本是属于哪一个人的任务。其有",
      "page": 23
    },
    {
      "level": "H1",
      "text": "两种设置，即闭集和开集人脸鉴别。闭集人脸识别的训练和测试的候选集所包含",
      "page": 23
    },
    {
      "level": "H1",
      "text": "的个体一样，而且查询样本已知在候选集中。通常把它看做一个多分类问题，类",
      "page": 23
    },
    {
      "level": "H1",
      "text": "别数量为候选集人数。而开集人脸鉴别则不确定查询样本是否属于候选集的某个",
      "page": 23
    },
    {
      "level": "H1",
      "text": "人或训练测试的候选集所包含的个体不一致。因此该问题通常被看做将查询样本",
      "page": 23
    },
    {
      "level": "H1",
      "text": "与每个候选样本逐一比较，即进行多次人脸验证。",
      "page": 23
    },
    {
      "level": "H1",
      "text": "）人脸身份识别的网络框架",
      "page": 23
    },
    {
      "level": "H1",
      "text": "对于基于深度学习的人脸身份识别模块主要包括两个重要组成成分。其一是",
      "page": 23
    },
    {
      "level": "H1",
      "text": "进行深度特征提取的网络架构。自深度学习在",
      "page": 23
    },
    {
      "level": "H1",
      "text": "ImageNet",
      "page": 23
    },
    {
      "level": "H1",
      "text": "[3]",
      "page": 23
    },
    {
      "level": "H1",
      "text": "数据集上取得了物体识",
      "page": 23
    },
    {
      "level": "H1",
      "text": "别的巨大成功后，一系列典型的",
      "page": 23
    },
    {
      "level": "H1",
      "text": "CNN",
      "page": 23
    },
    {
      "level": "H1",
      "text": "结构被广泛的使用到包括人脸身份识别的",
      "page": 23
    },
    {
      "level": "H1",
      "text": "各类计算机视觉任务中。例如",
      "page": 24
    },
    {
      "level": "H1",
      "text": "AlexNet",
      "page": 24
    },
    {
      "level": "H1",
      "text": "[28]",
      "page": 24
    },
    {
      "level": "H1",
      "text": "VGGNet",
      "page": 24
    },
    {
      "level": "H1",
      "text": "[29]",
      "page": 24
    },
    {
      "level": "H1",
      "text": "GoogleNet",
      "page": 24
    },
    {
      "level": "H1",
      "text": "[30]",
      "page": 24
    },
    {
      "level": "H1",
      "text": "ResNet",
      "page": 24
    },
    {
      "level": "H1",
      "text": "[31]",
      "page": 24
    },
    {
      "level": "H1",
      "text": "1995",
      "page": 24
    },
    {
      "level": "H1",
      "text": "Lecun",
      "page": 24
    },
    {
      "level": "H1",
      "text": "LeNet-5",
      "page": 24
    },
    {
      "level": "H1",
      "text": "[32]",
      "page": 24
    },
    {
      "level": "H1",
      "text": "网络结构中使用卷积代替传统",
      "page": 24
    },
    {
      "level": "H1",
      "text": "ANN",
      "page": 24
    },
    {
      "level": "H1",
      "text": "的线性函",
      "page": 24
    },
    {
      "level": "H1",
      "text": "数对图像进行处理并应用于手写字体的识别任务，而现今的网络结构均来源于此，",
      "page": 24
    },
    {
      "level": "H1",
      "text": "但在更深更宽的方向逐步发展。",
      "page": 24
    },
    {
      "level": "H1",
      "text": "CNN",
      "page": 24
    },
    {
      "level": "H1",
      "text": "已广泛用于各种计算机视觉应用，其对于",
      "page": 24
    },
    {
      "level": "H1",
      "text": "人脸位置变化和尺度变化而言有较好的鲁棒性。",
      "page": 24
    },
    {
      "level": "H1",
      "text": "由三种类型的异构层组成：",
      "page": 24
    },
    {
      "level": "H1",
      "text": "卷积层，池化层和完全连接的层。卷积层有一组可学习的卷积滤波器，通过对整",
      "page": 24
    },
    {
      "level": "H1",
      "text": "个输入图像进行卷积并产生激活特征图。卷积操作有以下优点：",
      "page": 24
    },
    {
      "level": "H1",
      "text": "）局部连接，",
      "page": 24
    },
    {
      "level": "H1",
      "text": "学习相邻像素之间的相关性；",
      "page": 24
    },
    {
      "level": "H1",
      "text": "）参数分享，大大减少了要学习的参数的数量；",
      "page": 24
    },
    {
      "level": "H1",
      "text": "）物体位置的移位不变性。池化层（",
      "page": 24
    },
    {
      "level": "H1",
      "text": "Pooling layer",
      "page": 24
    },
    {
      "level": "H1",
      "text": "）跟随卷积层并用于减少特征",
      "page": 24
    },
    {
      "level": "H1",
      "text": "图的空间大小和计算成本。平均池化（",
      "page": 24
    },
    {
      "level": "H1",
      "text": "Average Pooling",
      "page": 24
    },
    {
      "level": "H1",
      "text": "）和最大化池化（",
      "page": 24
    },
    {
      "level": "H1",
      "text": "Max",
      "page": 24
    },
    {
      "level": "H1",
      "text": "Pooling",
      "page": 24
    },
    {
      "level": "H1",
      "text": "）是最常用的两个非线性下采样策略。全连接层通常在网络的末端，所有",
      "page": 24
    },
    {
      "level": "H1",
      "text": "的神经元都完整的连接到上一层所有的输出，以将",
      "page": 24
    },
    {
      "level": "H1",
      "text": "特征图进一步转换为",
      "page": 24
    },
    {
      "level": "H1",
      "text": "特征向量，用于进一步的特征表示和分类。",
      "page": 24
    },
    {
      "level": "H1",
      "text": "）人脸身份识别的损失函数",
      "page": 24
    },
    {
      "level": "H1",
      "text": "第二个重要部分则是损失函数",
      "page": 24
    },
    {
      "level": "H1",
      "text": "[33]",
      "page": 24
    },
    {
      "level": "H1",
      "text": "。多分类任务中的监督信号通常基于",
      "page": 24
    },
    {
      "level": "H1",
      "text": "softmax",
      "page": 24
    },
    {
      "level": "H1",
      "text": "输出与独热（",
      "page": 24
    },
    {
      "level": "H1",
      "text": "one-hot",
      "page": 24
    },
    {
      "level": "H1",
      "text": "）标签间的交叉熵损失（",
      "page": 24
    },
    {
      "level": "H1",
      "text": "Cross-entropy loss",
      "page": 24
    },
    {
      "level": "H1",
      "text": "）。当样",
      "page": 24
    },
    {
      "level": "H1",
      "text": "本标签采用独热（",
      "page": 24
    },
    {
      "level": "H1",
      "text": "One-hot",
      "page": 24
    },
    {
      "level": "H1",
      "text": "）向量进行表示时，交叉熵损失可简化为",
      "page": 24
    },
    {
      "level": "H1",
      "text": "-log",
      "page": 24
    },
    {
      "level": "H1",
      "text": "损失，即：",
      "page": 24
    },
    {
      "level": "H1",
      "text": "是独热向量第",
      "page": 24
    },
    {
      "level": "H1",
      "text": "维的值，",
      "page": 24
    },
    {
      "level": "H1",
      "text": "输出的第",
      "page": 24
    },
    {
      "level": "H1",
      "text": "维的值。",
      "page": 24
    },
    {
      "level": "H1",
      "text": "它可以有效地指导网络结构将各个不同的类别在特征空间上映射到较远的",
      "page": 24
    },
    {
      "level": "H1",
      "text": "位置上。它对内类散度往往不作要求。然而对于人脸身份识别，当类内变化可能",
      "page": 24
    },
    {
      "level": "H1",
      "text": "大于类间差异时，交叉熵损失对人脸身份识别来说不够有效。对于人脸验证任务",
      "page": 24
    },
    {
      "level": "H1",
      "text": "则通常使用度量学习损失，例如在",
      "page": 24
    },
    {
      "level": "H1",
      "text": "Siamese",
      "page": 24
    },
    {
      "level": "H1",
      "text": "网络结构中使用的对比损失",
      "page": 24
    },
    {
      "level": "H1",
      "text": "Contrastive loss",
      "page": 24
    },
    {
      "level": "H1",
      "text": "[34]",
      "page": 24
    },
    {
      "level": "H1",
      "text": "。其要求同类样本在特征空间中相聚较近，而不同类别样",
      "page": 24
    },
    {
      "level": "H1",
      "text": "本则距离较远。因此一种可能的改进方法就是将交叉熵损失与度量学习损失相结",
      "page": 24
    },
    {
      "level": "H1",
      "text": "合以解决交叉熵损失难以使类内距离减小的问题。",
      "page": 24
    },
    {
      "level": "H1",
      "text": "在人脸验证任务中通常需要进行深度特征的相似度计算，而基于",
      "page": 24
    },
    {
      "level": "H1",
      "text": "出的闭集人脸鉴别则仅需找到最大值所对应的类别，并以此为预测的身份类别。",
      "page": 24
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 25
    },
    {
      "level": "H1",
      "text": "在使用网络结构提取深度特征后，大多数方法直接计算两个特征向量的余弦距离",
      "page": 25
    },
    {
      "level": "H1",
      "text": "距离用于衡量相似度。",
      "page": 25
    },
    {
      "level": "H1",
      "text": "L = ‖y −y",
      "page": 25
    },
    {
      "level": "H1",
      "text": "1.7",
      "page": 25
    },
    {
      "level": "H1",
      "text": "为两个对比样本所提取的特征向量。然后使用最近邻居（",
      "page": 25
    },
    {
      "level": "H1",
      "text": "Nearst Neighbor,",
      "page": 25
    },
    {
      "level": "H1",
      "text": "）进行开集人脸鉴别或阈值用于人脸验证任务。",
      "page": 25
    },
    {
      "level": "H1",
      "text": "）基于视频和图像集的人脸识别",
      "page": 25
    },
    {
      "level": "H1",
      "text": "最近几年无约束人脸识别在计算机视觉研究界受到了广泛关注。最初，基于",
      "page": 25
    },
    {
      "level": "H1",
      "text": "单个图像的人脸识别是人脸识别的主流，例如，",
      "page": 25
    },
    {
      "level": "H1",
      "text": "LFW",
      "page": 25
    },
    {
      "level": "H1",
      "text": "数据库",
      "page": 25
    },
    {
      "level": "H1",
      "text": "[25]",
      "page": 25
    },
    {
      "level": "H1",
      "text": "的人脸验证任务。",
      "page": 25
    },
    {
      "level": "H1",
      "text": "相机和数字存储技术的日益普及推动了人脸识别研究进入下一阶段，即利用视频",
      "page": 25
    },
    {
      "level": "H1",
      "text": "进行面部验证，例如（",
      "page": 25
    },
    {
      "level": "H1",
      "text": "YouTube Faces, YTF",
      "page": 25
    },
    {
      "level": "H1",
      "text": "）数据集",
      "page": 25
    },
    {
      "level": "H1",
      "text": "[35]",
      "page": 25
    },
    {
      "level": "H1",
      "text": "YTF",
      "page": 25
    },
    {
      "level": "H1",
      "text": "数据集具",
      "page": 25
    },
    {
      "level": "H1",
      "text": "有众所周知的正面姿态选择偏差，即其主要样本均为正脸图像或视频帧。",
      "page": 25
    },
    {
      "level": "H1",
      "text": "此外，与",
      "page": 25
    },
    {
      "level": "H1",
      "text": "数据集所常用的人脸验证问题相比，开集人脸识别",
      "page": 25
    },
    {
      "level": "H1",
      "text": "open-set face identification",
      "page": 25
    },
    {
      "level": "H1",
      "text": "）实际上更具挑战性。如图",
      "page": 25
    },
    {
      "level": "H1",
      "text": "5.1",
      "page": 25
    },
    {
      "level": "H1",
      "text": "所示，对于每个查询",
      "page": 25
    },
    {
      "level": "H1",
      "text": "样本（",
      "page": 25
    },
    {
      "level": "H1",
      "text": "probe sample",
      "page": 25
    },
    {
      "level": "H1",
      "text": "），其需要与每个候选样本（",
      "page": 25
    },
    {
      "level": "H1",
      "text": "gallery sample",
      "page": 25
    },
    {
      "level": "H1",
      "text": "）进行相似度比较。",
      "page": 25
    },
    {
      "level": "H1",
      "text": "即对于拥有",
      "page": 25
    },
    {
      "level": "H1",
      "text": "个候选人的任务，需要进行",
      "page": 25
    },
    {
      "level": "H1",
      "text": "次人脸验证。这就要求每次验证的",
      "page": 25
    },
    {
      "level": "H1",
      "text": "计算量要控制在较小的程度。",
      "page": 25
    },
    {
      "level": "H1",
      "text": "IARPA Janus",
      "page": 25
    },
    {
      "level": "H1",
      "text": "基准测试（",
      "page": 25
    },
    {
      "level": "H1",
      "text": "IJB-A",
      "page": 25
    },
    {
      "level": "H1",
      "text": "[36]",
      "page": 25
    },
    {
      "level": "H1",
      "text": "IJB-B",
      "page": 25
    },
    {
      "level": "H1",
      "text": "[37]",
      "page": 25
    },
    {
      "level": "H1",
      "text": "IJB-C",
      "page": 25
    },
    {
      "level": "H1",
      "text": "[38]",
      "page": 25
    },
    {
      "level": "H1",
      "text": "）提供了一种更加真实",
      "page": 25
    },
    {
      "level": "H1",
      "text": "的无约束面部验证和识别的基准测试库。他们使用一组包含具有大幅度头部旋转，",
      "page": 25
    },
    {
      "level": "H1",
      "text": "复杂表情和照明的无序面部图像和",
      "page": 25
    },
    {
      "level": "H1",
      "text": "或视频）作为表示一个人的最小单位。其中的",
      "page": 25
    },
    {
      "level": "H1",
      "text": "图像或视频样本可以来自于该个体的各类证件照片，历史自拍头像，在不同检查",
      "page": 25
    },
    {
      "level": "H1",
      "text": "点拍摄的图像以及视频中的面部。这种定义更类似于真实世界的生物特征识别场",
      "page": 25
    },
    {
      "level": "H1",
      "text": "景。从多个视图，背景环境和相机参数捕获人脸无疑会较视频帧引入更大的变化，",
      "page": 25
    },
    {
      "level": "H1",
      "text": "但也提供了更多补充信息，有望在实际应用中实现更好的性能。",
      "page": 25
    },
    {
      "level": "H1",
      "text": "1.2.3",
      "page": 25
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸表情识别",
      "page": 25
    },
    {
      "level": "H1",
      "text": "深度学习自",
      "page": 25
    },
    {
      "level": "H1",
      "text": "2014",
      "page": 25
    },
    {
      "level": "H1",
      "text": "ImageNet",
      "page": 25
    },
    {
      "level": "H1",
      "text": "[3]",
      "page": 25
    },
    {
      "level": "H1",
      "text": "数据集上取得物体识别的性能突破之后，",
      "page": 25
    },
    {
      "level": "H1",
      "text": "逐渐被应用到上一节所述的人脸身份识别上，随后又被应用到表情识别上。",
      "page": 25
    },
    {
      "level": "H1",
      "text": "在上世纪七十年代，美国心理学家",
      "page": 26
    },
    {
      "level": "H1",
      "text": "Ekman",
      "page": 26
    },
    {
      "level": "H1",
      "text": "Friesen",
      "page": 26
    },
    {
      "level": "H1",
      "text": "基于跨文化研究定义了",
      "page": 26
    },
    {
      "level": "H1",
      "text": "六种基本情绪（",
      "page": 26
    },
    {
      "level": "H1",
      "text": "Basic emotion",
      "page": 26
    },
    {
      "level": "H1",
      "text": "[39]",
      "page": 26
    },
    {
      "level": "H1",
      "text": "，即愤怒（",
      "page": 26
    },
    {
      "level": "H1",
      "text": "Anger",
      "page": 26
    },
    {
      "level": "H1",
      "text": "），厌恶（",
      "page": 26
    },
    {
      "level": "H1",
      "text": "Disgust",
      "page": 26
    },
    {
      "level": "H1",
      "text": "），恐惧（",
      "page": 26
    },
    {
      "level": "H1",
      "text": "Fear",
      "page": 26
    },
    {
      "level": "H1",
      "text": "快乐（",
      "page": 26
    },
    {
      "level": "H1",
      "text": "Happiness",
      "page": 26
    },
    {
      "level": "H1",
      "text": "），悲伤（",
      "page": 26
    },
    {
      "level": "H1",
      "text": "Sadness",
      "page": 26
    },
    {
      "level": "H1",
      "text": "）和惊讶（",
      "page": 26
    },
    {
      "level": "H1",
      "text": "Surprise",
      "page": 26
    },
    {
      "level": "H1",
      "text": "）。其研究结果表明不管文",
      "page": 26
    },
    {
      "level": "H1",
      "text": "化如何人类的基本情绪都是一致的。在此基础上建立了面部运动编码系统（",
      "page": 26
    },
    {
      "level": "H1",
      "text": "Facial",
      "page": 26
    },
    {
      "level": "H1",
      "text": "Action Coding System",
      "page": 26
    },
    {
      "level": "H1",
      "text": "FACS",
      "page": 26
    },
    {
      "level": "H1",
      "text": "[41]",
      "page": 26
    },
    {
      "level": "H1",
      "text": "根据肌肉的运动区域将人脸划分为多个运动单",
      "page": 26
    },
    {
      "level": "H1",
      "text": "Action Units, AUs",
      "page": 26
    },
    {
      "level": "H1",
      "text": "AUs",
      "page": 26
    },
    {
      "level": "H1",
      "text": "的不同组合可用于描述各类表情。",
      "page": 26
    },
    {
      "level": "H1",
      "text": "至上世纪八十年代，计算机科学家开始涉足表情识别的研究领域。",
      "page": 26
    },
    {
      "level": "H1",
      "text": "Suwa",
      "page": 26
    },
    {
      "level": "H1",
      "text": "个面部标记点在视频中的运动研究表情变化",
      "page": 26
    },
    {
      "level": "H1",
      "text": "[40]",
      "page": 26
    },
    {
      "level": "H1",
      "text": "。随着人脸跟踪，面部特征",
      "page": 26
    },
    {
      "level": "H1",
      "text": "点检测技术的发展，以及情感计算（",
      "page": 26
    },
    {
      "level": "H1",
      "text": "Affective computing",
      "page": 26
    },
    {
      "level": "H1",
      "text": "）与人机交互（",
      "page": 26
    },
    {
      "level": "H1",
      "text": "Human-",
      "page": 26
    },
    {
      "level": "H1",
      "text": "computer Interaction, HCI",
      "page": 26
    },
    {
      "level": "H1",
      "text": "）等学科的兴起，使得表情识别受到越来越多的关注。",
      "page": 26
    },
    {
      "level": "H1",
      "text": "）基于",
      "page": 26
    },
    {
      "level": "H1",
      "text": "CNN",
      "page": 26
    },
    {
      "level": "H1",
      "text": "的图片的人脸表情识别",
      "page": 26
    },
    {
      "level": "H1",
      "text": "基于图片的表情识别系统与人脸身份识别类似，也使用三个步骤，即人脸探",
      "page": 26
    },
    {
      "level": "H1",
      "text": "测，配准以及识别。而识别阶段可分为特征提取和分类两个阶段。作为典型的六",
      "page": 26
    },
    {
      "level": "H1",
      "text": "分类或七分类问题，",
      "page": 26
    },
    {
      "level": "H1",
      "text": "可以很好地适用于特征提取，并使用",
      "page": 26
    },
    {
      "level": "H1",
      "text": "softmax",
      "page": 26
    },
    {
      "level": "H1",
      "text": "输出以及",
      "page": 26
    },
    {
      "level": "H1",
      "text": "交叉熵损失进行优化。除此之外，基于区域的卷积神经网络（",
      "page": 26
    },
    {
      "level": "H1",
      "text": "region-based CNN,",
      "page": 26
    },
    {
      "level": "H1",
      "text": "R-CNN",
      "page": 26
    },
    {
      "level": "H1",
      "text": "）也被用于人脸表情识别。在文献",
      "page": 26
    },
    {
      "level": "H1",
      "text": "[42]",
      "page": 26
    },
    {
      "level": "H1",
      "text": "Faster R-CNN",
      "page": 26
    },
    {
      "level": "H1",
      "text": "[43]",
      "page": 26
    },
    {
      "level": "H1",
      "text": "被用于生成高质",
      "page": 26
    },
    {
      "level": "H1",
      "text": "量区域提议（",
      "page": 26
    },
    {
      "level": "H1",
      "text": "Region proposals",
      "page": 26
    },
    {
      "level": "H1",
      "text": "）来识别面部表情。",
      "page": 26
    },
    {
      "level": "H1",
      "text": "）深度自编码机",
      "page": 26
    },
    {
      "level": "H1",
      "text": "深度自编码器（",
      "page": 26
    },
    {
      "level": "H1",
      "text": "Deep autoencoder, DAE",
      "page": 26
    },
    {
      "level": "H1",
      "text": "）最初由文献",
      "page": 26
    },
    {
      "level": "H1",
      "text": "[44]",
      "page": 26
    },
    {
      "level": "H1",
      "text": "提出，用于学习有效",
      "page": 26
    },
    {
      "level": "H1",
      "text": "的降维编码。经过训练以预测目标值的",
      "page": 26
    },
    {
      "level": "H1",
      "text": "DAE",
      "page": 26
    },
    {
      "level": "H1",
      "text": "网络优化是通过最小化重建误差来",
      "page": 26
    },
    {
      "level": "H1",
      "text": "重建其输入。随后出现了许多深度自编码器的衍生物，例如去噪自编码机",
      "page": 26
    },
    {
      "level": "H1",
      "text": "denoising autoencoder",
      "page": 26
    },
    {
      "level": "H1",
      "text": "[45]",
      "page": 26
    },
    {
      "level": "H1",
      "text": "用部分损坏的数据来恢复原始的未失真输入；卷积自",
      "page": 26
    },
    {
      "level": "H1",
      "text": "动编码器（",
      "page": 26
    },
    {
      "level": "H1",
      "text": "convolutional autoencoder, CAE",
      "page": 26
    },
    {
      "level": "H1",
      "text": "[47]",
      "page": 26
    },
    {
      "level": "H1",
      "text": "使用卷积层（和池化层）代替全连",
      "page": 26
    },
    {
      "level": "H1",
      "text": "接的隐含层",
      "page": 26
    },
    {
      "level": "H1",
      "text": "变分自动编码器（",
      "page": 26
    },
    {
      "level": "H1",
      "text": "variational auto-encoder, VAE",
      "page": 26
    },
    {
      "level": "H1",
      "text": "[48]",
      "page": 26
    },
    {
      "level": "H1",
      "text": "，这是一种具有",
      "page": 26
    },
    {
      "level": "H1",
      "text": "有向图形模型可用于设计具有分布先验知识的生成模型。本文中将人脸表情看做",
      "page": 26
    },
    {
      "level": "H1",
      "text": "中性表情上叠加的噪声，使用去噪编码器将其移除，并结合一种对抗式的",
      "page": 26
    },
    {
      "level": "H1",
      "text": "VAE",
      "page": 26
    },
    {
      "level": "H1",
      "text": "以产生更逼真的纹理。",
      "page": 26
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 27
    },
    {
      "level": "H1",
      "text": "）网络输入",
      "page": 27
    },
    {
      "level": "H1",
      "text": "通常使用的网络输入为进行人脸配准后的",
      "page": 27
    },
    {
      "level": "H1",
      "text": "RGB",
      "page": 27
    },
    {
      "level": "H1",
      "text": "或灰度图像。但是这些原始",
      "page": 27
    },
    {
      "level": "H1",
      "text": "数据可能缺乏或未能强调某些重要信息，例如规则的纹理和图像关于某些方面的",
      "page": 27
    },
    {
      "level": "H1",
      "text": "不变性（如缩放，旋转，遮挡和照明等）。多种手工特征提取被用于作为网络输",
      "page": 27
    },
    {
      "level": "H1",
      "text": "入的扩展以缓解此问题。",
      "page": 27
    },
    {
      "level": "H1",
      "text": "CNN",
      "page": 27
    },
    {
      "level": "H1",
      "text": "的低级表示（",
      "page": 27
    },
    {
      "level": "H1",
      "text": "Low-level representation",
      "page": 27
    },
    {
      "level": "H1",
      "text": "）编码来自",
      "page": 27
    },
    {
      "level": "H1",
      "text": "给定的",
      "page": 27
    },
    {
      "level": "H1",
      "text": "图像中小块区域的特征，然后与对照明变化和位点误差较鲁棒的局",
      "page": 27
    },
    {
      "level": "H1",
      "text": "部直方图进行聚合并池化。一种新颖的映射",
      "page": 27
    },
    {
      "level": "H1",
      "text": "LBP",
      "page": 27
    },
    {
      "level": "H1",
      "text": "[49]",
      "page": 27
    },
    {
      "level": "H1",
      "text": "被提出用于照明不变的",
      "page": 27
    },
    {
      "level": "H1",
      "text": "人脸表情识别。文献",
      "page": 27
    },
    {
      "level": "H1",
      "text": "[50]",
      "page": 27
    },
    {
      "level": "H1",
      "text": "SIFT",
      "page": 27
    },
    {
      "level": "H1",
      "text": "对图像缩放和旋转的鲁棒性用于使其人脸表情",
      "page": 27
    },
    {
      "level": "H1",
      "text": "识别系统有同样特性。将轮廓，纹理，角度和颜色中的不同描述符组合为输入数",
      "page": 27
    },
    {
      "level": "H1",
      "text": "据也可以帮助增强深度网络性能",
      "page": 27
    },
    {
      "level": "H1",
      "text": "[51],[52]",
      "page": 27
    },
    {
      "level": "H1",
      "text": "基于部分的表示根据特征提取的目标任务，从整个图像中删除非关键部分，",
      "page": 27
    },
    {
      "level": "H1",
      "text": "并利用对任务敏感的关键部分。文献",
      "page": 27
    },
    {
      "level": "H1",
      "text": "[53]",
      "page": 27
    },
    {
      "level": "H1",
      "text": "表明三个感兴趣的区域（",
      "page": 27
    },
    {
      "level": "H1",
      "text": "regions of interest,",
      "page": 27
    },
    {
      "level": "H1",
      "text": "ROI",
      "page": 27
    },
    {
      "level": "H1",
      "text": "），即眉毛，眼睛和嘴巴与面部表情变化密切相关，并且裁剪这些区域作为",
      "page": 27
    },
    {
      "level": "H1",
      "text": "DSAE",
      "page": 27
    },
    {
      "level": "H1",
      "text": "的输入。例如，文献",
      "page": 27
    },
    {
      "level": "H1",
      "text": "[54]",
      "page": 27
    },
    {
      "level": "H1",
      "text": "采用深层多层网络进行视觉显着图的检测，在重要",
      "page": 27
    },
    {
      "level": "H1",
      "text": "区域上加强关注度。",
      "page": 27
    },
    {
      "level": "H1",
      "text": "）网络的集成",
      "page": 27
    },
    {
      "level": "H1",
      "text": "先前研究表明通过多个网络的集合可以取得比单个网络更好的成绩",
      "page": 27
    },
    {
      "level": "H1",
      "text": "[55]",
      "page": 27
    },
    {
      "level": "H1",
      "text": "。在实",
      "page": 27
    },
    {
      "level": "H1",
      "text": "施网络集成时应考虑两个关键因素：",
      "page": 27
    },
    {
      "level": "H1",
      "text": "足够的网络多样性，以确保其互补性；",
      "page": 27
    },
    {
      "level": "H1",
      "text": "）可以有效聚合多个网络的适当集成方法。对于网络多样性，可通过对训练数",
      "page": 27
    },
    {
      "level": "H1",
      "text": "据使用不同类型的预处理方法或采用各种网络参数和架构来实现。集成算法主要",
      "page": 27
    },
    {
      "level": "H1",
      "text": "在两个层级，即特征级别和决策层级。对于前者，最常见的策略是串联学到的多",
      "page": 27
    },
    {
      "level": "H1",
      "text": "样特征",
      "page": 27
    },
    {
      "level": "H1",
      "text": "[56],[57]",
      "page": 27
    },
    {
      "level": "H1",
      "text": "。而决策层集成可使用多数投票，简单的平均和加权平均值。其中",
      "page": 27
    },
    {
      "level": "H1",
      "text": "加权平均规则可考虑每特征的重要性，通常更为有效。",
      "page": 27
    },
    {
      "level": "H1",
      "text": "）多任务网络",
      "page": 27
    },
    {
      "level": "H1",
      "text": "大多数现有的人脸表情识别网络专注于单一的表情识别任务。文献",
      "page": 27
    },
    {
      "level": "H1",
      "text": "[58],[59]",
      "page": 27
    },
    {
      "level": "H1",
      "text": "出同时进行人脸表情识别与其他任务，如面部标记点定位和面部动作单元",
      "page": 27
    },
    {
      "level": "H1",
      "text": "Action Unit, AUs",
      "page": 27
    },
    {
      "level": "H1",
      "text": "）检测",
      "page": 27
    },
    {
      "level": "H1",
      "text": "[60]",
      "page": 27
    },
    {
      "level": "H1",
      "text": "相联合可提高人脸表情识别性能。在现实世界中，人",
      "page": 27
    },
    {
      "level": "H1",
      "text": "脸表情识别与各种因素交织在一起，例如头部姿势，照明和身份（面部形态）。",
      "page": 28
    },
    {
      "level": "H1",
      "text": "为解决此问题，引入了多任务倾向来从其他相关任务传递知识。文献",
      "page": 28
    },
    {
      "level": "H1",
      "text": "[61]",
      "page": 28
    },
    {
      "level": "H1",
      "text": "构造了一",
      "page": 28
    },
    {
      "level": "H1",
      "text": "个高阶玻尔兹曼机器（",
      "page": 28
    },
    {
      "level": "H1",
      "text": "disBM",
      "page": 28
    },
    {
      "level": "H1",
      "text": "）来学习相关因素的流形坐标并提出了解除各因素",
      "page": 28
    },
    {
      "level": "H1",
      "text": "缠绕的训练策略。此外，文献",
      "page": 28
    },
    {
      "level": "H1",
      "text": "[62]",
      "page": 28
    },
    {
      "level": "H1",
      "text": "设计了一种一体化的",
      "page": 28
    },
    {
      "level": "H1",
      "text": "CNN",
      "page": 28
    },
    {
      "level": "H1",
      "text": "模型同时解决人脸识",
      "page": 28
    },
    {
      "level": "H1",
      "text": "别任务以及微笑检测。其首先使用人脸识别预训练进行参数初始化，然后使用两",
      "page": 28
    },
    {
      "level": "H1",
      "text": "个不同分支的子网络对两个识别任务进行优化。",
      "page": 28
    },
    {
      "level": "H1",
      "text": "）基于视频的人脸表情识别",
      "page": 28
    },
    {
      "level": "H1",
      "text": "人脸表情识别也可基于视频。递归神经网络（",
      "page": 28
    },
    {
      "level": "H1",
      "text": "Recurrent neural network, RNN",
      "page": 28
    },
    {
      "level": "H1",
      "text": "是一种捕获时序信息的连接模型。除了在每个时间位点使用单个深度神经网络，",
      "page": 28
    },
    {
      "level": "H1",
      "text": "RNN",
      "page": 28
    },
    {
      "level": "H1",
      "text": "也包括连接相邻时间位点的递归边（",
      "page": 28
    },
    {
      "level": "H1",
      "text": "Recurrent edge",
      "page": 28
    },
    {
      "level": "H1",
      "text": "）并在所有步骤中共享",
      "page": 28
    },
    {
      "level": "H1",
      "text": "相同的参数。使用经典的反向时间传播（",
      "page": 28
    },
    {
      "level": "H1",
      "text": "back propagation through time, BPTT",
      "page": 28
    },
    {
      "level": "H1",
      "text": "[63]",
      "page": 28
    },
    {
      "level": "H1",
      "text": "。随后",
      "page": 28
    },
    {
      "level": "H1",
      "text": "Hochreiter",
      "page": 28
    },
    {
      "level": "H1",
      "text": "Schmidhuber",
      "page": 28
    },
    {
      "level": "H1",
      "text": "[64]",
      "page": 28
    },
    {
      "level": "H1",
      "text": "为了解决训练传统",
      "page": 28
    },
    {
      "level": "H1",
      "text": "常见的梯",
      "page": 28
    },
    {
      "level": "H1",
      "text": "度消失（",
      "page": 28
    },
    {
      "level": "H1",
      "text": "Vanishing",
      "page": 28
    },
    {
      "level": "H1",
      "text": "）和爆炸（",
      "page": 28
    },
    {
      "level": "H1",
      "text": "Exploding",
      "page": 28
    },
    {
      "level": "H1",
      "text": "）问题引入了长期短期记忆（",
      "page": 28
    },
    {
      "level": "H1",
      "text": "Long-short",
      "page": 28
    },
    {
      "level": "H1",
      "text": "term memory, LSTM",
      "page": 28
    },
    {
      "level": "H1",
      "text": "）。该",
      "page": 28
    },
    {
      "level": "H1",
      "text": "LSTM",
      "page": 28
    },
    {
      "level": "H1",
      "text": "中的单元状态由三个门调节和控制：一个输入",
      "page": 28
    },
    {
      "level": "H1",
      "text": "Input gate",
      "page": 28
    },
    {
      "level": "H1",
      "text": "）允许或阻止输入信号改变单元状态，一个输出门（",
      "page": 28
    },
    {
      "level": "H1",
      "text": "Output gate",
      "page": 28
    },
    {
      "level": "H1",
      "text": "可启用或阻止本单元的状态影响其他神经元，以及一个遗忘门（",
      "page": 28
    },
    {
      "level": "H1",
      "text": "Forget gate",
      "page": 28
    },
    {
      "level": "H1",
      "text": "调节是需要累积还是忘记先前状态。通过组合这三个门，",
      "page": 28
    },
    {
      "level": "H1",
      "text": "可以对更长的序",
      "page": 28
    },
    {
      "level": "H1",
      "text": "列进行建模。而",
      "page": 28
    },
    {
      "level": "H1",
      "text": "卷积（",
      "page": 28
    },
    {
      "level": "H1",
      "text": "3D CNN",
      "page": 28
    },
    {
      "level": "H1",
      "text": "[65]",
      "page": 28
    },
    {
      "level": "H1",
      "text": "也可以用来捕获多个相邻帧的运动信息",
      "page": 28
    },
    {
      "level": "H1",
      "text": "进行视频识别。而在实际应用中，由于采集表情视频也需要相对较长的时间，目",
      "page": 28
    },
    {
      "level": "H1",
      "text": "前也有大量工作仅使用视频中的任意几张图片来进行实时表情识别。",
      "page": 28
    },
    {
      "level": "H1",
      "text": "1.3",
      "page": 28
    },
    {
      "level": "H1",
      "text": "论文主要内容与篇章结构",
      "page": 28
    },
    {
      "level": "H1",
      "text": "本论文一共分为六个章节：",
      "page": 28
    },
    {
      "level": "H1",
      "text": "第一章系统性的介绍了研究背景、现状并概述了全文内容。其第一小节从机",
      "page": 28
    },
    {
      "level": "H1",
      "text": "器学习与人工智能的技术发展与人脸图像分析的实际需求等方面阐述了课题研",
      "page": 28
    },
    {
      "level": "H1",
      "text": "究的重要性。随后总结了目前相关方法的优缺点，并针对性的提出了待改善的问",
      "page": 28
    },
    {
      "level": "H1",
      "text": "题。通过结合待解决的关键问题与最前沿的深度学习、神经网络的进展提出了一",
      "page": 28
    },
    {
      "level": "H1",
      "text": "系列的解决方案作为全文的主要研究内容。",
      "page": 28
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 29
    },
    {
      "level": "H1",
      "text": "第二章提出基于自适应度量学习的去除身份信息干扰的人脸（图片",
      "page": 29
    },
    {
      "level": "H1",
      "text": "视频）表",
      "page": 29
    },
    {
      "level": "H1",
      "text": "情识别特征提取",
      "page": 29
    },
    {
      "level": "H1",
      "text": "[66],[67]",
      "page": 29
    },
    {
      "level": "H1",
      "text": "。面部表情是人类传递情感信息的重要途径，但在提取表",
      "page": 29
    },
    {
      "level": "H1",
      "text": "情特征时往往容易受到身份信息的干扰。本章提出了一种新的深度尺度学习算法",
      "page": 29
    },
    {
      "level": "H1",
      "text": "N+M",
      "page": 29
    },
    {
      "level": "H1",
      "text": "元组簇损失，解决了度量学习领域长期存在的锚点选择问题并大大减少了",
      "page": 29
    },
    {
      "level": "H1",
      "text": "运算量。其阈值参数可自适应学习。通过合理的设置负样本为同一个体的其他表",
      "page": 29
    },
    {
      "level": "H1",
      "text": "情图像能有效地实现难样本挖掘，并明确的消除身份信息的干扰。在",
      "page": 29
    },
    {
      "level": "H1",
      "text": "CK+",
      "page": 29
    },
    {
      "level": "H1",
      "text": "MMI",
      "page": 29
    },
    {
      "level": "H1",
      "text": "SFEW",
      "page": 29
    },
    {
      "level": "H1",
      "text": "数据集上的实验表明该算法能有效的利用表情识别数据库中常有的身",
      "page": 29
    },
    {
      "level": "H1",
      "text": "份标签，进一步提高识别精度。",
      "page": 29
    },
    {
      "level": "H1",
      "text": "第三章提出了一种难样本生成方法并配以径向度量学习",
      "page": 29
    },
    {
      "level": "H1",
      "text": "[68],[69],[70]",
      "page": 29
    },
    {
      "level": "H1",
      "text": "。来自同一",
      "page": 29
    },
    {
      "level": "H1",
      "text": "个个体的中性表情图片是较好的参考图像。但不是所有数据集中都普遍拥有此参",
      "page": 29
    },
    {
      "level": "H1",
      "text": "考图像。本章提出将查询图片与基于其生成的同身份中性脸参考图片进行比较进",
      "page": 29
    },
    {
      "level": "H1",
      "text": "而去除身份信息的影响。其难样本生成是基于像素级对抗生成网络以去除表情、",
      "page": 29
    },
    {
      "level": "H1",
      "text": "姿态等属性干扰的身份不变归一化脸生成。通过在",
      "page": 29
    },
    {
      "level": "H1",
      "text": "数据集",
      "page": 29
    },
    {
      "level": "H1",
      "text": "上的实验表明难样本生成可以利用远大于表情识别库的人脸身份识别库中的正",
      "page": 29
    },
    {
      "level": "H1",
      "text": "面中性图片以形成参考图像的先验知识，其不仅能提升识别效果，还能相较于传",
      "page": 29
    },
    {
      "level": "H1",
      "text": "统的度量学习大大缩短了度量学习训练时间。",
      "page": 29
    },
    {
      "level": "H1",
      "text": "第四章系统性的总结了人脸图片中各因素之间的关系，并定义到更广泛的多",
      "page": 29
    },
    {
      "level": "H1",
      "text": "标签数据上。提出了一种基于特征级对抗训练的解构网络，将输入图片分解为对",
      "page": 29
    },
    {
      "level": "H1",
      "text": "主识别任务（例如身份识别）具有辨识力的特征，期望对其鲁棒的有标签语义属",
      "page": 29
    },
    {
      "level": "H1",
      "text": "性（如可表情、光照、化妆等属性），以及期望对其鲁棒的无标签或难以量化的",
      "page": 29
    },
    {
      "level": "H1",
      "text": "因素（如背景等），三者互补而又互相边际独立",
      "page": 29
    },
    {
      "level": "H1",
      "text": "[10]",
      "page": 29
    },
    {
      "level": "H1",
      "text": "第五章研究了基于一个图片集合的一对一人脸验证（",
      "page": 29
    },
    {
      "level": "H1",
      "text": "Face verification",
      "page": 29
    },
    {
      "level": "H1",
      "text": "）与一",
      "page": 29
    },
    {
      "level": "H1",
      "text": "对多人脸识别（",
      "page": 29
    },
    {
      "level": "H1",
      "text": "Face identification",
      "page": 29
    },
    {
      "level": "H1",
      "text": "）问题。与传统的单个样本（单张图像或单个",
      "page": 29
    },
    {
      "level": "H1",
      "text": "视频）识别不同之处在于图片集（",
      "page": 29
    },
    {
      "level": "H1",
      "text": "Image set",
      "page": 29
    },
    {
      "level": "H1",
      "text": "）可以是一组无序图像和视频的集合。",
      "page": 29
    },
    {
      "level": "H1",
      "text": "随着数字媒体内容的爆炸性增长，查询图片或视频帧可以从多个摄像头所拍摄到",
      "page": 29
    },
    {
      "level": "H1",
      "text": "的某人所获得，而候选图片或视频帧也可由该人历史上各种证件照和其他场合所",
      "page": 29
    },
    {
      "level": "H1",
      "text": "拍摄照片组成。相较于传统的图片与图片，或视频与视频的相似度对比，该设定",
      "page": 29
    },
    {
      "level": "H1",
      "text": "可以提供更丰富的信息，但也给信息融合带来了挑战。考虑到集合中的图片质量",
      "page": 29
    },
    {
      "level": "H1",
      "text": "差异较大，传统方法往往引入一个图像质量评价环节，对每张图片进行单独评分，",
      "page": 29
    },
    {
      "level": "H1",
      "text": "而未能考虑到图片间的互补性",
      "page": 29
    },
    {
      "level": "H1",
      "text": "[11]",
      "page": 29
    },
    {
      "level": "H1",
      "text": "。如何探索一个无序的图片集合中的集内关系是",
      "page": 29
    },
    {
      "level": "H1",
      "text": "一个长期未能妥善解决的问题。针对此问题，本章提出将图片集中某图片的重要",
      "page": 30
    },
    {
      "level": "H1",
      "text": "性评价视为一个马尔科夫决策过程（",
      "page": 30
    },
    {
      "level": "H1",
      "text": "Markov Decision Process, MDP",
      "page": 30
    },
    {
      "level": "H1",
      "text": "）。具体来说，",
      "page": 30
    },
    {
      "level": "H1",
      "text": "本章首先提出一种依赖性感知的注意力控制（",
      "page": 30
    },
    {
      "level": "H1",
      "text": "dependency-aware attention control,",
      "page": 30
    },
    {
      "level": "H1",
      "text": "DAC",
      "page": 30
    },
    {
      "level": "H1",
      "text": "）网络，其使用演员",
      "page": 30
    },
    {
      "level": "H1",
      "text": "评论员（",
      "page": 30
    },
    {
      "level": "H1",
      "text": "Actor-critic",
      "page": 30
    },
    {
      "level": "H1",
      "text": "）强化学习（",
      "page": 30
    },
    {
      "level": "H1",
      "text": "Reinforcement learning,",
      "page": 30
    },
    {
      "level": "H1",
      "text": "）来决定每个图像所分配的的注意力（",
      "page": 30
    },
    {
      "level": "H1",
      "text": "Attention",
      "page": 30
    },
    {
      "level": "H1",
      "text": "）来利用无序图像之间的相关",
      "page": 30
    },
    {
      "level": "H1",
      "text": "性。进一步引入了异策略（",
      "page": 30
    },
    {
      "level": "H1",
      "text": "Off-policy",
      "page": 30
    },
    {
      "level": "H1",
      "text": "）经验重播，以加快学习过程。此外，基于",
      "page": 30
    },
    {
      "level": "H1",
      "text": "分而治之策略，",
      "page": 30
    },
    {
      "level": "H1",
      "text": "可以与针对视频的时序模型相结合分别处理无序图片以及",
      "page": 30
    },
    {
      "level": "H1",
      "text": "有序视频帧。此外还引入了姿态引导表达（",
      "page": 30
    },
    {
      "level": "H1",
      "text": "pose-guided representation, PGR",
      "page": 30
    },
    {
      "level": "H1",
      "text": "）方案，",
      "page": 30
    },
    {
      "level": "H1",
      "text": "可以进一步提高头部姿态差异较大时的识别性能。提出了一种无需训练参数的无",
      "page": 30
    },
    {
      "level": "H1",
      "text": "PGR",
      "page": 30
    },
    {
      "level": "H1",
      "text": "以及一种新颖的基于度量学习的",
      "page": 30
    },
    {
      "level": "H1",
      "text": "用于姿态对准。且基于度量学习",
      "page": 30
    },
    {
      "level": "H1",
      "text": "无需在测试阶段进行姿势检测。在",
      "page": 30
    },
    {
      "level": "H1",
      "text": "IJB-A/B/C",
      "page": 30
    },
    {
      "level": "H1",
      "text": "YTF",
      "page": 30
    },
    {
      "level": "H1",
      "text": "Celebrity-1000",
      "page": 30
    },
    {
      "level": "H1",
      "text": "集上的充分实验表明，该方法在基于集合以及基于视频的人脸识别数据库上优于",
      "page": 30
    },
    {
      "level": "H1",
      "text": "许多最先进的方法。",
      "page": 30
    },
    {
      "level": "H1",
      "text": "第六章总结了全文的研究内容与贡献，并梳理了研究过程中新发现的问题与",
      "page": 30
    },
    {
      "level": "H1",
      "text": "实际应用的需求，对下一步研究工作进行了展望。",
      "page": 30
    },
    {
      "level": "H1",
      "text": "基于深度度量学习的身份感知人脸表情识别",
      "page": 32
    },
    {
      "level": "H1",
      "text": "面部表情（",
      "page": 32
    },
    {
      "level": "H1",
      "text": "Facial expression",
      "page": 32
    },
    {
      "level": "H1",
      "text": "）是人类传达其情绪状态的最具表现力的非语言",
      "page": 32
    },
    {
      "level": "H1",
      "text": "交流渠道之一",
      "page": 32
    },
    {
      "level": "H1",
      "text": "[71]",
      "page": 32
    },
    {
      "level": "H1",
      "text": "。因此，自动面部表情识别（",
      "page": 32
    },
    {
      "level": "H1",
      "text": "FER",
      "page": 32
    },
    {
      "level": "H1",
      "text": "）在包括人机交互（",
      "page": 32
    },
    {
      "level": "H1",
      "text": "HCI",
      "page": 32
    },
    {
      "level": "H1",
      "text": "），数",
      "page": 32
    },
    {
      "level": "H1",
      "text": "字娱乐，医疗保健和智能机器人系统在内的广泛应用中非常重要",
      "page": 32
    },
    {
      "level": "H1",
      "text": "[72]",
      "page": 32
    },
    {
      "level": "H1",
      "text": "近年，研究人员在识别在摆拍的面部表情方面已取得了较大进展。而更贴近",
      "page": 32
    },
    {
      "level": "H1",
      "text": "实际应用的情况，即自然场景下自发表情识别任务仍然具有挑战性。本章的目标",
      "page": 32
    },
    {
      "level": "H1",
      "text": "是开发和设计一个在真实情境中能良好运行的表情识别系统。",
      "page": 32
    },
    {
      "level": "H1",
      "text": "表情识别的一个难点在于自发表情通常仅涉及到较小的面部肌肉运动即较",
      "page": 32
    },
    {
      "level": "H1",
      "text": "小的类间变化，而不同身份（",
      "page": 32
    },
    {
      "level": "H1",
      "text": "Identity, ID",
      "page": 32
    },
    {
      "level": "H1",
      "text": "）的人在长相上却有较大差异而有较大",
      "page": 32
    },
    {
      "level": "H1",
      "text": "的类内变化。因此提取自不同表情类别的表情相关信息容易被与身份相关而与表",
      "page": 32
    },
    {
      "level": "H1",
      "text": "情识别无关的信息所淹没",
      "page": 32
    },
    {
      "level": "H1",
      "text": "[73]",
      "page": 32
    },
    {
      "level": "H1",
      "text": "。而提取出来的表情特征若包含有较多的身份信息也",
      "page": 32
    },
    {
      "level": "H1",
      "text": "会降低系统对未见的新身份的表情识别性能。",
      "page": 32
    },
    {
      "level": "H1",
      "text": "2.1",
      "page": 32
    },
    {
      "level": "H1",
      "text": "面部表情识别（",
      "page": 32
    },
    {
      "level": "H1",
      "text": "）特征空间中所需表示的图示。这里的“类别（",
      "page": 32
    },
    {
      "level": "H1",
      "text": "class",
      "page": 32
    },
    {
      "level": "H1",
      "text": "）”指的",
      "page": 32
    },
    {
      "level": "H1",
      "text": "是面部表情。",
      "page": 32
    },
    {
      "level": "H1",
      "text": "Figure 2.1 Illustration of the desired representations in the Face Expression Recognition",
      "page": 32
    },
    {
      "level": "H1",
      "text": "(FER) feature space. The “class”here refers to the facial expression.",
      "page": 32
    },
    {
      "level": "H1",
      "text": "为了进一步提升所提取的表情特征的区分能力，并解决人脸表情识别中的较",
      "page": 32
    },
    {
      "level": "H1",
      "text": "大类内变化，一种可行的解决方案是将深度度量学习结合到传统分类网络中。广",
      "page": 32
    },
    {
      "level": "H1",
      "text": "泛使用的三重组（",
      "page": 32
    },
    {
      "level": "H1",
      "text": "triplet",
      "page": 32
    },
    {
      "level": "H1",
      "text": "）损失函数",
      "page": 32
    },
    {
      "level": "H1",
      "text": "[74]",
      "page": 32
    },
    {
      "level": "H1",
      "text": "将某个查询样例（",
      "page": 32
    },
    {
      "level": "H1",
      "text": "query sample",
      "page": 32
    },
    {
      "level": "H1",
      "text": "）设置锚点",
      "page": 32
    },
    {
      "level": "H1",
      "text": "anchor",
      "page": 32
    },
    {
      "level": "H1",
      "text": "），并在训练库中寻找一个与查询样例表情类别相同的正样本（",
      "page": 32
    },
    {
      "level": "H1",
      "text": "positive",
      "page": 32
    },
    {
      "level": "H1",
      "text": "sample",
      "page": 32
    },
    {
      "level": "H1",
      "text": "）和一个与表情类别不同的负样本（",
      "page": 32
    },
    {
      "level": "H1",
      "text": "negative sample",
      "page": 32
    },
    {
      "level": "H1",
      "text": "），并要求此正样本在",
      "page": 32
    },
    {
      "level": "H1",
      "text": "基于深度度量学习的身份感知人脸表情识别",
      "page": 33
    },
    {
      "level": "H1",
      "text": "特征空间上更接近锚点，并且负样本与锚点之间的间距超过阈值",
      "page": 33
    },
    {
      "level": "H1",
      "text": "。因此，在每",
      "page": 33
    },
    {
      "level": "H1",
      "text": "一次迭代期间，三元组损失只涉及到某另一类的负样本而忽略了其余类别。此外，",
      "page": 33
    },
    {
      "level": "H1",
      "text": "选择三元组中属于同一类的两个样本中的某一个作为锚点时却通常有不一样的",
      "page": 33
    },
    {
      "level": "H1",
      "text": "效果。即存在一些特殊情况，具有不合适锚点的三重组损失函数可能无法有效地",
      "page": 33
    },
    {
      "level": "H1",
      "text": "利用样本进行训练，并导致测试阶段的错误地判断，如图",
      "page": 33
    },
    {
      "level": "H1",
      "text": "2.3",
      "page": 33
    },
    {
      "level": "H1",
      "text": "所示。这意味着模",
      "page": 33
    },
    {
      "level": "H1",
      "text": "型的性能对三元组输入中的锚点选择较为敏感。本章受先前度量学习算法",
      "page": 33
    },
    {
      "level": "H1",
      "text": "[75],[76]",
      "page": 33
    },
    {
      "level": "H1",
      "text": "的启发，设计了一个",
      "page": 33
    },
    {
      "level": "H1",
      "text": "N+M",
      "page": 33
    },
    {
      "level": "H1",
      "text": "元组簇损失函数，它包含一个带有",
      "page": 33
    },
    {
      "level": "H1",
      "text": "个样本的负样本",
      "page": 33
    },
    {
      "level": "H1",
      "text": "集和一个使用",
      "page": 33
    },
    {
      "level": "H1",
      "text": "个样本的正样本集。并引入参考距离",
      "page": 33
    },
    {
      "level": "H1",
      "text": "以迫使负样本向远离正",
      "page": 33
    },
    {
      "level": "H1",
      "text": "样本的平均中心移动。此外对于正样本，要求被映射到围绕其中心",
      "page": 33
    },
    {
      "level": "H1",
      "text": "的小簇内。",
      "page": 33
    },
    {
      "level": "H1",
      "text": "为中心的半径圆",
      "page": 33
    },
    {
      "level": "H1",
      "text": "𝑇+ 𝜏/2",
      "page": 33
    },
    {
      "level": "H1",
      "text": "𝑇−𝜏/2",
      "page": 33
    },
    {
      "level": "H1",
      "text": "分别形成负集和正集的两个边界，如图",
      "page": 33
    },
    {
      "level": "H1",
      "text": "）所示。该算法可以有效的处理类内和类间变化的复杂分布，并且解决在传",
      "page": 33
    },
    {
      "level": "H1",
      "text": "统的深度度量学习方法中普遍存在的锚点选择问题。此外，参考距离",
      "page": 33
    },
    {
      "level": "H1",
      "text": "和边界",
      "page": 33
    },
    {
      "level": "H1",
      "text": "可以通过神经网络中的反向传播自适应地学习而不需要手动调试。此外，还提出",
      "page": 33
    },
    {
      "level": "H1",
      "text": "了一种简单有效的训练样本挖掘方案，该方案使用与查询样例身份相同而表情不",
      "page": 33
    },
    {
      "level": "H1",
      "text": "同的图片，以避免计算复杂的难负样本搜索，同时在线挖掘正样本集，如图",
      "page": 33
    },
    {
      "level": "H1",
      "text": "2.2",
      "page": 33
    },
    {
      "level": "H1",
      "text": "所示。",
      "page": 33
    },
    {
      "level": "H1",
      "text": "元组簇损失可以在每次计算损失并进行更新时使用所有其他类别的",
      "page": 33
    },
    {
      "level": "H1",
      "text": "负样本以实现身份不变的人脸表情识别。",
      "page": 33
    },
    {
      "level": "H1",
      "text": "本章所采用的人脸表情识别模型的训练。深度卷积模型学习将原图像映射到一个",
      "page": 33
    },
    {
      "level": "H1",
      "text": "特征空间中，并将同表情聚集为一个簇，而不同表情图片的特征则相互远离。",
      "page": 33
    },
    {
      "level": "H1",
      "text": "Figure 2.2 Frame work of our FER model used for training. The deep convolutional network",
      "page": 33
    },
    {
      "level": "H1",
      "text": "aims to map the original expression images into a feature space that the images of the same",
      "page": 33
    },
    {
      "level": "H1",
      "text": "expression tend to form a cluster while other images tend to locate far away.",
      "page": 33
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 34
    },
    {
      "level": "H1",
      "text": "本章提出联合优化基于",
      "page": 34
    },
    {
      "level": "H1",
      "text": "softmax",
      "page": 34
    },
    {
      "level": "H1",
      "text": "函数输出的交叉熵损失和",
      "page": 34
    },
    {
      "level": "H1",
      "text": "N+M",
      "page": 34
    },
    {
      "level": "H1",
      "text": "元组簇损失，",
      "page": 34
    },
    {
      "level": "H1",
      "text": "以同时利用表情标签和身份标签信息的潜力。考虑到每个损失函数的特性及其任",
      "page": 34
    },
    {
      "level": "H1",
      "text": "务的不同，设计了两个全连接（",
      "page": 34
    },
    {
      "level": "H1",
      "text": "fully connected , FC",
      "page": 34
    },
    {
      "level": "H1",
      "text": "）层的分支分别用于两个损失",
      "page": 34
    },
    {
      "level": "H1",
      "text": "函数的计算。此外还设计了一个平衡它们的连接层。由表情分类分支提取的特征",
      "page": 34
    },
    {
      "level": "H1",
      "text": "可以输入到度量学习分支而增加信息量。这使得每个分支能够更好地专注于各自",
      "page": 34
    },
    {
      "level": "H1",
      "text": "的任务，而无需包含另一个分支所需的某些冗余信息。如图",
      "page": 34
    },
    {
      "level": "H1",
      "text": "2.2",
      "page": 34
    },
    {
      "level": "H1",
      "text": "所示，输入是两",
      "page": 34
    },
    {
      "level": "H1",
      "text": "个面部表情图像集：一个正样本集合（来自不同个体的相同表情图像）和一个负",
      "page": 34
    },
    {
      "level": "H1",
      "text": "样本集合（具有与查询示例相同身份标记的其他表情图像）。",
      "page": 34
    },
    {
      "level": "H1",
      "text": "本章的三个主要贡献可总结为：",
      "page": 34
    },
    {
      "level": "H1",
      "text": "）提出了一种具有自适应学习参考阈值的",
      "page": 34
    },
    {
      "level": "H1",
      "text": "元组簇损失函数，该函数可",
      "page": 34
    },
    {
      "level": "H1",
      "text": "以使用线性全连接层更新阈值超参数，从而实现端到端的自动学习。",
      "page": 34
    },
    {
      "level": "H1",
      "text": "）通过身份感知的负样本挖掘和在线正样本挖掘方案，该模型只需较少的",
      "page": 34
    },
    {
      "level": "H1",
      "text": "较少输入传递和距离计算的距离度量，而不会牺牲身份不变人脸表情识别的性能。",
      "page": 34
    },
    {
      "level": "H1",
      "text": "）在双全连接层分支的分类与度量学习联合优化框架中，基于各损失和任",
      "page": 34
    },
    {
      "level": "H1",
      "text": "务的特点，共同优化交叉熵损失和",
      "page": 34
    },
    {
      "level": "H1",
      "text": "元组簇损失。",
      "page": 34
    },
    {
      "level": "H1",
      "text": "实验表明，本章所提出的方法不仅在摆拍的面部表情数据集（例如，",
      "page": 34
    },
    {
      "level": "H1",
      "text": "CK +",
      "page": 34
    },
    {
      "level": "H1",
      "text": "MMI",
      "page": 34
    },
    {
      "level": "H1",
      "text": "）上优于现有技术方案，而且在自发的面部表情数据集（即，",
      "page": 34
    },
    {
      "level": "H1",
      "text": "SFEW",
      "page": 34
    },
    {
      "level": "H1",
      "text": "）中取",
      "page": 34
    },
    {
      "level": "H1",
      "text": "得了优越性能。",
      "page": 34
    },
    {
      "level": "H1",
      "text": "2.1",
      "page": 34
    },
    {
      "level": "H1",
      "text": "相关工作",
      "page": 34
    },
    {
      "level": "H1",
      "text": "2.1.1",
      "page": 34
    },
    {
      "level": "H1",
      "text": "人脸表情识别",
      "page": 34
    },
    {
      "level": "H1",
      "text": "人脸表情识别专注于六种基本面部表情的分类，这些面部表情在被认为是人",
      "page": 34
    },
    {
      "level": "H1",
      "text": "类所普遍拥有的",
      "page": 34
    },
    {
      "level": "H1",
      "text": "[77]",
      "page": 34
    },
    {
      "level": "H1",
      "text": "。近年来在提取一组特征用于表示面部图像方面取得了许多进",
      "page": 34
    },
    {
      "level": "H1",
      "text": "[78]",
      "page": 34
    },
    {
      "level": "H1",
      "text": "。几何表示利用面部标志点之间的形状或关系。然而，他们对面部标志点的",
      "page": 34
    },
    {
      "level": "H1",
      "text": "错误配准很敏感",
      "page": 34
    },
    {
      "level": "H1",
      "text": "[79]",
      "page": 34
    },
    {
      "level": "H1",
      "text": "。另一方面，外观特征，如",
      "page": 34
    },
    {
      "level": "H1",
      "text": "Gabor",
      "page": 34
    },
    {
      "level": "H1",
      "text": "滤波器，尺度不变特征变换",
      "page": 34
    },
    {
      "level": "H1",
      "text": "Scale Invariant Feature Transform , SIFT",
      "page": 34
    },
    {
      "level": "H1",
      "text": "），局部二值模式（",
      "page": 34
    },
    {
      "level": "H1",
      "text": "Local Binary Patterns,",
      "page": 34
    },
    {
      "level": "H1",
      "text": "LBP",
      "page": 34
    },
    {
      "level": "H1",
      "text": "），局部相位量化（",
      "page": 34
    },
    {
      "level": "H1",
      "text": "Local Phase Quantization, LPQ",
      "page": 34
    },
    {
      "level": "H1",
      "text": "），定向梯度直方图（",
      "page": 34
    },
    {
      "level": "H1",
      "text": "Histogram",
      "page": 34
    },
    {
      "level": "H1",
      "text": "of Oriented Gradients, HOG",
      "page": 34
    },
    {
      "level": "H1",
      "text": "）以及通过多个内核学习这些特征的组合通常用于表",
      "page": 34
    },
    {
      "level": "H1",
      "text": "基于深度度量学习的身份感知人脸表情识别",
      "page": 35
    },
    {
      "level": "H1",
      "text": "示面部纹理",
      "page": 35
    },
    {
      "level": "H1",
      "text": "[80],[81],[82],[83]",
      "page": 35
    },
    {
      "level": "H1",
      "text": "。另一些方法，如主动外观模型（",
      "page": 35
    },
    {
      "level": "H1",
      "text": "active appearance models,",
      "page": 35
    },
    {
      "level": "H1",
      "text": "AAM",
      "page": 35
    },
    {
      "level": "H1",
      "text": "[22]",
      "page": 35
    },
    {
      "level": "H1",
      "text": "结合了几何和外观表示，以提供更好的空间信息。文献",
      "page": 35
    },
    {
      "level": "H1",
      "text": "[84]",
      "page": 35
    },
    {
      "level": "H1",
      "text": "对相关方法",
      "page": 35
    },
    {
      "level": "H1",
      "text": "提供了更全面的文献综述。由于手工特征提取的局限性，提取纯粹的仅与表情相",
      "page": 35
    },
    {
      "level": "H1",
      "text": "关的特征较为困难。事实许多相关算法都事先为人脸身份识别所使用。",
      "page": 35
    },
    {
      "level": "H1",
      "text": "2.1.2",
      "page": 35
    },
    {
      "level": "H1",
      "text": "深度卷积神经网络",
      "page": 35
    },
    {
      "level": "H1",
      "text": "近年来，深度学习的发展，尤其是卷积神经网络（",
      "page": 35
    },
    {
      "level": "H1",
      "text": "Convolutional Neural",
      "page": 35
    },
    {
      "level": "H1",
      "text": "Networks, CNN",
      "page": 35
    },
    {
      "level": "H1",
      "text": "）的成功，使得高精度的图像分类成为可能。先前研究表明，精",
      "page": 35
    },
    {
      "level": "H1",
      "text": "心设计的神经网络架构在人脸表情识别任务中也有较好表现",
      "page": 35
    },
    {
      "level": "H1",
      "text": "[85]",
      "page": 35
    },
    {
      "level": "H1",
      "text": "。尽管其在分类问",
      "page": 35
    },
    {
      "level": "H1",
      "text": "题上广受欢迎，但使用基于",
      "page": 35
    },
    {
      "level": "H1",
      "text": "softmax",
      "page": 35
    },
    {
      "level": "H1",
      "text": "输出的交叉熵损失的网络并没有明确地鼓励",
      "page": 35
    },
    {
      "level": "H1",
      "text": "类内特征向量间的紧凑性和较大的类间隔离。新兴的深度度量度学习方法已经被",
      "page": 35
    },
    {
      "level": "H1",
      "text": "研究用于具有大的类内变化的行人重识别和车辆重识别等问题，这表明深度度量",
      "page": 35
    },
    {
      "level": "H1",
      "text": "度学习可以为人脸表情识别提供更有效的优化目标。",
      "page": 35
    },
    {
      "level": "H1",
      "text": "2.1.3",
      "page": 35
    },
    {
      "level": "H1",
      "text": "度量学习",
      "page": 35
    },
    {
      "level": "H1",
      "text": "与传统的距离度量学习相比，深度度量学习使用深度神经网络学习数据的非",
      "page": 35
    },
    {
      "level": "H1",
      "text": "线性嵌入。其最初的工作是训练具有对比度（",
      "page": 35
    },
    {
      "level": "H1",
      "text": "Contrastive",
      "page": 35
    },
    {
      "level": "H1",
      "text": "）损失函数的孪生网络",
      "page": 35
    },
    {
      "level": "H1",
      "text": "Siamese network",
      "page": 35
    },
    {
      "level": "H1",
      "text": "[86]",
      "page": 35
    },
    {
      "level": "H1",
      "text": "。成对的样本被输入到两个对称的网络中以预测它们是否",
      "page": 35
    },
    {
      "level": "H1",
      "text": "来自同一类。如若属于同一类，两个特征将被要求近于一个阈值，若不同则应远",
      "page": 35
    },
    {
      "level": "H1",
      "text": "于此阈值。由于每次比较中没有相同对和不相同对之间的相互作用，",
      "page": 35
    },
    {
      "level": "H1",
      "text": "Siamese",
      "page": 35
    },
    {
      "level": "H1",
      "text": "络可能无法在存在大的类内和类间变化的情况下学习到有效的目标。针对此问题，",
      "page": 35
    },
    {
      "level": "H1",
      "text": "一种改进是使用三元组损失",
      "page": 35
    },
    {
      "level": "H1",
      "text": "[74]",
      "page": 35
    },
    {
      "level": "H1",
      "text": "，它在重识别和人脸验证问题上都取得了很好的表",
      "page": 35
    },
    {
      "level": "H1",
      "text": "现。其输入是三元组，每个三元组由查询样本，正样本和负样本组成。具体而言，",
      "page": 35
    },
    {
      "level": "H1",
      "text": "它将查询样本设置为锚点，并迫使从锚点到正例的距离与从锚点到负例的距离差",
      "page": 35
    },
    {
      "level": "H1",
      "text": "大于固定的边界阈值",
      "page": 35
    },
    {
      "level": "H1",
      "text": "。最近，基于此距离进一步开发了一些具有更快和更稳定",
      "page": 35
    },
    {
      "level": "H1",
      "text": "收敛性的改进。与本章所提出方法最相似的模型是",
      "page": 35
    },
    {
      "level": "H1",
      "text": "+1)",
      "page": 35
    },
    {
      "level": "H1",
      "text": "元组损失",
      "page": 35
    },
    {
      "level": "H1",
      "text": "[75]",
      "page": 35
    },
    {
      "level": "H1",
      "text": "。本章使用",
      "page": 35
    },
    {
      "level": "H1",
      "text": "来表示查询示例",
      "page": 35
    },
    {
      "level": "H1",
      "text": "的正样本和负样本，这意味着",
      "page": 35
    },
    {
      "level": "H1",
      "text": "为同一类，而",
      "page": 35
    },
    {
      "level": "H1",
      "text": "不是一类。考虑",
      "page": 35
    },
    {
      "level": "H1",
      "text": "元组包括",
      "page": 35
    },
    {
      "level": "H1",
      "text": "个负样本",
      "page": 35
    },
    {
      "level": "H1",
      "text": "௝ୀଵ",
      "page": 35
    },
    {
      "level": "H1",
      "text": "ேିଵ",
      "page": 35
    },
    {
      "level": "H1",
      "text": "，其损失可定义为：",
      "page": 35
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 36
    },
    {
      "level": "H1",
      "text": "𝑥, 𝑥",
      "page": 36
    },
    {
      "level": "H1",
      "text": "௝ୀଵ",
      "page": 36
    },
    {
      "level": "H1",
      "text": "ேିଵ",
      "page": 36
    },
    {
      "level": "H1",
      "text": "; 𝑓",
      "page": 36
    },
    {
      "level": "H1",
      "text": "= log",
      "page": 36
    },
    {
      "level": "H1",
      "text": "1 + ∑",
      "page": 36
    },
    {
      "level": "H1",
      "text": "exp(𝐷(𝑓, 𝑓",
      "page": 36
    },
    {
      "level": "H1",
      "text": ") + τ −𝐷(𝑓, 𝑓",
      "page": 36
    },
    {
      "level": "H1",
      "text": "(2.1)",
      "page": 36
    },
    {
      "level": "H1",
      "text": "𝑓(·)",
      "page": 36
    },
    {
      "level": "H1",
      "text": "CNN",
      "page": 36
    },
    {
      "level": "H1",
      "text": "定义的特征提取器，它将",
      "page": 36
    },
    {
      "level": "H1",
      "text": "嵌入到特征空间并表示为特征",
      "page": 36
    },
    {
      "level": "H1",
      "text": "𝑓(𝑥)",
      "page": 36
    },
    {
      "level": "H1",
      "text": "。为简单起见，可将其写为",
      "page": 36
    },
    {
      "level": "H1",
      "text": "所有的上标和下标均与前文",
      "page": 36
    },
    {
      "level": "H1",
      "text": "相同。",
      "page": 36
    },
    {
      "level": "H1",
      "text": "在不同的方法中，",
      "page": 36
    },
    {
      "level": "H1",
      "text": "( ·,· )",
      "page": 36
    },
    {
      "level": "H1",
      "text": "可被定义为马氏距离（",
      "page": 36
    },
    {
      "level": "H1",
      "text": "Mahalanobis distance",
      "page": 36
    },
    {
      "level": "H1",
      "text": "）或欧几里",
      "page": 36
    },
    {
      "level": "H1",
      "text": "德距离（",
      "page": 36
    },
    {
      "level": "H1",
      "text": "Euclidean distance",
      "page": 36
    },
    {
      "level": "H1",
      "text": "）。本章所用方法也与耦合簇损失",
      "page": 36
    },
    {
      "level": "H1",
      "text": "[76]",
      "page": 36
    },
    {
      "level": "H1",
      "text": "有类似之处。其中",
      "page": 36
    },
    {
      "level": "H1",
      "text": "正样本中心",
      "page": 36
    },
    {
      "level": "H1",
      "text": "被设置为锚点而非某个正样本。其使用两个阈值来避免锚点选择问",
      "page": 36
    },
    {
      "level": "H1",
      "text": "题，并且无需手动设置阈值参数",
      "page": 36
    },
    {
      "level": "H1",
      "text": "。通过将每个实例与该中心相互比较而不",
      "page": 36
    },
    {
      "level": "H1",
      "text": "是相互比较，每次的距离比较次数大大减少。",
      "page": 36
    },
    {
      "level": "H1",
      "text": "2.3",
      "page": 36
    },
    {
      "level": "H1",
      "text": "）三重组损失，（",
      "page": 36
    },
    {
      "level": "H1",
      "text": "+1)",
      "page": 36
    },
    {
      "level": "H1",
      "text": "元组损失，以及（",
      "page": 36
    },
    {
      "level": "H1",
      "text": "）耦合簇损失中的损失值为零，而",
      "page": 36
    },
    {
      "level": "H1",
      "text": "正负样本距离却仍然较正样本",
      "page": 36
    },
    {
      "level": "H1",
      "text": "锚点距离小的情况。（",
      "page": 36
    },
    {
      "level": "H1",
      "text": "）本章所提出的",
      "page": 36
    },
    {
      "level": "H1",
      "text": "N+M",
      "page": 36
    },
    {
      "level": "H1",
      "text": "元组簇损失。",
      "page": 36
    },
    {
      "level": "H1",
      "text": "此图中使用",
      "page": 36
    },
    {
      "level": "H1",
      "text": "黄色圆点",
      "page": 36
    },
    {
      "level": "H1",
      "text": ") and",
      "page": 36
    },
    {
      "level": "H1",
      "text": "分别表示正样本与负样本，即",
      "page": 36
    },
    {
      "level": "H1",
      "text": "与查询样本",
      "page": 36
    },
    {
      "level": "H1",
      "text": "同类别而",
      "page": 36
    },
    {
      "level": "H1",
      "text": "属于不同类别。",
      "page": 36
    },
    {
      "level": "H1",
      "text": "𝒇(·)",
      "page": 36
    },
    {
      "level": "H1",
      "text": "为进行特征提取的映射。",
      "page": 36
    },
    {
      "level": "H1",
      "text": "Figure 2.3 Failed case of (a) triplet loss, (b) (",
      "page": 36
    },
    {
      "level": "H1",
      "text": "+1)-tuplet loss, and (c) Coupled clusters loss.",
      "page": 36
    },
    {
      "level": "H1",
      "text": "The proposed (",
      "page": 36
    },
    {
      "level": "H1",
      "text": ")-tuplet clusters loss is illustrated in (d)",
      "page": 36
    },
    {
      "level": "H1",
      "text": "We use",
      "page": 36
    },
    {
      "level": "H1",
      "text": "(yellow points) and",
      "page": 36
    },
    {
      "level": "H1",
      "text": "(squares) to denote the positive and negative examples of a query example",
      "page": 36
    },
    {
      "level": "H1",
      "text": ", meaning",
      "page": 36
    },
    {
      "level": "H1",
      "text": "that",
      "page": 36
    },
    {
      "level": "H1",
      "text": "is the same class of",
      "page": 36
    },
    {
      "level": "H1",
      "text": ", while",
      "page": 36
    },
    {
      "level": "H1",
      "text": "is not.",
      "page": 36
    },
    {
      "level": "H1",
      "text": "is an embedding kernel.",
      "page": 36
    },
    {
      "level": "H1",
      "text": "基于深度度量学习的身份感知人脸表情识别",
      "page": 37
    },
    {
      "level": "H1",
      "text": "尽管以上深度度量学习算法被广泛使用，但上述框架仍然受限于难以利用有",
      "page": 37
    },
    {
      "level": "H1",
      "text": "效的样本组合。在实际操作中，生成所有可能的样本对或三元组将分别需要二次",
      "page": 37
    },
    {
      "level": "H1",
      "text": "方和三次方于训练样本数量的组合，并且这些对或三元组中的大多数在训练阶段",
      "page": 37
    },
    {
      "level": "H1",
      "text": "太过容易而缺少学习价值，甚至使得网络收敛到较差的局部最优解。因此需要难",
      "page": 37
    },
    {
      "level": "H1",
      "text": "样本挖掘算法对可能的组合进行筛选以提供较难区分的对或三元组。然而无论是",
      "page": 37
    },
    {
      "level": "H1",
      "text": "传统的在线或离线的难样本选择都不可避免的带来了较大的计算量。而且，如图",
      "page": 37
    },
    {
      "level": "H1",
      "text": "2.3",
      "page": 37
    },
    {
      "level": "H1",
      "text": "），（",
      "page": 37
    },
    {
      "level": "H1",
      "text": "）和（",
      "page": 37
    },
    {
      "level": "H1",
      "text": "）所示，当类内和类间变化很大时，它们通常都对锚点选择",
      "page": 37
    },
    {
      "level": "H1",
      "text": "敏感。因为锚和正例之间的距离确实小于锚和负例之间的距离",
      "page": 37
    },
    {
      "level": "H1",
      "text": "，三重组损失，",
      "page": 37
    },
    {
      "level": "H1",
      "text": "+1)",
      "page": 37
    },
    {
      "level": "H1",
      "text": "元组损失和耦合簇损失（",
      "page": 37
    },
    {
      "level": "H1",
      "text": "coupled clusters loss, CCL",
      "page": 37
    },
    {
      "level": "H1",
      "text": "[76]",
      "page": 37
    },
    {
      "level": "H1",
      "text": "在这些例子中均是",
      "page": 37
    },
    {
      "level": "H1",
      "text": "。这意味着损失函数将在反向传播期间忽略这些情况，而事实上其中正样本到",
      "page": 37
    },
    {
      "level": "H1",
      "text": "锚点的距离还是远于到负样本的距离。这将导致在测试中将正样本划分为与较近",
      "page": 37
    },
    {
      "level": "H1",
      "text": "的负样本一类。传统度量学习方法寄希望于多次迭代后轮换到另一个正样本当锚",
      "page": 37
    },
    {
      "level": "H1",
      "text": "点时可以发现这个分布的不合理性并纠正网络，而这导致需要遍历所有的组合来",
      "page": 37
    },
    {
      "level": "H1",
      "text": "纠正它。对比损失中的固定阈值也被认为是次优的选择，因为它无法适应特征空",
      "page": 37
    },
    {
      "level": "H1",
      "text": "间中的局部数据结构。",
      "page": 37
    },
    {
      "level": "H1",
      "text": "[87]",
      "page": 37
    },
    {
      "level": "H1",
      "text": "提出通过在新的特征空间中学习线性支持向量",
      "page": 37
    },
    {
      "level": "H1",
      "text": "SVM",
      "page": 37
    },
    {
      "level": "H1",
      "text": "）来解决这个问题。另一些工作",
      "page": 37
    },
    {
      "level": "H1",
      "text": "[88],[89]",
      "page": 37
    },
    {
      "level": "H1",
      "text": "对成对的输入使用收缩",
      "page": 37
    },
    {
      "level": "H1",
      "text": "shrinkage-expansion",
      "page": 37
    },
    {
      "level": "H1",
      "text": "）自适应约束，通过对",
      "page": 37
    },
    {
      "level": "H1",
      "text": "训练和投影到所有正半定（",
      "page": 37
    },
    {
      "level": "H1",
      "text": "PSD",
      "page": 37
    },
    {
      "level": "H1",
      "text": "矩阵锥上进行交替优化。但这些方法机制并不直接适用于深度学习模型。",
      "page": 37
    },
    {
      "level": "H1",
      "text": "最近的研究进行了交叉熵损失与深度度量学习损失之间的客观比较，并表明",
      "page": 37
    },
    {
      "level": "H1",
      "text": "它们可以相互补充。因此，直观的改进方法是将分类和相似性约束的损失函数相",
      "page": 37
    },
    {
      "level": "H1",
      "text": "结合以形成联合优化目标更新网络参数。例如，文献",
      "page": 37
    },
    {
      "level": "H1",
      "text": "[90],[91]",
      "page": 37
    },
    {
      "level": "H1",
      "text": "将对比度损失函数和",
      "page": 37
    },
    {
      "level": "H1",
      "text": "交叉熵损失结合在一起以实现更好的性能，而文献",
      "page": 37
    },
    {
      "level": "H1",
      "text": "[92]",
      "page": 37
    },
    {
      "level": "H1",
      "text": "提出通过联合优化来组合三",
      "page": 37
    },
    {
      "level": "H1",
      "text": "重组损失和交叉熵损失。这些模型改善了仅具有交叉熵损失的传统多分类神经网",
      "page": 37
    },
    {
      "level": "H1",
      "text": "络，因为相似性约束可以增加用于训练网络的信息，构建更为严格的学习目标也",
      "page": 37
    },
    {
      "level": "H1",
      "text": "可以有效地避免过度拟合。然而，以上这些策略往往直接在最后一个全连接层上",
      "page": 37
    },
    {
      "level": "H1",
      "text": "同时应用相似性和分类约束，而未考虑到两者的区别。通常交叉熵损失的收敛比",
      "page": 37
    },
    {
      "level": "H1",
      "text": "多任务网络中的深度度量学习损失快得多。事实上深度度量学习是较交叉熵损失",
      "page": 37
    },
    {
      "level": "H1",
      "text": "更难优化的目标函数。因此，采用先前方法，较难的任务不能分配到更多的参数",
      "page": 37
    },
    {
      "level": "H1",
      "text": "并且约束之间的交互是隐式的。为此本章提出构建一个统一的联合学习框架，以",
      "page": 37
    },
    {
      "level": "H1",
      "text": "更合理的方式同时学习这两个损失函数。",
      "page": 37
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 38
    },
    {
      "level": "H1",
      "text": "2.2",
      "page": 38
    },
    {
      "level": "H1",
      "text": "基于深度度量学习的人脸图片表情识别算法",
      "page": 38
    },
    {
      "level": "H1",
      "text": "2.2.1",
      "page": 38
    },
    {
      "level": "H1",
      "text": "N+M",
      "page": 38
    },
    {
      "level": "H1",
      "text": "元组簇损失的深度度量学习",
      "page": 38
    },
    {
      "level": "H1",
      "text": "正如在第二章",
      "page": 38
    },
    {
      "level": "H1",
      "text": "2.1.2",
      "page": 38
    },
    {
      "level": "H1",
      "text": "小节中所讨论的，三元组损失、",
      "page": 38
    },
    {
      "level": "H1",
      "text": "+1)",
      "page": 38
    },
    {
      "level": "H1",
      "text": "元组损失以及聚合",
      "page": 38
    },
    {
      "level": "H1",
      "text": "簇损失都难以有效地利用训练样本使得特征空间中的不同类别有较宽的边界。一",
      "page": 38
    },
    {
      "level": "H1",
      "text": "种可能的解释是由于只选用一个固定长度的超参数",
      "page": 38
    },
    {
      "level": "H1",
      "text": "来控制边界的宽度，而无法",
      "page": 38
    },
    {
      "level": "H1",
      "text": "控制每一类正样本分布的稀疏程度。这导致正样本的分布直径与边界宽度",
      "page": 38
    },
    {
      "level": "H1",
      "text": "的比例难以确定。基于以上考虑，本小结提出使用两个距离参数来实现正样本的",
      "page": 38
    },
    {
      "level": "H1",
      "text": "集中分布以及负样本与正样本之间的远距离分布。为了与先前研究的符号相匹配",
      "page": 38
    },
    {
      "level": "H1",
      "text": "以及便于后文中使用全连接层自适应调整相关超参数的公式推导，在本文中不使",
      "page": 38
    },
    {
      "level": "H1",
      "text": "用两个单独的参数来表示正样本簇的半径和正样本中心到负样本距离两个边界，",
      "page": 38
    },
    {
      "level": "H1",
      "text": "而是引入一个新的参数",
      "page": 38
    },
    {
      "level": "H1",
      "text": "作为两者的中间值（见图",
      "page": 38
    },
    {
      "level": "H1",
      "text": "2.3",
      "page": 38
    },
    {
      "level": "H1",
      "text": "）。从而要求正样本在特征",
      "page": 38
    },
    {
      "level": "H1",
      "text": "空间上分布于一个圆心为中心锚点、半径为",
      "page": 38
    },
    {
      "level": "H1",
      "text": "𝑇−𝜏/2",
      "page": 38
    },
    {
      "level": "H1",
      "text": "的圆内，而负样本则需远离",
      "page": 38
    },
    {
      "level": "H1",
      "text": "中心锚点超过",
      "page": 38
    },
    {
      "level": "H1",
      "text": "𝑇+ 𝜏/2",
      "page": 38
    },
    {
      "level": "H1",
      "text": "的距离。",
      "page": 38
    },
    {
      "level": "H1",
      "text": "如果将公式（",
      "page": 38
    },
    {
      "level": "H1",
      "text": "）中的",
      "page": 38
    },
    {
      "level": "H1",
      "text": "元组损失进行改写，可以得到：",
      "page": 38
    },
    {
      "level": "H1",
      "text": "𝐿(𝑥, 𝑥",
      "page": 38
    },
    {
      "level": "H1",
      "text": "௝ୀଵ",
      "page": 38
    },
    {
      "level": "H1",
      "text": "ேିଵ",
      "page": 38
    },
    {
      "level": "H1",
      "text": "; 𝑓) = log (1 + ∑",
      "page": 38
    },
    {
      "level": "H1",
      "text": "exp(𝐷(𝑓, 𝑓",
      "page": 38
    },
    {
      "level": "H1",
      "text": ") + τ −𝐷(𝑓, 𝑓",
      "page": 38
    },
    {
      "level": "H1",
      "text": "= log (1 + ∑",
      "page": 38
    },
    {
      "level": "H1",
      "text": ") + (−𝑇+ 𝜏/2 + 𝑇+",
      "page": 38
    },
    {
      "level": "H1",
      "text": "𝜏/2) −𝐷(𝑓, 𝑓",
      "page": 38
    },
    {
      "level": "H1",
      "text": ")))",
      "page": 38
    },
    {
      "level": "H1",
      "text": ") −𝑇+ 𝜏/2) ∗exp (𝑇+ 𝜏/2 −𝐷(𝑓, 𝑓",
      "page": 38
    },
    {
      "level": "H1",
      "text": "(2.2)",
      "page": 38
    },
    {
      "level": "H1",
      "text": "可见其实质是在使用",
      "page": 38
    },
    {
      "level": "H1",
      "text": ") −𝑇+",
      "page": 38
    },
    {
      "level": "H1",
      "text": "𝜏/2)",
      "page": 38
    },
    {
      "level": "H1",
      "text": "项使正样本与锚点的距离小",
      "page": 38
    },
    {
      "level": "H1",
      "text": "，并使用",
      "page": 38
    },
    {
      "level": "H1",
      "text": "exp (𝑇+",
      "page": 38
    },
    {
      "level": "H1",
      "text": "𝜏/2 −𝐷(𝑓, 𝑓",
      "page": 38
    },
    {
      "level": "H1",
      "text": "项将负样本推离到距锚点远于",
      "page": 38
    },
    {
      "level": "H1",
      "text": "𝜏/2",
      "page": 38
    },
    {
      "level": "H1",
      "text": "的距离。然而，这两项之间采用的乘号使得这两个要求之间为“或”关系，",
      "page": 38
    },
    {
      "level": "H1",
      "text": "即满足任意一个即可。这就导致了",
      "page": 38
    },
    {
      "level": "H1",
      "text": "元组损失是一种较为宽松的惩罚，没能",
      "page": 38
    },
    {
      "level": "H1",
      "text": "充分地利用训练数据。一种简单而又直观的改进方式则是将其“或”关系转变为",
      "page": 38
    },
    {
      "level": "H1",
      "text": "“与”关系，即需要两者同时满足才能达到损失函数的要求。",
      "page": 38
    },
    {
      "level": "H1",
      "text": "此外，进一步将三元组损失扩展为包含",
      "page": 38
    },
    {
      "level": "H1",
      "text": "个正样本与",
      "page": 38
    },
    {
      "level": "H1",
      "text": "个负样本的多元组",
      "page": 38
    },
    {
      "level": "H1",
      "text": "损失。三元组损失以及聚合簇损失中都只使用了一个负样本。因此其每次迭代只",
      "page": 38
    },
    {
      "level": "H1",
      "text": "要求正样本锚点或正样本中心锚点远离某一个类别。对于一个多分类问题，例如",
      "page": 38
    },
    {
      "level": "H1",
      "text": "表情识别和人脸识别，这两种损失函数期望通过在充分多次的迭代中随机选择负",
      "page": 38
    },
    {
      "level": "H1",
      "text": "样本来实现多个类别的远距离分布。而在实际操作中，尤其是进入训练后期时，",
      "page": 38
    },
    {
      "level": "H1",
      "text": "基于深度度量学习的身份感知人脸表情识别",
      "page": 39
    },
    {
      "level": "H1",
      "text": "大量迭代回合的损失都为零。缺少难样本将导致训练不稳定及收敛速度慢等问题。",
      "page": 39
    },
    {
      "level": "H1",
      "text": "为避免训练样本利用不充分的问题，本章在每次迭代中使用多个负样本。",
      "page": 39
    },
    {
      "level": "H1",
      "text": "不同于先前度量学习中随机选择多个负样本",
      "page": 39
    },
    {
      "level": "H1",
      "text": "本文提出了一种利用人脸身",
      "page": 39
    },
    {
      "level": "H1",
      "text": "份信息的负难样本挖掘算法。首先，人脸表情识别的类别约为",
      "page": 39
    },
    {
      "level": "H1",
      "text": "类，因此可",
      "page": 39
    },
    {
      "level": "H1",
      "text": "以在每一类中挑选一个负样本而不会对",
      "page": 39
    },
    {
      "level": "H1",
      "text": "GPU",
      "page": 39
    },
    {
      "level": "H1",
      "text": "存储造成太大压力。在实际选取负",
      "page": 39
    },
    {
      "level": "H1",
      "text": "样本的操作中，选择与查询样本具有同身份的其他表情图片。通过使得同身份但",
      "page": 39
    },
    {
      "level": "H1",
      "text": "不同表情的人脸图片分布的较远，可以使得神经网络明确的学习到与身份相关的",
      "page": 39
    },
    {
      "level": "H1",
      "text": "信息应该被去除。如果仍然保留身份信息，则两者间表示身份的共同部分会使得",
      "page": 39
    },
    {
      "level": "H1",
      "text": "其在特征空间上的相似度较大，即距离较近而受到损失函数的惩罚。",
      "page": 39
    },
    {
      "level": "H1",
      "text": "考虑到身份信息在表情识别库中广泛存在，这种反差对比可以有效的保留与",
      "page": 39
    },
    {
      "level": "H1",
      "text": "表情相关、身份无关的信息，而又不引入额外的复杂结构和算法。事实上即便没",
      "page": 39
    },
    {
      "level": "H1",
      "text": "有对应的人脸身份标签，也可以使用目前先进的人脸身份识别网络进行身份标记。",
      "page": 39
    },
    {
      "level": "H1",
      "text": "人脸身份识别网络通常使用百万张人脸图像进行训练，其识别性能已达较高水平。",
      "page": 39
    },
    {
      "level": "H1",
      "text": "此外，可以像传统的尺度学习一样随机的选择正样本，例如与查询样本同表",
      "page": 39
    },
    {
      "level": "H1",
      "text": "情不同身份的图片。然而一些极难的正样本容易导致模型训练不稳定以及过拟合",
      "page": 39
    },
    {
      "level": "H1",
      "text": "现象的发生。在自发表情识别中（例如",
      "page": 39
    },
    {
      "level": "H1",
      "text": "SFEW",
      "page": 39
    },
    {
      "level": "H1",
      "text": "库），普遍存在表情被错误标记的",
      "page": 39
    },
    {
      "level": "H1",
      "text": "情况。一个图片可能被不同的标记者标记为不同的表情，而这取决于标记者的经",
      "page": 39
    },
    {
      "level": "H1",
      "text": "验和所受训练",
      "page": 39
    },
    {
      "level": "H1",
      "text": "[93],[94]",
      "page": 39
    },
    {
      "level": "H1",
      "text": "。在摆拍的表情库中这种情况则较少见。在采集过程中往往",
      "page": 39
    },
    {
      "level": "H1",
      "text": "先由组织者告诉演员或志愿者需要摆拍某类表情再进行采集。而在实际应用中，",
      "page": 39
    },
    {
      "level": "H1",
      "text": "自发表情显然更贴近真实情况。因此需要设计一种针对",
      "page": 39
    },
    {
      "level": "H1",
      "text": "个随机选取的正样本",
      "page": 39
    },
    {
      "level": "H1",
      "text": "的简单有效的在线挖掘方法用于解决噪声数据以及大类内误差数据。本文采用按",
      "page": 39
    },
    {
      "level": "H1",
      "text": "与中心平均锚点距离排序的方法简单的舍弃掉最远的一个正样本不参与到损失",
      "page": 39
    },
    {
      "level": "H1",
      "text": "计算。",
      "page": 39
    },
    {
      "level": "H1",
      "text": "N+M",
      "page": 39
    },
    {
      "level": "H1",
      "text": "元组簇损失",
      "page": 39
    },
    {
      "level": "H1",
      "text": "௜ୀଵ",
      "page": 39
    },
    {
      "level": "H1",
      "text": "௝ୀଵ",
      "page": 39
    },
    {
      "level": "H1",
      "text": "; 𝑓",
      "page": 39
    },
    {
      "level": "H1",
      "text": "可以表示为：",
      "page": 39
    },
    {
      "level": "H1",
      "text": "୫ୟ୶",
      "page": 39
    },
    {
      "level": "H1",
      "text": "்ାఛ",
      "page": 39
    },
    {
      "level": "H1",
      "text": "ଶି஽",
      "page": 39
    },
    {
      "level": "H1",
      "text": ")))",
      "page": 39
    },
    {
      "level": "H1",
      "text": "ೕసభ",
      "page": 39
    },
    {
      "level": "H1",
      "text": "(2.3)",
      "page": 39
    },
    {
      "level": "H1",
      "text": "2.1",
      "page": 39
    },
    {
      "level": "H1",
      "text": "给出了",
      "page": 39
    },
    {
      "level": "H1",
      "text": "元组簇损失的具体计算流程。通过在线挖掘留下",
      "page": 39
    },
    {
      "level": "H1",
      "text": "正样本，并使用",
      "page": 39
    },
    {
      "level": "H1",
      "text": "个样本计算",
      "page": 39
    },
    {
      "level": "H1",
      "text": "2.3",
      "page": 39
    },
    {
      "level": "H1",
      "text": "）给出了特征平面样本间关系的简",
      "page": 39
    },
    {
      "level": "H1",
      "text": "化的几何描述。仅当在线挖掘的正样本距离更新后的正样本中心",
      "page": 39
    },
    {
      "level": "H1",
      "text": "也即锚点距离",
      "page": 39
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 40
    },
    {
      "level": "H1",
      "text": "𝑇−𝜏/2",
      "page": 40
    },
    {
      "level": "H1",
      "text": "，同时满足利用身份信息挖掘的负样本与",
      "page": 40
    },
    {
      "level": "H1",
      "text": "距离均远于",
      "page": 40
    },
    {
      "level": "H1",
      "text": "𝑇+ 𝜏/2",
      "page": 40
    },
    {
      "level": "H1",
      "text": "失函数才为零。",
      "page": 40
    },
    {
      "level": "H1",
      "text": "对于一个由",
      "page": 40
    },
    {
      "level": "H1",
      "text": "个查询样本组成的训练批次（",
      "page": 40
    },
    {
      "level": "H1",
      "text": "Batch",
      "page": 40
    },
    {
      "level": "H1",
      "text": "元组簇损失仅需",
      "page": 40
    },
    {
      "level": "H1",
      "text": "次损失计算即可使得每个查询样本均远离其他类别并与同类别样本相近。",
      "page": 40
    },
    {
      "level": "H1",
      "text": "在每次损失计算中，",
      "page": 40
    },
    {
      "level": "H1",
      "text": "元组簇损失需要进行约",
      "page": 40
    },
    {
      "level": "H1",
      "text": "2(𝑁+ 𝑀)",
      "page": 40
    },
    {
      "level": "H1",
      "text": "次相似度计算，因而",
      "page": 40
    },
    {
      "level": "H1",
      "text": "遍历整个批次需要",
      "page": 40
    },
    {
      "level": "H1",
      "text": "2(𝑁+ 𝑀) ∗𝑋",
      "page": 40
    },
    {
      "level": "H1",
      "text": "次相似度计算。通常而言，",
      "page": 40
    },
    {
      "level": "H1",
      "text": "的值远小于",
      "page": 40
    },
    {
      "level": "H1",
      "text": "。而传统的三元组损失需要",
      "page": 40
    },
    {
      "level": "H1",
      "text": "种组合以及",
      "page": 40
    },
    {
      "level": "H1",
      "text": "次相似度计算",
      "page": 40
    },
    {
      "level": "H1",
      "text": "+1)",
      "page": 40
    },
    {
      "level": "H1",
      "text": "元组损失",
      "page": 40
    },
    {
      "level": "H1",
      "text": "则需要",
      "page": 40
    },
    {
      "level": "H1",
      "text": "(𝑋+ 1) ∗𝑋",
      "page": 40
    },
    {
      "level": "H1",
      "text": "次损失计以及共计",
      "page": 40
    },
    {
      "level": "H1",
      "text": "次相似度计算。即便对于一个",
      "page": 40
    },
    {
      "level": "H1",
      "text": "较小的数据库或采用较小的训练批次，传统度量学习中需要",
      "page": 40
    },
    {
      "level": "H1",
      "text": "的平方次采样及",
      "page": 40
    },
    {
      "level": "H1",
      "text": "损失计算都具有极大的计算量，通常都无法做到将三元组损失中的",
      "page": 40
    },
    {
      "level": "H1",
      "text": "种组合全部",
      "page": 40
    },
    {
      "level": "H1",
      "text": "遍历一遍。这就导致了很多有学习意义和难度的组合可能不会被随机抽取到。相",
      "page": 40
    },
    {
      "level": "H1",
      "text": "较之下，",
      "page": 40
    },
    {
      "level": "H1",
      "text": "元组簇损失能更有效率的利用样本。",
      "page": 40
    },
    {
      "level": "H1",
      "text": "2.2.2",
      "page": 40
    },
    {
      "level": "H1",
      "text": "自适应深度度量学习",
      "page": 40
    },
    {
      "level": "H1",
      "text": "通过对超参数",
      "page": 40
    },
    {
      "level": "H1",
      "text": "的赋值，可以灵活地调整",
      "page": 40
    },
    {
      "level": "H1",
      "text": "元组簇损失的严格程度",
      "page": 40
    },
    {
      "level": "H1",
      "text": "而适应不同的数据库。然而，通常需要人为手动调整超参数的值并观察其对验证",
      "page": 40
    },
    {
      "level": "H1",
      "text": "集识别精度的影响。为了减轻调整参数的工作量，本小节提出一种自适应调整超",
      "page": 40
    },
    {
      "level": "H1",
      "text": "2.1",
      "page": 40
    },
    {
      "level": "H1",
      "text": "在线正样本挖掘（",
      "page": 40
    },
    {
      "level": "H1",
      "text": "Online positive mining",
      "page": 40
    },
    {
      "level": "H1",
      "text": "查询样本及其随机选取的正样本集",
      "page": 40
    },
    {
      "level": "H1",
      "text": "௜ୀଵ",
      "page": 40
    },
    {
      "level": "H1",
      "text": "，和负样本集",
      "page": 40
    },
    {
      "level": "H1",
      "text": "௝ୀଵ",
      "page": 40
    },
    {
      "level": "H1",
      "text": "CNN",
      "page": 40
    },
    {
      "level": "H1",
      "text": "将样本映射到特征空间得到其向量",
      "page": 40
    },
    {
      "level": "H1",
      "text": "计算正样本簇的中心",
      "page": 40
    },
    {
      "level": "H1",
      "text": "计算从",
      "page": 40
    },
    {
      "level": "H1",
      "text": "到每个正样本和负样本的距离",
      "page": 40
    },
    {
      "level": "H1",
      "text": "寻找最小的负样本距离",
      "page": 40
    },
    {
      "level": "H1",
      "text": "𝐷 (𝑥",
      "page": 40
    },
    {
      "level": "H1",
      "text": "௡௘௔௥௦௧",
      "page": 40
    },
    {
      "level": "H1",
      "text": "忽略掉满足",
      "page": 40
    },
    {
      "level": "H1",
      "text": "条件的正样本，留下",
      "page": 40
    },
    {
      "level": "H1",
      "text": "个正样本",
      "page": 40
    },
    {
      "level": "H1",
      "text": "更新正样本簇的中心",
      "page": 40
    },
    {
      "level": "H1",
      "text": "在线挖掘到的",
      "page": 40
    },
    {
      "level": "H1",
      "text": "个正样本以及更新后的",
      "page": 40
    },
    {
      "level": "H1",
      "text": "基于深度度量学习的身份感知人脸表情识别",
      "page": 41
    },
    {
      "level": "H1",
      "text": "的方法。",
      "page": 41
    },
    {
      "level": "H1",
      "text": "受到基于支持向量机的自适应尺度学习",
      "page": 41
    },
    {
      "level": "H1",
      "text": "[87]",
      "page": 41
    },
    {
      "level": "H1",
      "text": "的启发，将",
      "page": 41
    },
    {
      "level": "H1",
      "text": "定义为一个关于一",
      "page": 41
    },
    {
      "level": "H1",
      "text": "个样本与中心锚点间的距离函数",
      "page": 41
    },
    {
      "level": "H1",
      "text": "(·,·)",
      "page": 41
    },
    {
      "level": "H1",
      "text": "而非一个常量。由于马氏距离矩阵",
      "page": 41
    },
    {
      "level": "H1",
      "text": "次型矩阵可以由线性全连接层自动计算，假设",
      "page": 41
    },
    {
      "level": "H1",
      "text": "为一个简单的二次型，即",
      "page": 41
    },
    {
      "level": "H1",
      "text": "𝐐𝑧+ 𝜔",
      "page": 41
    },
    {
      "level": "H1",
      "text": "z + 𝑏",
      "page": 41
    },
    {
      "level": "H1",
      "text": "(2.4)",
      "page": 41
    },
    {
      "level": "H1",
      "text": "𝑏∈ℝ",
      "page": 41
    },
    {
      "level": "H1",
      "text": "and",
      "page": 41
    },
    {
      "level": "H1",
      "text": "为两个特征向量。",
      "page": 41
    },
    {
      "level": "H1",
      "text": "||𝑓",
      "page": 41
    },
    {
      "level": "H1",
      "text": "= (𝑓",
      "page": 41
    },
    {
      "level": "H1",
      "text": "𝐌(𝑓",
      "page": 41
    },
    {
      "level": "H1",
      "text": "(2.5)",
      "page": 41
    },
    {
      "level": "H1",
      "text": "由于距离函数关于",
      "page": 41
    },
    {
      "level": "H1",
      "text": "为对称关系",
      "page": 41
    },
    {
      "level": "H1",
      "text": "可以改写",
      "page": 41
    },
    {
      "level": "H1",
      "text": "𝑛+ 𝑓",
      "page": 41
    },
    {
      "level": "H1",
      "text": "+ 𝑐",
      "page": 41
    },
    {
      "level": "H1",
      "text": "+ 𝑓",
      "page": 41
    },
    {
      "level": "H1",
      "text": ") + 𝑏",
      "page": 41
    },
    {
      "level": "H1",
      "text": "(2.6)",
      "page": 41
    },
    {
      "level": "H1",
      "text": "𝑑× 𝑑",
      "page": 41
    },
    {
      "level": "H1",
      "text": "大小的实对称矩阵（但非",
      "page": 41
    },
    {
      "level": "H1",
      "text": "必须为半正定矩阵），",
      "page": 41
    },
    {
      "level": "H1",
      "text": "为一个",
      "page": 41
    },
    {
      "level": "H1",
      "text": "维向量",
      "page": 41
    },
    {
      "level": "H1",
      "text": "bias",
      "page": 41
    },
    {
      "level": "H1",
      "text": "项。接下来定义一",
      "page": 41
    },
    {
      "level": "H1",
      "text": "个新的二次型",
      "page": 41
    },
    {
      "level": "H1",
      "text": ") −",
      "page": 41
    },
    {
      "level": "H1",
      "text": "用于结合参考距离和距离度量方程。将",
      "page": 41
    },
    {
      "level": "H1",
      "text": "2.4",
      "page": 41
    },
    {
      "level": "H1",
      "text": "和公式",
      "page": 41
    },
    {
      "level": "H1",
      "text": "2.5",
      "page": 41
    },
    {
      "level": "H1",
      "text": "−2𝐌)𝑓",
      "page": 41
    },
    {
      "level": "H1",
      "text": "+ 2𝐌)𝑓",
      "page": 41
    },
    {
      "level": "H1",
      "text": "(2.7)",
      "page": 41
    },
    {
      "level": "H1",
      "text": "(2.8)",
      "page": 41
    },
    {
      "level": "H1",
      "text": "−2𝐌",
      "page": 41
    },
    {
      "level": "H1",
      "text": "+ 2𝐌",
      "page": 41
    },
    {
      "level": "H1",
      "text": "为半正定",
      "page": 41
    },
    {
      "level": "H1",
      "text": "(positive semi-definite",
      "page": 41
    },
    {
      "level": "H1",
      "text": "PSD)",
      "page": 41
    },
    {
      "level": "H1",
      "text": "矩阵，",
      "page": 41
    },
    {
      "level": "H1",
      "text": "为半负定矩阵",
      "page": 41
    },
    {
      "level": "H1",
      "text": "(negative semi-definite",
      "page": 41
    },
    {
      "level": "H1",
      "text": "NSD),",
      "page": 41
    },
    {
      "level": "H1",
      "text": "可以被分解为",
      "page": 41
    },
    {
      "level": "H1",
      "text": "。因而",
      "page": 41
    },
    {
      "level": "H1",
      "text": "可以被表达为",
      "page": 41
    },
    {
      "level": "H1",
      "text": ") +",
      "page": 41
    },
    {
      "level": "H1",
      "text": ") + (𝐋",
      "page": 41
    },
    {
      "level": "H1",
      "text": ") + 𝑐",
      "page": 41
    },
    {
      "level": "H1",
      "text": "+ 𝑏",
      "page": 41
    },
    {
      "level": "H1",
      "text": "(2.9)",
      "page": 41
    },
    {
      "level": "H1",
      "text": "基于以上推导，可以定义一种可自适应计算距离超参数的损失函数。延续以",
      "page": 41
    },
    {
      "level": "H1",
      "text": "上的符号表达，并将",
      "page": 41
    },
    {
      "level": "H1",
      "text": ", 𝐋",
      "page": 41
    },
    {
      "level": "H1",
      "text": ", 𝑐)",
      "page": 41
    },
    {
      "level": "H1",
      "text": "表达为",
      "page": 41
    },
    {
      "level": "H1",
      "text": "可以得到",
      "page": 41
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 42
    },
    {
      "level": "H1",
      "text": "𝐿(𝑊, {𝑥",
      "page": 42
    },
    {
      "level": "H1",
      "text": "௜ୀଵ",
      "page": 42
    },
    {
      "level": "H1",
      "text": "௝ୀଵ",
      "page": 42
    },
    {
      "level": "H1",
      "text": "; 𝑓) =",
      "page": 42
    },
    {
      "level": "H1",
      "text": "max(0,",
      "page": 42
    },
    {
      "level": "H1",
      "text": ") +",
      "page": 42
    },
    {
      "level": "H1",
      "text": "max(0, 𝐻(𝑓",
      "page": 42
    },
    {
      "level": "H1",
      "text": ", 𝑐",
      "page": 42
    },
    {
      "level": "H1",
      "text": "(2.10)",
      "page": 42
    },
    {
      "level": "H1",
      "text": "给定在一个小训练批次（",
      "page": 42
    },
    {
      "level": "H1",
      "text": "mini-batch",
      "page": 42
    },
    {
      "level": "H1",
      "text": "）中挖掘到的",
      "page": 42
    },
    {
      "level": "H1",
      "text": "N+M*",
      "page": 42
    },
    {
      "level": "H1",
      "text": "训练样本",
      "page": 42
    },
    {
      "level": "H1",
      "text": "𝑙(·)",
      "page": 42
    },
    {
      "level": "H1",
      "text": "个指标函数。如果样本",
      "page": 42
    },
    {
      "level": "H1",
      "text": "是来自于正集",
      "page": 42
    },
    {
      "level": "H1",
      "text": "𝑙(𝑥",
      "page": 42
    },
    {
      "level": "H1",
      "text": ") = −1",
      "page": 42
    },
    {
      "level": "H1",
      "text": ") =",
      "page": 42
    },
    {
      "level": "H1",
      "text": "简化为常数",
      "page": 42
    },
    {
      "level": "H1",
      "text": "而将其改变为任意其他正数值仅需要将矩阵除以相应的倍数",
      "page": 42
    },
    {
      "level": "H1",
      "text": "即可保持相对距离比例，而这可以由网络自动习得。因此损失函数可写为：",
      "page": 42
    },
    {
      "level": "H1",
      "text": "ேାெ",
      "page": 42
    },
    {
      "level": "H1",
      "text": "max(0, 𝑙(𝑥",
      "page": 42
    },
    {
      "level": "H1",
      "text": "(2.11)",
      "page": 42
    },
    {
      "level": "H1",
      "text": "对公式",
      "page": 42
    },
    {
      "level": "H1",
      "text": "2.11",
      "page": 42
    },
    {
      "level": "H1",
      "text": "使用具有动量的随机梯度下降（",
      "page": 42
    },
    {
      "level": "H1",
      "text": "stochastic gradient descent with",
      "page": 42
    },
    {
      "level": "H1",
      "text": "momentum",
      "page": 42
    },
    {
      "level": "H1",
      "text": "）。对每个样本的偏导为：",
      "page": 42
    },
    {
      "level": "H1",
      "text": "୒ା୑",
      "page": 42
    },
    {
      "level": "H1",
      "text": "(2.12)",
      "page": 42
    },
    {
      "level": "H1",
      "text": "ౢశభ",
      "page": 42
    },
    {
      "level": "H1",
      "text": "(2.13)",
      "page": 42
    },
    {
      "level": "H1",
      "text": "表示为样本",
      "page": 42
    },
    {
      "level": "H1",
      "text": "层的特征图。总的梯度为各样本梯度值的和。",
      "page": 42
    },
    {
      "level": "H1",
      "text": "2.4",
      "page": 42
    },
    {
      "level": "H1",
      "text": "网络结构图。在测试阶段仅使用卷积部分与表情分类分支，并用",
      "page": 42
    },
    {
      "level": "H1",
      "text": "softmax",
      "page": 42
    },
    {
      "level": "H1",
      "text": "函数的输",
      "page": 42
    },
    {
      "level": "H1",
      "text": "出值确定预测类别。",
      "page": 42
    },
    {
      "level": "H1",
      "text": "Figure 2.4 The proposed network structure. In the testing phase, only the convolutional",
      "page": 42
    },
    {
      "level": "H1",
      "text": "groups and expression classification branch with softmax are used to recognize a single facial",
      "page": 42
    },
    {
      "level": "H1",
      "text": "expression image.",
      "page": 42
    },
    {
      "level": "H1",
      "text": "2.2.3",
      "page": 42
    },
    {
      "level": "H1",
      "text": "双分支联合优化网络",
      "page": 42
    },
    {
      "level": "H1",
      "text": "为了结合传统的基于",
      "page": 42
    },
    {
      "level": "H1",
      "text": "的交叉熵损失和",
      "page": 42
    },
    {
      "level": "H1",
      "text": "元组簇损失，本小节提",
      "page": 42
    },
    {
      "level": "H1",
      "text": "出一种双分支网络",
      "page": 42
    },
    {
      "level": "H1",
      "text": "2B(",
      "page": 42
    },
    {
      "level": "H1",
      "text": "N+M",
      "page": 42
    },
    {
      "level": "H1",
      "text": ")Softmax",
      "page": 42
    },
    {
      "level": "H1",
      "text": "。其具体结构如图",
      "page": 42
    },
    {
      "level": "H1",
      "text": "所示。其卷积层部分",
      "page": 42
    },
    {
      "level": "H1",
      "text": "Inception FER",
      "page": 42
    },
    {
      "level": "H1",
      "text": "[95]",
      "page": 42
    },
    {
      "level": "H1",
      "text": "。先前研究表明",
      "page": 42
    },
    {
      "level": "H1",
      "text": "Inception",
      "page": 42
    },
    {
      "level": "H1",
      "text": "网络结构有助于对局部特征",
      "page": 42
    },
    {
      "level": "H1",
      "text": "基于深度度量学习的身份感知人脸表情识别",
      "page": 43
    },
    {
      "level": "H1",
      "text": "的提取",
      "page": 43
    },
    {
      "level": "H1",
      "text": "[96]",
      "page": 43
    },
    {
      "level": "H1",
      "text": "。小尺寸的卷积会覆盖较小的区域，而表情变化相关的肌肉运动也往往",
      "page": 43
    },
    {
      "level": "H1",
      "text": "只涉及到小范围区域。鉴于本研究的主要目的在与探究",
      "page": 43
    },
    {
      "level": "H1",
      "text": "元组簇损失对人脸",
      "page": 43
    },
    {
      "level": "H1",
      "text": "表情识别的性能提升，并未对网络结构的层数超参数进行仔细调整。",
      "page": 43
    },
    {
      "level": "H1",
      "text": "直接将基于",
      "page": 43
    },
    {
      "level": "H1",
      "text": "softmax",
      "page": 43
    },
    {
      "level": "H1",
      "text": "的交叉熵损失和",
      "page": 43
    },
    {
      "level": "H1",
      "text": "元组簇损失相加是一种直观的结",
      "page": 43
    },
    {
      "level": "H1",
      "text": "合方法。然而，考虑到两种损失的关注点以及计算难度的不同，同时在一个全连",
      "page": 43
    },
    {
      "level": "H1",
      "text": "接层输出处计算二者的损失值往往不是最优的选择。",
      "page": 43
    },
    {
      "level": "H1",
      "text": "2.3",
      "page": 43
    },
    {
      "level": "H1",
      "text": "正为了评估所提出的方法的有效性，在三个公开的主流人脸面部表情数据库",
      "page": 43
    },
    {
      "level": "H1",
      "text": "上进行了实验分析。",
      "page": 43
    },
    {
      "level": "H1",
      "text": "2.3.1",
      "page": 43
    },
    {
      "level": "H1",
      "text": "预处理及训练流程",
      "page": 43
    },
    {
      "level": "H1",
      "text": "对于数据库中的原始图像，面部注册是获得良好性能的关键步骤。采用双向",
      "page": 43
    },
    {
      "level": "H1",
      "text": "扭曲的主动外观模型（",
      "page": 43
    },
    {
      "level": "H1",
      "text": "Active Appearance Model, AAM",
      "page": 43
    },
    {
      "level": "H1",
      "text": "[22]",
      "page": 43
    },
    {
      "level": "H1",
      "text": "的和一种称为",
      "page": 43
    },
    {
      "level": "H1",
      "text": "IntraFace",
      "page": 43
    },
    {
      "level": "H1",
      "text": "模型的监督下降法（",
      "page": 43
    },
    {
      "level": "H1",
      "text": "Supervised Descent Method, SDM",
      "page": 43
    },
    {
      "level": "H1",
      "text": "[100]",
      "page": 43
    },
    {
      "level": "H1",
      "text": "来定位",
      "page": 43
    },
    {
      "level": "H1",
      "text": "个面部标志。",
      "page": 43
    },
    {
      "level": "H1",
      "text": "然后，进行面部配准",
      "page": 43
    },
    {
      "level": "H1",
      "text": "(face alignment)",
      "page": 43
    },
    {
      "level": "H1",
      "text": "以减少面内旋转并基于这些界标的坐标将感",
      "page": 43
    },
    {
      "level": "H1",
      "text": "兴趣区域裁剪为",
      "page": 43
    },
    {
      "level": "H1",
      "text": "的尺寸。人脸面部表情识别数据集的有限图像是深度模",
      "page": 43
    },
    {
      "level": "H1",
      "text": "型在应用时的瓶颈。因此，采用数据增强来增加训练数据的量是十分有必要的操",
      "page": 43
    },
    {
      "level": "H1",
      "text": "作步骤。在图片中心和四个角处裁剪",
      "page": 43
    },
    {
      "level": "H1",
      "text": "大小的图像块，水平翻转它们",
      "page": 43
    },
    {
      "level": "H1",
      "text": "并将它们转换为灰度图像。这样将获得",
      "page": 43
    },
    {
      "level": "H1",
      "text": "倍的训练图片。使用标准直方图均衡",
      "page": 43
    },
    {
      "level": "H1",
      "text": "和线性平面拟合处理所有图像以去除不平衡照明。最后，将它们归一化为零均值",
      "page": 43
    },
    {
      "level": "H1",
      "text": "和单位方差向量。在测试阶段，使用单个尺寸为",
      "page": 43
    },
    {
      "level": "H1",
      "text": "像素的中心切块作为输",
      "page": 43
    },
    {
      "level": "H1",
      "text": "入数据。",
      "page": 43
    },
    {
      "level": "H1",
      "text": "[95],[101]",
      "page": 43
    },
    {
      "level": "H1",
      "text": "中的实验方案，在",
      "page": 43
    },
    {
      "level": "H1",
      "text": "FER2013",
      "page": 43
    },
    {
      "level": "H1",
      "text": "数据库",
      "page": 43
    },
    {
      "level": "H1",
      "text": "[88]",
      "page": 43
    },
    {
      "level": "H1",
      "text": "上预先训练卷积层和",
      "page": 43
    },
    {
      "level": "H1",
      "text": "支的全连接层",
      "page": 43
    },
    {
      "level": "H1",
      "text": "300",
      "page": 43
    },
    {
      "level": "H1",
      "text": "个周期，使用动量为",
      "page": 43
    },
    {
      "level": "H1",
      "text": "0.9",
      "page": 43
    },
    {
      "level": "H1",
      "text": "的随机梯度下降优化基于",
      "page": 43
    },
    {
      "level": "H1",
      "text": "交叉熵损失。初始网络学习速率、批的大小和权重衰减参数分别设置为",
      "page": 43
    },
    {
      "level": "H1",
      "text": "0.1",
      "page": 43
    },
    {
      "level": "H1",
      "text": "128",
      "page": 43
    },
    {
      "level": "H1",
      "text": "0.0001",
      "page": 43
    },
    {
      "level": "H1",
      "text": "。如果训练损失函数的值增加超过",
      "page": 43
    },
    {
      "level": "H1",
      "text": "％或者验证集准确度在十个周期",
      "page": 43
    },
    {
      "level": "H1",
      "text": "内没有改善，则学习率减半并且重新加载先前具有最佳损失的网络。然后添加",
      "page": 43
    },
    {
      "level": "H1",
      "text": "分支，并且通过从",
      "page": 43
    },
    {
      "level": "H1",
      "text": "CMU Multi-pie",
      "page": 43
    },
    {
      "level": "H1",
      "text": "数据集中选择的",
      "page": 43
    },
    {
      "level": "H1",
      "text": "204156",
      "page": 43
    },
    {
      "level": "H1",
      "text": "个正面视点",
      "page": 43
    },
    {
      "level": "H1",
      "text": "(-45",
      "page": 43
    },
    {
      "level": "H1",
      "text": "面部图像来训练整个网络。",
      "page": 43
    },
    {
      "level": "H1",
      "text": "[102]",
      "page": 43
    },
    {
      "level": "H1",
      "text": "337",
      "page": 43
    },
    {
      "level": "H1",
      "text": "人表现出厌恶，快",
      "page": 43
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 44
    },
    {
      "level": "H1",
      "text": "乐，惊喜和中性四种表情类别。正负集的大小均固定为",
      "page": 44
    },
    {
      "level": "H1",
      "text": "个图像。两个损失函数",
      "page": 44
    },
    {
      "level": "H1",
      "text": "的权重设置为相同选择最高验证集精度的训练周期的模型作为预训练的模型。",
      "page": 44
    },
    {
      "level": "H1",
      "text": "在微调（",
      "page": 44
    },
    {
      "level": "H1",
      "text": "fine-tuning",
      "page": 44
    },
    {
      "level": "H1",
      "text": "）阶段，正负集大小设置为固定的",
      "page": 44
    },
    {
      "level": "H1",
      "text": "个图像（对于",
      "page": 44
    },
    {
      "level": "H1",
      "text": "CK +",
      "page": 44
    },
    {
      "level": "H1",
      "text": "SFEW",
      "page": 44
    },
    {
      "level": "H1",
      "text": "MMI",
      "page": 44
    },
    {
      "level": "H1",
      "text": "）。对于查询样本",
      "page": 44
    },
    {
      "level": "H1",
      "text": "(query example)",
      "page": 44
    },
    {
      "level": "H1",
      "text": "，我们采用",
      "page": 44
    },
    {
      "level": "H1",
      "text": "随机搜索来选择其他",
      "page": 44
    },
    {
      "level": "H1",
      "text": "）个相同表情的图像以形成正集。在本章所提出的",
      "page": 44
    },
    {
      "level": "H1",
      "text": "方法中，负样本挖掘将要利用到身份标签。",
      "page": 44
    },
    {
      "level": "H1",
      "text": "具有被拍摄者的身份标",
      "page": 44
    },
    {
      "level": "H1",
      "text": "签，而",
      "page": 44
    },
    {
      "level": "H1",
      "text": "需要手动标记。实际上，可以使用现成的面部识别算法来自动的标",
      "page": 44
    },
    {
      "level": "H1",
      "text": "记该信息。我们采用已经在数十万张人脸身份识别数据库上训练好的",
      "page": 44
    },
    {
      "level": "H1",
      "text": "DeepID",
      "page": 44
    },
    {
      "level": "H1",
      "text": "型来进行人脸识别。当查询样本缺少来自相同",
      "page": 44
    },
    {
      "level": "H1",
      "text": "的一些表情图像时，使用与任",
      "page": 44
    },
    {
      "level": "H1",
      "text": "何其他正例共享相同",
      "page": 44
    },
    {
      "level": "H1",
      "text": "的相应表情图像。在每次训练迭代中输入",
      "page": 44
    },
    {
      "level": "H1",
      "text": "6 + 6",
      "page": 44
    },
    {
      "level": "H1",
      "text": "= 144",
      "page": 44
    },
    {
      "level": "H1",
      "text": "5 + 5",
      "page": 44
    },
    {
      "level": "H1",
      "text": "= 120",
      "page": 44
    },
    {
      "level": "H1",
      "text": "）个图像。使用",
      "page": 44
    },
    {
      "level": "H1",
      "text": "Adam",
      "page": 44
    },
    {
      "level": "H1",
      "text": "[136]",
      "page": 44
    },
    {
      "level": "H1",
      "text": "进行随机优化，并通过交",
      "page": 44
    },
    {
      "level": "H1",
      "text": "叉验证相应地调整其他超参数，例如学习率。",
      "page": 44
    },
    {
      "level": "H1",
      "text": "2.1",
      "page": 44
    },
    {
      "level": "H1",
      "text": "CK+",
      "page": 44
    },
    {
      "level": "H1",
      "text": "数据库上的",
      "page": 44
    },
    {
      "level": "H1",
      "text": "折平均的混淆矩阵",
      "page": 44
    },
    {
      "level": "H1",
      "text": "Table 2.1 Average confusion matrix obtained from proposed method on the CK+.",
      "page": 44
    },
    {
      "level": "H1",
      "text": "Predict",
      "page": 44
    },
    {
      "level": "H1",
      "text": "91.1%",
      "page": 44
    },
    {
      "level": "H1",
      "text": "1.1%",
      "page": 44
    },
    {
      "level": "H1",
      "text": "7.8%",
      "page": 44
    },
    {
      "level": "H1",
      "text": "5.6%",
      "page": 44
    },
    {
      "level": "H1",
      "text": "90.3%",
      "page": 44
    },
    {
      "level": "H1",
      "text": "2.7%",
      "page": 44
    },
    {
      "level": "H1",
      "text": "100%",
      "page": 44
    },
    {
      "level": "H1",
      "text": "98%",
      "page": 44
    },
    {
      "level": "H1",
      "text": "3.6%",
      "page": 44
    },
    {
      "level": "H1",
      "text": "1.8%",
      "page": 44
    },
    {
      "level": "H1",
      "text": "94.6%",
      "page": 44
    },
    {
      "level": "H1",
      "text": "1.2%",
      "page": 44
    },
    {
      "level": "H1",
      "text": "98.8%",
      "page": 44
    },
    {
      "level": "H1",
      "text": "2.3.2",
      "page": 44
    },
    {
      "level": "H1",
      "text": "实验结果",
      "page": 44
    },
    {
      "level": "H1",
      "text": "首先是扩展的",
      "page": 44
    },
    {
      "level": "H1",
      "text": "Cohn-Kanade",
      "page": 44
    },
    {
      "level": "H1",
      "text": "数据库",
      "page": 44
    },
    {
      "level": "H1",
      "text": "(CK+)",
      "page": 44
    },
    {
      "level": "H1",
      "text": "[97]",
      "page": 44
    },
    {
      "level": "H1",
      "text": "。它包括从",
      "page": 44
    },
    {
      "level": "H1",
      "text": "118",
      "page": 44
    },
    {
      "level": "H1",
      "text": "个受试者收集的",
      "page": 44
    },
    {
      "level": "H1",
      "text": "327",
      "page": 44
    },
    {
      "level": "H1",
      "text": "个序列，范围囊括",
      "page": 44
    },
    {
      "level": "H1",
      "text": "种不同的表情（即愤怒，蔑视，厌恶，恐惧，快乐，悲",
      "page": 44
    },
    {
      "level": "H1",
      "text": "伤和惊讶）。视频由中性表情逐渐扩展为",
      "page": 44
    },
    {
      "level": "H1",
      "text": "种表情之一，且最后一帧的表情强度",
      "page": 44
    },
    {
      "level": "H1",
      "text": "最大为整个视频的峰值帧。库中的标签仅提供给每个序列的最后一帧（峰值帧）。",
      "page": 44
    },
    {
      "level": "H1",
      "text": "Actual",
      "page": 44
    },
    {
      "level": "H1",
      "text": "基于深度度量学习的身份感知人脸表情识别",
      "page": 45
    },
    {
      "level": "H1",
      "text": "选择最后三张图像并标记为与最后一帧同样的表情，并获得",
      "page": 45
    },
    {
      "level": "H1",
      "text": "921",
      "page": 45
    },
    {
      "level": "H1",
      "text": "张图像（无中性",
      "page": 45
    },
    {
      "level": "H1",
      "text": "表情）。通过选择具有三个图像的最高可能性的类来进行最终的序列级预测。采",
      "page": 45
    },
    {
      "level": "H1",
      "text": "用严格的个体独立方式将",
      "page": 45
    },
    {
      "level": "H1",
      "text": "CK+",
      "page": 45
    },
    {
      "level": "H1",
      "text": "数据库分成",
      "page": 45
    },
    {
      "level": "H1",
      "text": "个子集，并采用",
      "page": 45
    },
    {
      "level": "H1",
      "text": "折交叉验证。每",
      "page": 45
    },
    {
      "level": "H1",
      "text": "个人脸",
      "page": 45
    },
    {
      "level": "H1",
      "text": "不存在于其他的子集中。采用",
      "page": 45
    },
    {
      "level": "H1",
      "text": "个子集的数据用于训练，其他两个子",
      "page": 45
    },
    {
      "level": "H1",
      "text": "集用于验证和测试，并迭代测试。",
      "page": 45
    },
    {
      "level": "H1",
      "text": "混淆矩阵是多类别分类的一种常用测试标准。矩阵的第",
      "page": 45
    },
    {
      "level": "H1",
      "text": "列元素的值",
      "page": 45
    },
    {
      "level": "H1",
      "text": "表示实际类别为",
      "page": 45
    },
    {
      "level": "H1",
      "text": "的所有图片，被识别系统分类为第",
      "page": 45
    },
    {
      "level": "H1",
      "text": "类的比例。",
      "page": 45
    },
    {
      "level": "H1",
      "text": "2.1",
      "page": 45
    },
    {
      "level": "H1",
      "text": "中报告了在",
      "page": 45
    },
    {
      "level": "H1",
      "text": "CK +",
      "page": 45
    },
    {
      "level": "H1",
      "text": "数据集上评估的所提出方法的混淆矩阵。可以观察",
      "page": 45
    },
    {
      "level": "H1",
      "text": "到厌恶和快乐表情被完全正确的识别，而蔑视表情对于网络来说相对较难，因为",
      "page": 45
    },
    {
      "level": "H1",
      "text": "训练实例数量有限且涉及到的肌肉变化通常很细微。如表",
      "page": 45
    },
    {
      "level": "H1",
      "text": "2.2",
      "page": 45
    },
    {
      "level": "H1",
      "text": "所示，本章所提出",
      "page": 45
    },
    {
      "level": "H1",
      "text": "N+M",
      "page": 45
    },
    {
      "level": "H1",
      "text": "Softmax",
      "page": 45
    },
    {
      "level": "H1",
      "text": "优于手工设计的特征提取的方法，基于稀疏编码的方法",
      "page": 45
    },
    {
      "level": "H1",
      "text": "和其他深度学习方法。其中，",
      "page": 45
    },
    {
      "level": "H1",
      "text": "3DCNN-DAP",
      "page": 45
    },
    {
      "level": "H1",
      "text": "STM-Explet",
      "page": 45
    },
    {
      "level": "H1",
      "text": "DTAGN",
      "page": 45
    },
    {
      "level": "H1",
      "text": "利用从序列",
      "page": 45
    },
    {
      "level": "H1",
      "text": "中提取的时间信息。它也大幅度的胜过基线方法，显然受益于新颖的深度度量学",
      "page": 45
    },
    {
      "level": "H1",
      "text": "习损失和双分支架构的结合。",
      "page": 45
    },
    {
      "level": "H1",
      "text": "MMI",
      "page": 45
    },
    {
      "level": "H1",
      "text": "数据库上的混淆矩阵",
      "page": 45
    },
    {
      "level": "H1",
      "text": "Table 2.2 Average confusion matrix obtained from proposed method on the CK+ and MMI",
      "page": 45
    },
    {
      "level": "H1",
      "text": "datasets.",
      "page": 45
    },
    {
      "level": "H1",
      "text": "Methods",
      "page": 45
    },
    {
      "level": "H1",
      "text": "MSR",
      "page": 45
    },
    {
      "level": "H1",
      "text": "[104]",
      "page": 45
    },
    {
      "level": "H1",
      "text": "91.4%",
      "page": 45
    },
    {
      "level": "H1",
      "text": "N/A",
      "page": 45
    },
    {
      "level": "H1",
      "text": "ITBN",
      "page": 45
    },
    {
      "level": "H1",
      "text": "[105]",
      "page": 45
    },
    {
      "level": "H1",
      "text": "91.44%",
      "page": 45
    },
    {
      "level": "H1",
      "text": "59.7%",
      "page": 45
    },
    {
      "level": "H1",
      "text": "BNBN",
      "page": 45
    },
    {
      "level": "H1",
      "text": "[106]",
      "page": 45
    },
    {
      "level": "H1",
      "text": "96.7%",
      "page": 45
    },
    {
      "level": "H1",
      "text": "IB-CNN",
      "page": 45
    },
    {
      "level": "H1",
      "text": "[107]",
      "page": 45
    },
    {
      "level": "H1",
      "text": "95.1%",
      "page": 45
    },
    {
      "level": "H1",
      "text": "[108]",
      "page": 45
    },
    {
      "level": "H1",
      "text": "92.4%",
      "page": 45
    },
    {
      "level": "H1",
      "text": "63.4%",
      "page": 45
    },
    {
      "level": "H1",
      "text": "[109]",
      "page": 45
    },
    {
      "level": "H1",
      "text": "94.19%",
      "page": 45
    },
    {
      "level": "H1",
      "text": "75.12%",
      "page": 45
    },
    {
      "level": "H1",
      "text": "[110]",
      "page": 45
    },
    {
      "level": "H1",
      "text": "97.25%",
      "page": 45
    },
    {
      "level": "H1",
      "text": "70.2%",
      "page": 45
    },
    {
      "level": "H1",
      "text": "Inception",
      "page": 45
    },
    {
      "level": "H1",
      "text": "[95]",
      "page": 45
    },
    {
      "level": "H1",
      "text": "93.2%",
      "page": 45
    },
    {
      "level": "H1",
      "text": "77.6%",
      "page": 45
    },
    {
      "level": "H1",
      "text": "1B(",
      "page": 45
    },
    {
      "level": "H1",
      "text": "+1)Softmax",
      "page": 45
    },
    {
      "level": "H1",
      "text": "93.21%",
      "page": 45
    },
    {
      "level": "H1",
      "text": "77.72%",
      "page": 45
    },
    {
      "level": "H1",
      "text": "2B(",
      "page": 45
    },
    {
      "level": "H1",
      "text": "94.3%",
      "page": 45
    },
    {
      "level": "H1",
      "text": "78.04%",
      "page": 45
    },
    {
      "level": "H1",
      "text": "+M)Softmax",
      "page": 45
    },
    {
      "level": "H1",
      "text": "96.55%",
      "page": 45
    },
    {
      "level": "H1",
      "text": "77.88%",
      "page": 45
    },
    {
      "level": "H1",
      "text": ")Softmax",
      "page": 45
    },
    {
      "level": "H1",
      "text": "97.1%",
      "page": 45
    },
    {
      "level": "H1",
      "text": "78.53%",
      "page": 45
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 46
    },
    {
      "level": "H1",
      "text": "2.3",
      "page": 46
    },
    {
      "level": "H1",
      "text": "SFEW",
      "page": 46
    },
    {
      "level": "H1",
      "text": "数据库上七种表情的分类精度。",
      "page": 46
    },
    {
      "level": "H1",
      "text": "Table 2.3 Recognition accuracy comparison on the SFEW database in terms of seven",
      "page": 46
    },
    {
      "level": "H1",
      "text": "expressions.",
      "page": 46
    },
    {
      "level": "H1",
      "text": "Methods",
      "page": 46
    },
    {
      "level": "H1",
      "text": "Validation",
      "page": 46
    },
    {
      "level": "H1",
      "text": "Kim et al.",
      "page": 46
    },
    {
      "level": "H1",
      "text": "[110]",
      "page": 46
    },
    {
      "level": "H1",
      "text": "53.9%",
      "page": 46
    },
    {
      "level": "H1",
      "text": "Yu et al.",
      "page": 46
    },
    {
      "level": "H1",
      "text": "[101]",
      "page": 46
    },
    {
      "level": "H1",
      "text": "55.96%",
      "page": 46
    },
    {
      "level": "H1",
      "text": "Ng et al.",
      "page": 46
    },
    {
      "level": "H1",
      "text": "[111]",
      "page": 46
    },
    {
      "level": "H1",
      "text": "48.5%",
      "page": 46
    },
    {
      "level": "H1",
      "text": "Yao et al.",
      "page": 46
    },
    {
      "level": "H1",
      "text": "[112]",
      "page": 46
    },
    {
      "level": "H1",
      "text": "43.58%",
      "page": 46
    },
    {
      "level": "H1",
      "text": "Sun et al.",
      "page": 46
    },
    {
      "level": "H1",
      "text": "[113]",
      "page": 46
    },
    {
      "level": "H1",
      "text": "51.02%",
      "page": 46
    },
    {
      "level": "H1",
      "text": "Zong et al.",
      "page": 46
    },
    {
      "level": "H1",
      "text": "[114]",
      "page": 46
    },
    {
      "level": "H1",
      "text": "N/A",
      "page": 46
    },
    {
      "level": "H1",
      "text": "Kaya et al.",
      "page": 46
    },
    {
      "level": "H1",
      "text": "[115]",
      "page": 46
    },
    {
      "level": "H1",
      "text": "53.06%",
      "page": 46
    },
    {
      "level": "H1",
      "text": "Mao et al.",
      "page": 46
    },
    {
      "level": "H1",
      "text": "[116]",
      "page": 46
    },
    {
      "level": "H1",
      "text": "44.7%",
      "page": 46
    },
    {
      "level": "H1",
      "text": "Mollahosseini",
      "page": 46
    },
    {
      "level": "H1",
      "text": "[95]",
      "page": 46
    },
    {
      "level": "H1",
      "text": "47.7%",
      "page": 46
    },
    {
      "level": "H1",
      "text": "1B(",
      "page": 46
    },
    {
      "level": "H1",
      "text": "+1)Softmax",
      "page": 46
    },
    {
      "level": "H1",
      "text": "49.77%",
      "page": 46
    },
    {
      "level": "H1",
      "text": "2B(",
      "page": 46
    },
    {
      "level": "H1",
      "text": "50.75%",
      "page": 46
    },
    {
      "level": "H1",
      "text": "N+M",
      "page": 46
    },
    {
      "level": "H1",
      "text": ")Softmax",
      "page": 46
    },
    {
      "level": "H1",
      "text": "53.36%",
      "page": 46
    },
    {
      "level": "H1",
      "text": "54.19%",
      "page": 46
    },
    {
      "level": "H1",
      "text": "MMI",
      "page": 46
    },
    {
      "level": "H1",
      "text": "数据库包括来自",
      "page": 46
    },
    {
      "level": "H1",
      "text": "个人的",
      "page": 46
    },
    {
      "level": "H1",
      "text": "213",
      "page": 46
    },
    {
      "level": "H1",
      "text": "个正面人脸图像序列",
      "page": 46
    },
    {
      "level": "H1",
      "text": "[98]",
      "page": 46
    },
    {
      "level": "H1",
      "text": "。其每个视频都",
      "page": 46
    },
    {
      "level": "H1",
      "text": "包含表情表达和还原的完整过程，即随着时间的推移从中性表情逐渐发展为六个",
      "page": 46
    },
    {
      "level": "H1",
      "text": "基本表情中的一个，然后被再逐渐释放表情回归到中性表情。由于这种模式很适",
      "page": 46
    },
    {
      "level": "H1",
      "text": "合采用基于时间序列的方法对变化进行建模，",
      "page": 46
    },
    {
      "level": "H1",
      "text": "数据库常常受到基于视频方",
      "page": 46
    },
    {
      "level": "H1",
      "text": "法的青睐。在每个图像序列的中间收集三个帧并将它们与标签相关联，产生了",
      "page": 46
    },
    {
      "level": "H1",
      "text": "624",
      "page": 46
    },
    {
      "level": "H1",
      "text": "个图像。需要注意的是，这三个帧往往并不是峰值帧。将",
      "page": 46
    },
    {
      "level": "H1",
      "text": "数据集划分为",
      "page": 46
    },
    {
      "level": "H1",
      "text": "个子集，用于",
      "page": 46
    },
    {
      "level": "H1",
      "text": "独立的的十折交叉验证。通过选择具有三个图像的最高平均分",
      "page": 46
    },
    {
      "level": "H1",
      "text": "数的表情类别来获得序列级的表情预测。其混淆矩阵展示于表",
      "page": 46
    },
    {
      "level": "H1",
      "text": "2.4",
      "page": 46
    },
    {
      "level": "H1",
      "text": "。在表",
      "page": 46
    },
    {
      "level": "H1",
      "text": "2.2",
      "page": 46
    },
    {
      "level": "H1",
      "text": "本章所提出的方法有效的超过了先前算法。",
      "page": 46
    },
    {
      "level": "H1",
      "text": "野外静态面部表情（",
      "page": 46
    },
    {
      "level": "H1",
      "text": "static facial expressions in the wild",
      "page": 46
    },
    {
      "level": "H1",
      "text": "）数据库简称",
      "page": 46
    },
    {
      "level": "H1",
      "text": "通过从",
      "page": 46
    },
    {
      "level": "H1",
      "text": "AFEW",
      "page": 46
    },
    {
      "level": "H1",
      "text": "数据语料库的短视频序列中提取某些帧而创建的",
      "page": 46
    },
    {
      "level": "H1",
      "text": "[99]",
      "page": 46
    },
    {
      "level": "H1",
      "text": "。其中有",
      "page": 46
    },
    {
      "level": "H1",
      "text": "1766",
      "page": 46
    },
    {
      "level": "H1",
      "text": "个标记良好的图像（分别有",
      "page": 46
    },
    {
      "level": "H1",
      "text": "958",
      "page": 46
    },
    {
      "level": "H1",
      "text": "个用于训练，",
      "page": 46
    },
    {
      "level": "H1",
      "text": "436",
      "page": 46
    },
    {
      "level": "H1",
      "text": "个用于验证，",
      "page": 46
    },
    {
      "level": "H1",
      "text": "372",
      "page": 46
    },
    {
      "level": "H1",
      "text": "个用于测试）",
      "page": 46
    },
    {
      "level": "H1",
      "text": "涵盖了",
      "page": 46
    },
    {
      "level": "H1",
      "text": "种常见表情。与前两个在实验室环境摆拍得到的数据集不同，它所包含",
      "page": 46
    },
    {
      "level": "H1",
      "text": "的是非实验室控制环境下的更自然的面部表情图片，但其复杂的背景、光照等变",
      "page": 46
    },
    {
      "level": "H1",
      "text": "化也使得其更有挑战性。表",
      "page": 46
    },
    {
      "level": "H1",
      "text": "将其与先前方法进行了对比，其混淆矩阵展示于",
      "page": 46
    },
    {
      "level": "H1",
      "text": "2.5",
      "page": 46
    },
    {
      "level": "H1",
      "text": "中。其验证集训练损失与精度展示于图",
      "page": 46
    },
    {
      "level": "H1",
      "text": "基于深度度量学习的身份感知人脸表情识别",
      "page": 47
    },
    {
      "level": "H1",
      "text": "2.4",
      "page": 47
    },
    {
      "level": "H1",
      "text": "MMI",
      "page": 47
    },
    {
      "level": "H1",
      "text": "数据库上的混淆矩阵",
      "page": 47
    },
    {
      "level": "H1",
      "text": "Table 2 .4 Average confusion matrix obtained from proposed method on the MMI database.",
      "page": 47
    },
    {
      "level": "H1",
      "text": "Predict",
      "page": 47
    },
    {
      "level": "H1",
      "text": "81.8%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "1.5%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "10.6%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "10.9% 71.9%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "3.1%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "4.7%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "9.4%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "5.4%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "8.9%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "41.4%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "7.1%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "30.4%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "1.1%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "3.6%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "92.9%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "2.4%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "17.2%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "7.8%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "1.6%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "73.4%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "7.3%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "14.6%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "79.6%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "2.5",
      "page": 47
    },
    {
      "level": "H1",
      "text": "SFEW",
      "page": 47
    },
    {
      "level": "H1",
      "text": "Table 2.5 Average confusion matrix obtained from proposed method on the SFEW validation",
      "page": 47
    },
    {
      "level": "H1",
      "text": "set.",
      "page": 47
    },
    {
      "level": "H1",
      "text": "66.24%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "1.3%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "6.94%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "9.09%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "5.19%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "10.69%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "21.74% 4.35% 4.35% 30.34% 13.04%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "4.35%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "21.74%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "27.66%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "6.38%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "8.51%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "10.64% 19.15% 27.66%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "87.67%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "6.85%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "1.37%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "4.11%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "5.48%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "2.74%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "57.53%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "27.4%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "22.81%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "1.75%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "7.02%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "8.77%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "40.35%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "19.3%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "1.16%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "2.33%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "5.81%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "17.44%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "73.26%",
      "page": 47
    },
    {
      "level": "H1",
      "text": "Actual",
      "page": 47
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 48
    },
    {
      "level": "H1",
      "text": "验证集上的",
      "page": 48
    },
    {
      "level": "H1",
      "text": "(a)",
      "page": 48
    },
    {
      "level": "H1",
      "text": "训练损失以及",
      "page": 48
    },
    {
      "level": "H1",
      "text": "(b)",
      "page": 48
    },
    {
      "level": "H1",
      "text": "精确度",
      "page": 48
    },
    {
      "level": "H1",
      "text": "Figure 2.5 (a) the training loss of different methods on SFEW validation set. (b) the",
      "page": 48
    },
    {
      "level": "H1",
      "text": "validation accuracies of different methods on SFEW validation set.",
      "page": 48
    },
    {
      "level": "H1",
      "text": "2.4",
      "page": 48
    },
    {
      "level": "H1",
      "text": "本章小结",
      "page": 48
    },
    {
      "level": "H1",
      "text": "本章提出了一种",
      "page": 48
    },
    {
      "level": "H1",
      "text": "N+M",
      "page": 48
    },
    {
      "level": "H1",
      "text": "元组簇损失并将其与基于",
      "page": 48
    },
    {
      "level": "H1",
      "text": "softmax",
      "page": 48
    },
    {
      "level": "H1",
      "text": "的交叉熵损失相结",
      "page": 48
    },
    {
      "level": "H1",
      "text": "合在统一的双分支全连接层度量学习",
      "page": 48
    },
    {
      "level": "H1",
      "text": "CNN",
      "page": 48
    },
    {
      "level": "H1",
      "text": "架构中，以减轻不同身份对人脸身份",
      "page": 48
    },
    {
      "level": "H1",
      "text": "识别引入的类内变化。采用有效的身份感知负样本挖掘和在线正样本挖掘方案。",
      "page": 48
    },
    {
      "level": "H1",
      "text": "在摆拍和自发人脸表情识别数据集上进行的性能评估证明了所提出的方法在提",
      "page": 48
    },
    {
      "level": "H1",
      "text": "取表情相关特征的能力方面优于先前基于",
      "page": 48
    },
    {
      "level": "H1",
      "text": "损失的深度学习方法。更具吸",
      "page": 48
    },
    {
      "level": "H1",
      "text": "引力的是，",
      "page": 48
    },
    {
      "level": "H1",
      "text": "元组簇损失函数有效的解决了锚点选择问题。并计划探索将其",
      "page": 48
    },
    {
      "level": "H1",
      "text": "用于人或车辆的重新识别等相关应用。",
      "page": 48
    },
    {
      "level": "H3",
      "text": "2.5  SFEW",
      "page": 48
    },
    {
      "level": "H1",
      "text": "基于难样本生成的人脸表情识别",
      "page": 50
    },
    {
      "level": "H1",
      "text": "人脸面部表情识别系统的性能在很大程度上取决于提取到的面部表情的特",
      "page": 50
    },
    {
      "level": "H1",
      "text": "征表示质量，其受姿态、光照变化以及面部形态变化（例如个体长相差异）的影",
      "page": 50
    },
    {
      "level": "H1",
      "text": "响。由于一些面部表情涉及微妙的面部肌肉运动，所以从不同表情的人脸图片所",
      "page": 50
    },
    {
      "level": "H1",
      "text": "提取的表情相关信息往往被有更大差异、更高辨识度的身份信息所干扰，从而降",
      "page": 50
    },
    {
      "level": "H1",
      "text": "低人脸表情识别的性能。如若提取的面部特征表示包含身份信息，则可能对人脸",
      "page": 50
    },
    {
      "level": "H1",
      "text": "表情识别任务有负面影响。这些身份特定因素可能会降低系统对未见的新身份的",
      "page": 50
    },
    {
      "level": "H1",
      "text": "人脸表情识别性能。然而，由于各种滋扰因素的紧密耦合，当前方法较难解开这",
      "page": 50
    },
    {
      "level": "H1",
      "text": "些面部因素。",
      "page": 50
    },
    {
      "level": "H1",
      "text": "3.1",
      "page": 50
    },
    {
      "level": "H1",
      "text": "种基本面部表情及其与中性表情脸的关系的示意图。外环中的表示对应于",
      "page": 50
    },
    {
      "level": "H1",
      "text": "与内环中的表情相比较高强度的面部表情。",
      "page": 50
    },
    {
      "level": "H1",
      "text": "Figure 3.1 A schematic depicting the 6 basic facial expressions and their relationships to the",
      "page": 50
    },
    {
      "level": "H1",
      "text": "neutral face. Representations in the outer ring correspond to higher-intensity facial",
      "page": 50
    },
    {
      "level": "H1",
      "text": "expressions compared to those in the inner ring.",
      "page": 50
    },
    {
      "level": "H1",
      "text": "上一章提出使用度量学习方法将查询图像与包含来自同一主题的其他面部",
      "page": 50
    },
    {
      "level": "H1",
      "text": "表情图像的负集进行比较。通过合理的选择正负样本集不仅可以明确的去除身份",
      "page": 50
    },
    {
      "level": "H1",
      "text": "信息，也解决了度量学习中锚点选择问题导致的缓慢收敛。在实践中，真实世界",
      "page": 50
    },
    {
      "level": "H1",
      "text": "的人脸表情识别数据集的结构却常常不能满足其要求，即数据集可能不包含每个",
      "page": 50
    },
    {
      "level": "H1",
      "text": "人的每个面部表情的图像。而实际上，可能并不需要将查询样本的面部表情与任",
      "page": 50
    },
    {
      "level": "H1",
      "text": "何其他所有类别的面部表情进行比较。根据一些心理学和解剖学研究",
      "page": 50
    },
    {
      "level": "H1",
      "text": "[117],[118],[119]",
      "page": 50
    },
    {
      "level": "H1",
      "text": "不同面部表情的肌肉活动均是从中性面开始，如图",
      "page": 50
    },
    {
      "level": "H1",
      "text": "所示。这也是动作单元",
      "page": 50
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 51
    },
    {
      "level": "H1",
      "text": "action units, AU",
      "page": 51
    },
    {
      "level": "H1",
      "text": "）和面部动作编码系统（",
      "page": 51
    },
    {
      "level": "H1",
      "text": "Facial Action Coding System, FACS",
      "page": 51
    },
    {
      "level": "H1",
      "text": "[60]",
      "page": 51
    },
    {
      "level": "H1",
      "text": "的基本原理。这表明一种可能的解决方案即是将面部表情图像与同身份的中性表",
      "page": 51
    },
    {
      "level": "H1",
      "text": "情面部图像进行比较。然而，在实际应用和几个基于图像的人脸表情识别数据集",
      "page": 51
    },
    {
      "level": "H1",
      "text": "中，并没有每个人的表情",
      "page": 51
    },
    {
      "level": "H1",
      "text": "中性面部图像对。",
      "page": 51
    },
    {
      "level": "H1",
      "text": "本章提出生成查询样本对应的正面和中性表情的标准化面部图像，并使用所",
      "page": 51
    },
    {
      "level": "H1",
      "text": "提出的身份去除的的面部表情识别机（",
      "page": 51
    },
    {
      "level": "H1",
      "text": "identity-disentangled facial expression",
      "page": 51
    },
    {
      "level": "H1",
      "text": "recognition machine, IDFERM",
      "page": 51
    },
    {
      "level": "H1",
      "text": "）剥离可能影响人脸表情识别的身份信息。",
      "page": 51
    },
    {
      "level": "H1",
      "text": "IDFERM",
      "page": 51
    },
    {
      "level": "H1",
      "text": "由两个主要部分组成，即难负样本生成（",
      "page": 51
    },
    {
      "level": "H1",
      "text": "HNG",
      "page": 51
    },
    {
      "level": "H1",
      "text": "）网络和径向度量学习（",
      "page": 51
    },
    {
      "level": "H1",
      "text": "RML",
      "page": 51
    },
    {
      "level": "H1",
      "text": "络。在",
      "page": 51
    },
    {
      "level": "H1",
      "text": "的训练阶段，给定查询面部表情图像，使用与查询样本具有相同身",
      "page": 51
    },
    {
      "level": "H1",
      "text": "份的正面中性面部图像作为",
      "page": 51
    },
    {
      "level": "H1",
      "text": "网络的目标图像，并由正面和中性面部图像组",
      "page": 51
    },
    {
      "level": "H1",
      "text": "成的引导集合，两者共同引导",
      "page": 51
    },
    {
      "level": "H1",
      "text": "网络的训练来合成其标准化面部作为参考。",
      "page": 51
    },
    {
      "level": "H1",
      "text": "然后，查询样本与其合成的标准化脸参考成对的被输入到径向度量学习（",
      "page": 51
    },
    {
      "level": "H1",
      "text": "网络，该网络使用与上一章相类似的统一卷积（",
      "page": 51
    },
    {
      "level": "H1",
      "text": "Convolutional, Conv",
      "page": 51
    },
    {
      "level": "H1",
      "text": "）层组主干",
      "page": 51
    },
    {
      "level": "H1",
      "text": "网络和双分支全连接（",
      "page": 51
    },
    {
      "level": "H1",
      "text": "Fully connected, FC",
      "page": 51
    },
    {
      "level": "H1",
      "text": "）层框架来提取查询样本",
      "page": 51
    },
    {
      "level": "H1",
      "text": "参考对的差",
      "page": 51
    },
    {
      "level": "H1",
      "text": "异并同时优化基于",
      "page": 51
    },
    {
      "level": "H1",
      "text": "softmax",
      "page": 51
    },
    {
      "level": "H1",
      "text": "的交叉熵损失和",
      "page": 51
    },
    {
      "level": "H1",
      "text": "损失。通过将面部表情图像的",
      "page": 51
    },
    {
      "level": "H1",
      "text": "特征表达推离其生成的参考并将所有样本拉近其每个表情类别的聚类中心，",
      "page": 51
    },
    {
      "level": "H1",
      "text": "可以有效的平衡类内和类间变化。",
      "page": 51
    },
    {
      "level": "H1",
      "text": "与从单个输入图像确定性的映射到输出表示的其他基于图像的人脸表情识",
      "page": 51
    },
    {
      "level": "H1",
      "text": "别系统不同，",
      "page": 51
    },
    {
      "level": "H1",
      "text": "利用表情图像",
      "page": 51
    },
    {
      "level": "H1",
      "text": "生成的参考图像对来去除关于身份的因素。与",
      "page": 51
    },
    {
      "level": "H1",
      "text": "基于视频的人脸表情识别方法",
      "page": 51
    },
    {
      "level": "H1",
      "text": "[67],[120]",
      "page": 51
    },
    {
      "level": "H1",
      "text": "或上一章基于真实面部表情图像对的方法",
      "page": 51
    },
    {
      "level": "H1",
      "text": "[66]",
      "page": 51
    },
    {
      "level": "H1",
      "text": "相比，本章使用合成生成的参考图像来解决有时数据集不包含所有可能的面部表",
      "page": 51
    },
    {
      "level": "H1",
      "text": "情样本的实际限制。",
      "page": 51
    },
    {
      "level": "H1",
      "text": "基于上一章的内容，本章在以下方面进行了扩展和提升：",
      "page": 51
    },
    {
      "level": "H1",
      "text": "）研究了不同表",
      "page": 51
    },
    {
      "level": "H1",
      "text": "情类别的先验关系，并通过难样本生成提出了一种新采样方案，作为传统难样本",
      "page": 51
    },
    {
      "level": "H1",
      "text": "挖掘的有效替代。",
      "page": 51
    },
    {
      "level": "H1",
      "text": "）设计了一个端到端的身份解除的面部表情识别机（",
      "page": 51
    },
    {
      "level": "H1",
      "text": "来提取去除身份信息的人脸表情识别特征表示，而不需要人脸表情识别数据集中",
      "page": 51
    },
    {
      "level": "H1",
      "text": "真正的表情",
      "page": 51
    },
    {
      "level": "H1",
      "text": "中性脸图片对。",
      "page": 51
    },
    {
      "level": "H1",
      "text": "）径向度量学习所需的距离比较的数量比传统的度",
      "page": 51
    },
    {
      "level": "H1",
      "text": "量学习方法所需的数量少几个数量级。",
      "page": 51
    },
    {
      "level": "H1",
      "text": "）使用新架构进行所有实验，并在没有",
      "page": 51
    },
    {
      "level": "H1",
      "text": "中性样本的情况下对更多数据集进行了测试。",
      "page": 51
    },
    {
      "level": "H1",
      "text": "基于难样本生成的人脸表情识别",
      "page": 52
    },
    {
      "level": "H1",
      "text": "2.1",
      "page": 52
    },
    {
      "level": "H1",
      "text": "相关工作",
      "page": 52
    },
    {
      "level": "H1",
      "text": "生成模型是机器学习中的经典主题，数十年来已经为此提出了多种方法。诸",
      "page": 52
    },
    {
      "level": "H1",
      "text": "如高斯混合模型（",
      "page": 52
    },
    {
      "level": "H1",
      "text": "Gaussian Mixture Model, GMM",
      "page": 52
    },
    {
      "level": "H1",
      "text": "），主成分分析（",
      "page": 52
    },
    {
      "level": "H1",
      "text": "Principal",
      "page": 52
    },
    {
      "level": "H1",
      "text": "Component Analysis, PCA",
      "page": 52
    },
    {
      "level": "H1",
      "text": "），独立分量分析（",
      "page": 52
    },
    {
      "level": "H1",
      "text": "Independent Component Analysis, ICA",
      "page": 52
    },
    {
      "level": "H1",
      "text": "等常规方法难以对不规则分布的复杂模式进行建模",
      "page": 52
    },
    {
      "level": "H1",
      "text": "[121]",
      "page": 52
    },
    {
      "level": "H1",
      "text": "。最近，受限玻尔兹曼机",
      "page": 52
    },
    {
      "level": "H1",
      "text": "Restricted Boltzmann Machine, RBM",
      "page": 52
    },
    {
      "level": "H1",
      "text": "），隐马尔可夫模型（",
      "page": 52
    },
    {
      "level": "H1",
      "text": "Hidden Markov Model,",
      "page": 52
    },
    {
      "level": "H1",
      "text": "HMM",
      "page": 52
    },
    {
      "level": "H1",
      "text": "），马尔可夫随机场（",
      "page": 52
    },
    {
      "level": "H1",
      "text": "Markov Random Field, MRF",
      "page": 52
    },
    {
      "level": "H1",
      "text": "）等已被用于对数字，纹",
      "page": 52
    },
    {
      "level": "H1",
      "text": "理斑块和良好配准的面部的图像进行建模",
      "page": 52
    },
    {
      "level": "H1",
      "text": "[122]",
      "page": 52
    },
    {
      "level": "H1",
      "text": "。然而，它们有限的特征表示能力",
      "page": 52
    },
    {
      "level": "H1",
      "text": "限制了进一步的发展。由于最近生成模型的深层次结构能够处理复杂的数据结构，",
      "page": 52
    },
    {
      "level": "H1",
      "text": "因此使用这些深层神经网络结构的生成图像更加真实。",
      "page": 52
    },
    {
      "level": "H1",
      "text": "自动编码器是一种神经网络，其训练目标为将其输入复制到其输出，其将可",
      "page": 52
    },
    {
      "level": "H1",
      "text": "微分编码器和解码器配对，将图像样本",
      "page": 52
    },
    {
      "level": "H1",
      "text": "编码为潜在表示",
      "page": 52
    },
    {
      "level": "H1",
      "text": "，然后将",
      "page": 52
    },
    {
      "level": "H1",
      "text": "解码回另",
      "page": 52
    },
    {
      "level": "H1",
      "text": "一个图像空间",
      "page": 52
    },
    {
      "level": "H1",
      "text": "，这使我们能够构建变换网络",
      "page": 52
    },
    {
      "level": "H1",
      "text": "[123]",
      "page": 52
    },
    {
      "level": "H1",
      "text": "。其编码器与解码器构成一个瓶",
      "page": 52
    },
    {
      "level": "H1",
      "text": "颈结构，使得在其中心的隐空间表示为原图像的高度压缩编码。去噪自动编码器",
      "page": 52
    },
    {
      "level": "H1",
      "text": "Denoising auto-encoder, DAE",
      "page": 52
    },
    {
      "level": "H1",
      "text": "）则输入具有噪声的图片并使用没有噪声的图片作",
      "page": 52
    },
    {
      "level": "H1",
      "text": "为生成目标。对于标准化面部生成任务，姿态和表情可以被视为要去噪的噪声。",
      "page": 52
    },
    {
      "level": "H1",
      "text": "这类方法的主要局限在于平方像素重建误差会导致生成的样本看起来模糊，因为",
      "page": 52
    },
    {
      "level": "H1",
      "text": "它们会生成该分布的平均图像",
      "page": 52
    },
    {
      "level": "H1",
      "text": "[124]",
      "page": 52
    },
    {
      "level": "H1",
      "text": "。文献",
      "page": 52
    },
    {
      "level": "H1",
      "text": "[125]",
      "page": 52
    },
    {
      "level": "H1",
      "text": "从有向图模型的角度提出了随机变分",
      "page": 52
    },
    {
      "level": "H1",
      "text": "自动编码器。",
      "page": 52
    },
    {
      "level": "H1",
      "text": "最近提出的对抗生成网络（",
      "page": 52
    },
    {
      "level": "H1",
      "text": "Generative Adversarial Network, GAN",
      "page": 52
    },
    {
      "level": "H1",
      "text": "[127]",
      "page": 52
    },
    {
      "level": "H1",
      "text": "同时训",
      "page": 52
    },
    {
      "level": "H1",
      "text": "练两个网络：生成网络（",
      "page": 52
    },
    {
      "level": "H1",
      "text": "Generative network,",
      "page": 52
    },
    {
      "level": "H1",
      "text": "Gen",
      "page": 52
    },
    {
      "level": "H1",
      "text": "）用于合成图像（将潜在",
      "page": 52
    },
    {
      "level": "H1",
      "text": "到图像空间），以及（",
      "page": 52
    },
    {
      "level": "H1",
      "text": "Discriminative network,",
      "page": 52
    },
    {
      "level": "H1",
      "text": "Dis",
      "page": 52
    },
    {
      "level": "H1",
      "text": "）判别网络用于区分真实训练图",
      "page": 52
    },
    {
      "level": "H1",
      "text": "像与生成图片。当",
      "page": 52
    },
    {
      "level": "H1",
      "text": "是真实图片时，",
      "page": 52
    },
    {
      "level": "H1",
      "text": "输出概率",
      "page": 52
    },
    {
      "level": "H1",
      "text": "y = 𝐷𝑖𝑠(𝑥) ∈[0,1]",
      "page": 52
    },
    {
      "level": "H1",
      "text": "成图片时输出概率",
      "page": 52
    },
    {
      "level": "H1",
      "text": "1 −𝐷𝑖𝑠(𝑥",
      "page": 52
    },
    {
      "level": "H1",
      "text": "进行博弈，最小化或最大化以下二元",
      "page": 52
    },
    {
      "level": "H1",
      "text": "交叉熵损失：",
      "page": 52
    },
    {
      "level": "H1",
      "text": "ீ஺ே",
      "page": 52
    },
    {
      "level": "H1",
      "text": "= 𝔼",
      "page": 52
    },
    {
      "level": "H1",
      "text": "ௗ௔௧௔",
      "page": 52
    },
    {
      "level": "H1",
      "text": "[log𝐷𝑖𝑠(𝑥)] + 𝔼",
      "page": 52
    },
    {
      "level": "H1",
      "text": "[log(1 −𝐷𝑖𝑠(𝐺𝑒𝑛(𝑧)))]",
      "page": 52
    },
    {
      "level": "H1",
      "text": "(3.1)",
      "page": 52
    },
    {
      "level": "H1",
      "text": "其中用",
      "page": 52
    },
    {
      "level": "H1",
      "text": "表示输入样本和",
      "page": 52
    },
    {
      "level": "H1",
      "text": "𝑧~𝑝(𝑧)",
      "page": 52
    },
    {
      "level": "H1",
      "text": "。在实践中，",
      "page": 52
    },
    {
      "level": "H1",
      "text": "log(1 −𝐷𝑖𝑠(𝐺𝑒𝑛(𝑧)))",
      "page": 52
    },
    {
      "level": "H1",
      "text": "在学习过程中很",
      "page": 52
    },
    {
      "level": "H1",
      "text": "容易饱和，当",
      "page": 52
    },
    {
      "level": "H1",
      "text": "很差时，",
      "page": 52
    },
    {
      "level": "H1",
      "text": "可以较容易的地分辨出生成的图像。如果只训练",
      "page": 52
    },
    {
      "level": "H1",
      "text": "来最大化",
      "page": 52
    },
    {
      "level": "H1",
      "text": "log 𝐷𝑖𝑠(𝑥)",
      "page": 52
    },
    {
      "level": "H1",
      "text": "，那么",
      "page": 52
    },
    {
      "level": "H1",
      "text": "可以提供更强的梯度。利用",
      "page": 52
    },
    {
      "level": "H1",
      "text": "GAN",
      "page": 52
    },
    {
      "level": "H1",
      "text": "，可以从来自",
      "page": 52
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 53
    },
    {
      "level": "H1",
      "text": "特定分布的随机采样矢量",
      "page": 53
    },
    {
      "level": "H1",
      "text": "生成预期图像。有一些方法可以将自动编码器和",
      "page": 53
    },
    {
      "level": "H1",
      "text": "GAN",
      "page": 53
    },
    {
      "level": "H1",
      "text": "结合起来实现图像样式转换",
      "page": 53
    },
    {
      "level": "H1",
      "text": "[128]",
      "page": 53
    },
    {
      "level": "H1",
      "text": "，这些转换与本章提出的架构相关并且启发了本",
      "page": 53
    },
    {
      "level": "H1",
      "text": "章所提出的架构。然而，仍然难以利用生成的结果来改进监督识别任务，因为",
      "page": 53
    },
    {
      "level": "H1",
      "text": "总是试图对数据分布的中心部分进行建模，而特征空间中的类别间的边界",
      "page": 53
    },
    {
      "level": "H1",
      "text": "对于分类起着至关重要的作用。",
      "page": 53
    },
    {
      "level": "H1",
      "text": "Semi-GAN",
      "page": 53
    },
    {
      "level": "H1",
      "text": "[129]",
      "page": 53
    },
    {
      "level": "H1",
      "text": "为鉴别器网络增加了额外的分类任",
      "page": 53
    },
    {
      "level": "H1",
      "text": "务，以改进半监督识别任务。",
      "page": 53
    },
    {
      "level": "H1",
      "text": "Tran",
      "page": 53
    },
    {
      "level": "H1",
      "text": "[130]",
      "page": 53
    },
    {
      "level": "H1",
      "text": "Huang",
      "page": 53
    },
    {
      "level": "H1",
      "text": "[131]",
      "page": 53
    },
    {
      "level": "H1",
      "text": "提出面部旋转器方案用于生成",
      "page": 53
    },
    {
      "level": "H1",
      "text": "正面人脸，作为普通面部识别网络的预处理。而本章所提出的方法则是从数据增",
      "page": 53
    },
    {
      "level": "H1",
      "text": "强的角度利用生成结果，并将其应用于人脸表情识别。",
      "page": 53
    },
    {
      "level": "H1",
      "text": "与这些工作相比，本章的",
      "page": 53
    },
    {
      "level": "H1",
      "text": "HNG",
      "page": 53
    },
    {
      "level": "H1",
      "text": "模型保持了身份相关内容的不变性，同时去",
      "page": 53
    },
    {
      "level": "H1",
      "text": "除了姿势和表情等干扰因素。数据分布的先验知识和面部的对称性都被合理的应",
      "page": 53
    },
    {
      "level": "H1",
      "text": "用。此外，进一步利用了特征级语义相似性来提高面部生成质量。",
      "page": 53
    },
    {
      "level": "H1",
      "text": "3.2",
      "page": 53
    },
    {
      "level": "H1",
      "text": "难样本生成",
      "page": 53
    },
    {
      "level": "H1",
      "text": "当试图从人脸图像",
      "page": 53
    },
    {
      "level": "H1",
      "text": "中解开与身份相关的因素并保留表情信息时，需要来",
      "page": 53
    },
    {
      "level": "H1",
      "text": "自同一个体的参考中性表情人脸图像以获得同一个人的中性表情与",
      "page": 53
    },
    {
      "level": "H1",
      "text": "之间的差",
      "page": 53
    },
    {
      "level": "H1",
      "text": "异以用于面部表情识别。然而，在现实世界的应用场景中，中性脸参考图像并不",
      "page": 53
    },
    {
      "level": "H1",
      "text": "总是存在的。本章提出直接使用生成的归一化（",
      "page": 53
    },
    {
      "level": "H1",
      "text": "Normalized",
      "page": 53
    },
    {
      "level": "H1",
      "text": "）面部图像作为参考",
      "page": 53
    },
    {
      "level": "H1",
      "text": "图像并作为负样本，而不是如上一章所提出方法去挖掘难负样本。归一化面部图",
      "page": 53
    },
    {
      "level": "H1",
      "text": "像指的是姿态为正面且表情为中性的人脸图片。难负样本生成（",
      "page": 53
    },
    {
      "level": "H1",
      "text": "hard negative",
      "page": 53
    },
    {
      "level": "H1",
      "text": "generation, HNG",
      "page": 53
    },
    {
      "level": "H1",
      "text": "）网络的目标是将查询样本图像",
      "page": 53
    },
    {
      "level": "H1",
      "text": "转换为外观真实、与",
      "page": 53
    },
    {
      "level": "H1",
      "text": "身份一",
      "page": 53
    },
    {
      "level": "H1",
      "text": "样的归一化面部图像",
      "page": 53
    },
    {
      "level": "H1",
      "text": "。本章所采用的网络架构如图",
      "page": 53
    },
    {
      "level": "H1",
      "text": "3.3",
      "page": 53
    },
    {
      "level": "H1",
      "text": "所示。",
      "page": 53
    },
    {
      "level": "H1",
      "text": "将输入图像",
      "page": 53
    },
    {
      "level": "H1",
      "text": "输入到编码器",
      "page": 53
    },
    {
      "level": "H1",
      "text": "解码器结构并生成其变换后的输出",
      "page": 53
    },
    {
      "level": "H1",
      "text": "。训练",
      "page": 53
    },
    {
      "level": "H1",
      "text": "Dis",
      "page": 53
    },
    {
      "level": "H1",
      "text": "以分辨其输入是来自引导集（真实正面中性表情图像）还是编码器",
      "page": 53
    },
    {
      "level": "H1",
      "text": "解码器结构",
      "page": 53
    },
    {
      "level": "H1",
      "text": "（生成的图像），从而鼓励编码器",
      "page": 53
    },
    {
      "level": "H1",
      "text": "解码器结构生成更类似于引导集中的图像。引",
      "page": 53
    },
    {
      "level": "H1",
      "text": "导集包含所有目标图像",
      "page": 53
    },
    {
      "level": "H1",
      "text": "，其是许多正面和中性真实面部图像的汇编。",
      "page": 53
    },
    {
      "level": "H1",
      "text": "Light-",
      "page": 53
    },
    {
      "level": "H1",
      "text": "CNN",
      "page": 53
    },
    {
      "level": "H1",
      "text": "[133]",
      "page": 53
    },
    {
      "level": "H1",
      "text": "提取用于身份相似性测量的身份特征，并且采用",
      "page": 53
    },
    {
      "level": "H1",
      "text": "VGG-Face",
      "page": 53
    },
    {
      "level": "H1",
      "text": "来嵌入图像",
      "page": 53
    },
    {
      "level": "H1",
      "text": "以用于特征级感知相似性测量。随机采样的真实表情人脸图像及其相应的生成的",
      "page": 53
    },
    {
      "level": "H1",
      "text": "归一化人脸图像被输入到",
      "page": 53
    },
    {
      "level": "H1",
      "text": "RML",
      "page": 53
    },
    {
      "level": "H1",
      "text": "，一种自适应深度度量学习框架，通过最小化基",
      "page": 53
    },
    {
      "level": "H1",
      "text": "softmax",
      "page": 53
    },
    {
      "level": "H1",
      "text": "的交叉熵损失和",
      "page": 53
    },
    {
      "level": "H1",
      "text": "来去除人脸图像中的身份信息。",
      "page": 53
    },
    {
      "level": "H1",
      "text": "基于难样本生成的人脸表情识别",
      "page": 54
    },
    {
      "level": "H1",
      "text": "3.3",
      "page": 54
    },
    {
      "level": "H1",
      "text": "本章提出的",
      "page": 54
    },
    {
      "level": "H1",
      "text": "IDFERM",
      "page": 54
    },
    {
      "level": "H1",
      "text": "框架，其中左侧和右侧分别是",
      "page": 54
    },
    {
      "level": "H1",
      "text": "HNG",
      "page": 54
    },
    {
      "level": "H1",
      "text": "RML",
      "page": 54
    },
    {
      "level": "H1",
      "text": "网络。",
      "page": 54
    },
    {
      "level": "H1",
      "text": "Figure 3.3 Framework of our IDFERM, in which, the left and right side are the HNG and",
      "page": 54
    },
    {
      "level": "H1",
      "text": "RML network, respectively.",
      "page": 54
    },
    {
      "level": "H1",
      "text": "归一化人脸生成（即表情识别的难样本生成）网络由五个主要部分组成：",
      "page": 54
    },
    {
      "level": "H1",
      "text": "编码器网络（",
      "page": 54
    },
    {
      "level": "H1",
      "text": "Encoder,",
      "page": 54
    },
    {
      "level": "H1",
      "text": "Enc",
      "page": 54
    },
    {
      "level": "H1",
      "text": "），（",
      "page": 54
    },
    {
      "level": "H1",
      "text": "）解码器网络（",
      "page": 54
    },
    {
      "level": "H1",
      "text": "Decoder,",
      "page": 54
    },
    {
      "level": "H1",
      "text": "Dec",
      "page": 54
    },
    {
      "level": "H1",
      "text": "）判别",
      "page": 54
    },
    {
      "level": "H1",
      "text": "Discriminator,",
      "page": 54
    },
    {
      "level": "H1",
      "text": "Dis",
      "page": 54
    },
    {
      "level": "H1",
      "text": "）基于",
      "page": 54
    },
    {
      "level": "H1",
      "text": "Light CNN",
      "page": 54
    },
    {
      "level": "H1",
      "text": "的身份验证网络和（",
      "page": 54
    },
    {
      "level": "H1",
      "text": "VGG-",
      "page": 54
    },
    {
      "level": "H1",
      "text": "facenet",
      "page": 54
    },
    {
      "level": "H1",
      "text": "的特征空间感知网络。其中",
      "page": 54
    },
    {
      "level": "H1",
      "text": "网络的功能与自动编码器",
      "page": 54
    },
    {
      "level": "H1",
      "text": "[44]",
      "page": 54
    },
    {
      "level": "H1",
      "text": "相应组成模块功能相同。",
      "page": 54
    },
    {
      "level": "H1",
      "text": "通过学习分布",
      "page": 54
    },
    {
      "level": "H1",
      "text": "z|x",
      "page": 54
    },
    {
      "level": "H1",
      "text": "将输入样本图像",
      "page": 54
    },
    {
      "level": "H1",
      "text": "映射到隐空",
      "page": 54
    },
    {
      "level": "H1",
      "text": "Latent space",
      "page": 54
    },
    {
      "level": "H1",
      "text": "）中的特征向量",
      "page": 54
    },
    {
      "level": "H1",
      "text": "用于将",
      "page": 54
    },
    {
      "level": "H1",
      "text": "生成预测的归一化面部图像",
      "page": 54
    },
    {
      "level": "H1",
      "text": "的功能与",
      "page": 54
    },
    {
      "level": "H1",
      "text": "GAN",
      "page": 54
    },
    {
      "level": "H1",
      "text": "[127]",
      "page": 54
    },
    {
      "level": "H1",
      "text": "的功能相同。",
      "page": 54
    },
    {
      "level": "H1",
      "text": "网络试图通过来自",
      "page": 54
    },
    {
      "level": "H1",
      "text": "的梯度",
      "page": 54
    },
    {
      "level": "H1",
      "text": "来学习生成真实图像，",
      "page": 54
    },
    {
      "level": "H1",
      "text": "的学习任务则是区分在引导集",
      "page": 54
    },
    {
      "level": "H1",
      "text": "中的实际图像和",
      "page": 54
    },
    {
      "level": "H1",
      "text": "生成的图像",
      "page": 54
    },
    {
      "level": "H1",
      "text": "。引导集包含许多正面而且带有中性表情的真实面部图像，包括",
      "page": 54
    },
    {
      "level": "H1",
      "text": "和来自其他扩充库的许多其他人的图像。学习可微分编码器",
      "page": 54
    },
    {
      "level": "H1",
      "text": "和解码器",
      "page": 54
    },
    {
      "level": "H1",
      "text": "需要来自多个个体的输入目标对",
      "page": 54
    },
    {
      "level": "H1",
      "text": ", 𝑦",
      "page": 54
    },
    {
      "level": "H1",
      "text": "，其中",
      "page": 54
    },
    {
      "level": "H1",
      "text": "是具有表情的面部图像，",
      "page": 54
    },
    {
      "level": "H1",
      "text": "是该个体的正面中性表情面部图像。典型的损失函数选择是平方欧几里德损失",
      "page": 54
    },
    {
      "level": "H1",
      "text": "‖𝑥−𝑦‖",
      "page": 54
    },
    {
      "level": "H1",
      "text": "。但是，这些损失可能会导致过于模糊的生成结果。",
      "page": 54
    },
    {
      "level": "H1",
      "text": "在本节中，将展示如何将多个目标函数用于不同的网络部分，以生成逼真的标准",
      "page": 54
    },
    {
      "level": "H1",
      "text": "化人脸图像。总共使用了五种不同的损失函数来结合",
      "page": 54
    },
    {
      "level": "H1",
      "text": "可以生成高质量图片",
      "page": 54
    },
    {
      "level": "H1",
      "text": "和自动编码器稳定的优点。在本节中，将展示如何使用多个目标函数为指导各个",
      "page": 54
    },
    {
      "level": "H1",
      "text": "模组生成可用于身份感知的人脸表情识别的归一化面部参考样本。",
      "page": 54
    },
    {
      "level": "H1",
      "text": "3.2.1",
      "page": 54
    },
    {
      "level": "H1",
      "text": "特征空间语义感知损失",
      "page": 54
    },
    {
      "level": "H1",
      "text": "通常，在图像空间中使用逐像素的相似性度量以促进图像内容一致性。但是，",
      "page": 54
    },
    {
      "level": "H1",
      "text": "它通常会产生过于平滑的结果。对于图像生成任务尤其如此，因为在从其特征表",
      "page": 54
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 55
    },
    {
      "level": "H1",
      "text": "示向量重建图像时具有较大的不确定性。在编码器进行降维处理之后，几乎所有",
      "page": 55
    },
    {
      "level": "H1",
      "text": "细节的精确位置都不会保留在特征向量中。使用图像空间中像素级的平方欧几里",
      "page": 55
    },
    {
      "level": "H1",
      "text": "德距离（",
      "page": 55
    },
    {
      "level": "H1",
      "text": "squared Euclidean distance",
      "page": 55
    },
    {
      "level": "H1",
      "text": "）对所有可能位置进行平均会使得重建后的图",
      "page": 55
    },
    {
      "level": "H1",
      "text": "像看起来模糊。图像细节的确切位置对于衡量图像的感知相似性（",
      "page": 55
    },
    {
      "level": "H1",
      "text": "perceptual",
      "page": 55
    },
    {
      "level": "H1",
      "text": "similarity",
      "page": 55
    },
    {
      "level": "H1",
      "text": "）不是必不可少的。但由于表情涉及到的往往是面部肌肉的空间位移，",
      "page": 55
    },
    {
      "level": "H1",
      "text": "这些细节的空间分布在人脸表情识别中起着关键作用。因此，通过测量替代的合",
      "page": 55
    },
    {
      "level": "H1",
      "text": "适特征空间中的距离，可以实现对不相关变换的不变性和对局部图像统计的灵敏",
      "page": 55
    },
    {
      "level": "H1",
      "text": "度。实际上，卷积网络就可以提供具有这种特性的特征表示。它们对于小的平滑",
      "page": 55
    },
    {
      "level": "H1",
      "text": "的形变不敏感，但对与感知相关的图像属性敏感，例如锐利的边缘和纹理。",
      "page": 55
    },
    {
      "level": "H1",
      "text": "因此不仅要求两个图像在像素级别上相同或相似，还要求它们在特征空间中",
      "page": 55
    },
    {
      "level": "H1",
      "text": "具有相似性。模型采用",
      "page": 55
    },
    {
      "level": "H1",
      "text": "CNN",
      "page": 55
    },
    {
      "level": "H1",
      "text": "提取的特征表示之间的平方误差损失来表示特征层",
      "page": 55
    },
    {
      "level": "H1",
      "text": "级的感知损失（",
      "page": 55
    },
    {
      "level": "H1",
      "text": "Perceptual loss",
      "page": 55
    },
    {
      "level": "H1",
      "text": "）。在此采用的特征提取",
      "page": 55
    },
    {
      "level": "H1",
      "text": "为预先独立训练并固",
      "page": 55
    },
    {
      "level": "H1",
      "text": "定参数的",
      "page": 55
    },
    {
      "level": "H1",
      "text": "VGG-FaceNet",
      "page": 55
    },
    {
      "level": "H1",
      "text": "[132]",
      "page": 55
    },
    {
      "level": "H1",
      "text": "将图片映射到语义特征级别。但仅采用",
      "page": 55
    },
    {
      "level": "H1",
      "text": "的前五个卷积层，而将后续的卷积层以及全连接层舍弃掉。这主要是考虑到网络",
      "page": 55
    },
    {
      "level": "H1",
      "text": "深层的特征表达有限的空间分辨率不能良好的支持图像重建性能。",
      "page": 55
    },
    {
      "level": "H1",
      "text": "个卷积层的特征图由",
      "page": 55
    },
    {
      "level": "H1",
      "text": "表示，其使用标准前向传播过程（",
      "page": 55
    },
    {
      "level": "H1",
      "text": "forward-",
      "page": 55
    },
    {
      "level": "H1",
      "text": "propagation process",
      "page": 55
    },
    {
      "level": "H1",
      "text": "）来提取特征表示。第",
      "page": 55
    },
    {
      "level": "H1",
      "text": "个卷积层上的两个图像",
      "page": 55
    },
    {
      "level": "H1",
      "text": "之间的",
      "page": 55
    },
    {
      "level": "H1",
      "text": "语义感知损失被定义为两个特征图之间的平方误差损失。",
      "page": 55
    },
    {
      "level": "H1",
      "text": "௙௘௔௧",
      "page": 55
    },
    {
      "level": "H1",
      "text": ", 𝑦) =",
      "page": 55
    },
    {
      "level": "H1",
      "text": "௠ୀଵ",
      "page": 55
    },
    {
      "level": "H1",
      "text": "௡ୀଵ",
      "page": 55
    },
    {
      "level": "H1",
      "text": "(3.2)",
      "page": 55
    },
    {
      "level": "H1",
      "text": "表示第",
      "page": 55
    },
    {
      "level": "H1",
      "text": "个特征图的宽度和高度，",
      "page": 55
    },
    {
      "level": "H1",
      "text": "个特征图在点",
      "page": 55
    },
    {
      "level": "H1",
      "text": "n, m",
      "page": 55
    },
    {
      "level": "H1",
      "text": "的值。基于经验调试，在本章所有实验中",
      "page": 55
    },
    {
      "level": "H1",
      "text": "= 5",
      "page": 55
    },
    {
      "level": "H1",
      "text": "。仅使用",
      "page": 55
    },
    {
      "level": "H1",
      "text": "并不能为训练提供良",
      "page": 55
    },
    {
      "level": "H1",
      "text": "好的学习目标。众所周知，仅仅针对特征空间中的相似性进行优化通常会导致高",
      "page": 55
    },
    {
      "level": "H1",
      "text": "频缺陷（",
      "page": 55
    },
    {
      "level": "H1",
      "text": "high frequency artifacts",
      "page": 55
    },
    {
      "level": "H1",
      "text": "[129]",
      "page": 55
    },
    {
      "level": "H1",
      "text": "。这是因为对于每个自然图像，存在许多映",
      "page": 55
    },
    {
      "level": "H1",
      "text": "射到相同特征向量的非自然图像。因此，需要关于自然图像的先验知识将所生成",
      "page": 55
    },
    {
      "level": "H1",
      "text": "的图像约束到自然图像的流形中。",
      "page": 55
    },
    {
      "level": "H1",
      "text": "3.2.2",
      "page": 55
    },
    {
      "level": "H1",
      "text": "对称性损失",
      "page": 55
    },
    {
      "level": "H1",
      "text": "对称性是正常人脸图像的一种常见属性。利用该属性作为先验知识并且对所",
      "page": 55
    },
    {
      "level": "H1",
      "text": "基于难样本生成的人脸表情识别",
      "page": 56
    },
    {
      "level": "H1",
      "text": "生成的图像构成对称约束可以有效地减轻自遮挡问题，从而改善较大水平姿态变",
      "page": 56
    },
    {
      "level": "H1",
      "text": "化情况的系统性能。虽然严格的对称在大多数正面人脸图像中都不被满足，且该",
      "page": 56
    },
    {
      "level": "H1",
      "text": "假设往往无助于人脸身份识别。事实上，被自遮挡的面部信息在没有被其他角度",
      "page": 56
    },
    {
      "level": "H1",
      "text": "的拍摄设备采集到的情况下几乎无法真实的补全这部分信息。但中性表情所涉及",
      "page": 56
    },
    {
      "level": "H1",
      "text": "到的面部变化通常都是对称的，因此用另一侧的信息进行补充对该任务是较为合",
      "page": 56
    },
    {
      "level": "H1",
      "text": "理的操作。而且此操作有助于本生成任务的一个重要目标即图像的质量。面部图",
      "page": 56
    },
    {
      "level": "H1",
      "text": "像的对称性损失采用以下形式：",
      "page": 56
    },
    {
      "level": "H1",
      "text": "ୱ୷୫",
      "page": 56
    },
    {
      "level": "H1",
      "text": ") =",
      "page": 56
    },
    {
      "level": "H1",
      "text": "௡ିଵ",
      "page": 56
    },
    {
      "level": "H1",
      "text": "௠ୀଵ",
      "page": 56
    },
    {
      "level": "H1",
      "text": "௡ୀଵ",
      "page": 56
    },
    {
      "level": "H1",
      "text": "(3.3)",
      "page": 56
    },
    {
      "level": "H1",
      "text": "是图像的宽度和高度，（",
      "page": 56
    },
    {
      "level": "H1",
      "text": "n,m",
      "page": 56
    },
    {
      "level": "H1",
      "text": "）表示生成图像的像素。为简单起",
      "page": 56
    },
    {
      "level": "H1",
      "text": "见，当使用对称损失训练我们的模型时，先进性人脸配准并检测是否所有输入图",
      "page": 56
    },
    {
      "level": "H1",
      "text": "像都为正面或朝右姿态。如果不是，则翻转图像以其朝右。因此，我们可以通过",
      "page": 56
    },
    {
      "level": "H1",
      "text": "该损失函数指导网络利用图像右侧的信息来恢复图像左侧的丢失信息，从而将可",
      "page": 56
    },
    {
      "level": "H1",
      "text": "见部分的外观转移到被遮挡部分。然而，在原始像素空间中，照明变化和固有纹",
      "page": 56
    },
    {
      "level": "H1",
      "text": "理更复杂。真实世界的图像通常不会表现出灰度值的严格对称性。考虑到局部区",
      "page": 56
    },
    {
      "level": "H1",
      "text": "域内像素差异的一致性，并且在不同的照明下大致保留了各点沿所有方向的的梯",
      "page": 56
    },
    {
      "level": "H1",
      "text": "度，在拉普拉斯空间（",
      "page": 56
    },
    {
      "level": "H1",
      "text": "Laplacian space",
      "page": 56
    },
    {
      "level": "H1",
      "text": "）上定义对称性损失更为合理。因此在预处",
      "page": 56
    },
    {
      "level": "H1",
      "text": "理阶段需先将图片转换到拉普拉斯空间。",
      "page": 56
    },
    {
      "level": "H1",
      "text": "3.2.3",
      "page": 56
    },
    {
      "level": "H1",
      "text": "对抗性损失",
      "page": 56
    },
    {
      "level": "H1",
      "text": "引入了一个鉴别器",
      "page": 56
    },
    {
      "level": "H1",
      "text": "Dis",
      "page": 56
    },
    {
      "level": "H1",
      "text": "，它作为监督器推动合成图像与真实的正面中性面部",
      "page": 56
    },
    {
      "level": "H1",
      "text": "图像具有相似的分布。它可以有效地减少模糊效果并产生视觉上真实的结果。",
      "page": 56
    },
    {
      "level": "H1",
      "text": "旨在将生成的正面中性面部图像",
      "page": 56
    },
    {
      "level": "H1",
      "text": "与引导集中的实际中间面部图像",
      "page": 56
    },
    {
      "level": "H1",
      "text": "分开来，并且与表情变换网络（",
      "page": 56
    },
    {
      "level": "H1",
      "text": "Enc",
      "page": 56
    },
    {
      "level": "H1",
      "text": "Dec",
      "page": 56
    },
    {
      "level": "H1",
      "text": "）以迭代更新的方式同时训练。变换",
      "page": 56
    },
    {
      "level": "H1",
      "text": "网络试图“欺骗”",
      "page": 56
    },
    {
      "level": "H1",
      "text": "以将生成的图像分类为真实的图像。形式上，训练鉴别器",
      "page": 56
    },
    {
      "level": "H1",
      "text": "是通过最小化以下的二元交叉熵损失：",
      "page": 56
    },
    {
      "level": "H1",
      "text": "ீ஺ேି஽௜௦",
      "page": 56
    },
    {
      "level": "H1",
      "text": ", 𝑥",
      "page": 56
    },
    {
      "level": "H1",
      "text": "= −𝑙𝑜𝑔",
      "page": 56
    },
    {
      "level": "H1",
      "text": "𝐷𝑖𝑠(𝑔",
      "page": 56
    },
    {
      "level": "H1",
      "text": "−𝑙𝑜𝑔",
      "page": 56
    },
    {
      "level": "H1",
      "text": "1 −𝐷𝑖𝑠",
      "page": 56
    },
    {
      "level": "H1",
      "text": "෥൯ቁ",
      "page": 56
    },
    {
      "level": "H1",
      "text": "(3.4)",
      "page": 56
    },
    {
      "level": "H1",
      "text": "则通过最小化以下来自",
      "page": 56
    },
    {
      "level": "H1",
      "text": "的损失函数来训练其参数：",
      "page": 56
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 57
    },
    {
      "level": "H1",
      "text": "ீ஺ேି஽௘௖",
      "page": 57
    },
    {
      "level": "H1",
      "text": "= −𝑙𝑜𝑔",
      "page": 57
    },
    {
      "level": "H1",
      "text": "𝐷𝑖𝑠",
      "page": 57
    },
    {
      "level": "H1",
      "text": "෥൯ቁ",
      "page": 57
    },
    {
      "level": "H1",
      "text": "(3.5)",
      "page": 57
    },
    {
      "level": "H1",
      "text": "3.2.4",
      "page": 57
    },
    {
      "level": "H1",
      "text": "身份保持损失",
      "page": 57
    },
    {
      "level": "H1",
      "text": "在合成正面中性面部图像的同时保留身份是本系统的关键部分。这是因为所",
      "page": 57
    },
    {
      "level": "H1",
      "text": "生成的图片要作为中性脸参考，用以剥离查询图像中的身份信息。",
      "page": 57
    },
    {
      "level": "H1",
      "text": "通过要求所生成的图像和目标图像（来自与输入图像的同一个人）在像素和",
      "page": 57
    },
    {
      "level": "H1",
      "text": "特征层面相似，可以使得变换网络学习到保持一些身份信息。然而，没有直接的",
      "page": 57
    },
    {
      "level": "H1",
      "text": "身份保持损失监督来奖励输入和生成的图像之间的身份相似性则无法明确的要",
      "page": 57
    },
    {
      "level": "H1",
      "text": "求网络具有这一特性。身份作为一种高层级的语义概念，需要在特征层面衡量其",
      "page": 57
    },
    {
      "level": "H1",
      "text": "相似性。一种可行的方法是通过惩罚人脸验证网络从输入与合成图片所提取的特",
      "page": 57
    },
    {
      "level": "H1",
      "text": "征的差异来保留身份信息。在本模型中使用的人脸验证网络是",
      "page": 57
    },
    {
      "level": "H1",
      "text": "Light CNN",
      "page": 57
    },
    {
      "level": "H1",
      "text": "。其是",
      "page": 57
    },
    {
      "level": "H1",
      "text": "3.1",
      "page": 57
    },
    {
      "level": "H1",
      "text": "难样本生成网络训练",
      "page": 57
    },
    {
      "level": "H1",
      "text": "Enc,",
      "page": 57
    },
    {
      "level": "H1",
      "text": "Dec,",
      "page": 57
    },
    {
      "level": "H1",
      "text": "Dis",
      "page": 57
    },
    {
      "level": "H1",
      "text": "初始化网络参数",
      "page": 57
    },
    {
      "level": "H1",
      "text": "Repeat",
      "page": 57
    },
    {
      "level": "H1",
      "text": "从数据集中随机选取",
      "page": 57
    },
    {
      "level": "H1",
      "text": "mini-batch",
      "page": 57
    },
    {
      "level": "H1",
      "text": "Enc",
      "page": 57
    },
    {
      "level": "H1",
      "text": "Dec",
      "page": 57
    },
    {
      "level": "H1",
      "text": "௠ୀଵ",
      "page": 57
    },
    {
      "level": "H1",
      "text": "௡ୀଵ",
      "page": 57
    },
    {
      "level": "H1",
      "text": "௦௬௠",
      "page": 57
    },
    {
      "level": "H1",
      "text": "௡ିଵ",
      "page": 57
    },
    {
      "level": "H1",
      "text": "ீ஺ேି஽௜௦",
      "page": 57
    },
    {
      "level": "H1",
      "text": "←−𝑙𝑜𝑔",
      "page": 57
    },
    {
      "level": "H1",
      "text": "𝐷𝑖𝑠(𝑔",
      "page": 57
    },
    {
      "level": "H1",
      "text": "−𝑙𝑜𝑔",
      "page": 57
    },
    {
      "level": "H1",
      "text": "1 −𝐷𝑖𝑠",
      "page": 57
    },
    {
      "level": "H1",
      "text": "𝐷𝑖𝑠(𝑥",
      "page": 57
    },
    {
      "level": "H1",
      "text": ") −𝜙",
      "page": 57
    },
    {
      "level": "H1",
      "text": "(𝑥)",
      "page": 57
    },
    {
      "level": "H1",
      "text": "௟ୀଵ",
      "page": 57
    },
    {
      "level": "H1",
      "text": "௣௜௫௘௟",
      "page": 57
    },
    {
      "level": "H1",
      "text": "根据梯度更新网络",
      "page": 57
    },
    {
      "level": "H1",
      "text": "ಶ೙೎",
      "page": 57
    },
    {
      "level": "H1",
      "text": "௙௘௔௧",
      "page": 57
    },
    {
      "level": "H1",
      "text": "+ λ",
      "page": 57
    },
    {
      "level": "H1",
      "text": "←−∇",
      "page": 57
    },
    {
      "level": "H1",
      "text": "+  𝜂ℒ",
      "page": 57
    },
    {
      "level": "H1",
      "text": "ವ೔ೞ",
      "page": 57
    },
    {
      "level": "H1",
      "text": "ீ஺ேି஽",
      "page": 57
    },
    {
      "level": "H1",
      "text": "Until",
      "page": 57
    },
    {
      "level": "H1",
      "text": "训练损失收敛",
      "page": 57
    },
    {
      "level": "H1",
      "text": "基于难样本生成的人脸表情识别",
      "page": 58
    },
    {
      "level": "H1",
      "text": "一个紧凑的网络，只有",
      "page": 58
    },
    {
      "level": "H1",
      "text": "个具有",
      "page": 58
    },
    {
      "level": "H1",
      "text": "Max-Feature-Map",
      "page": 58
    },
    {
      "level": "H1",
      "text": "操作的卷积层和",
      "page": 58
    },
    {
      "level": "H1",
      "text": "个最大化池",
      "page": 58
    },
    {
      "level": "H1",
      "text": "[133]",
      "page": 58
    },
    {
      "level": "H1",
      "text": "。实用小尺寸的",
      "page": 58
    },
    {
      "level": "H1",
      "text": "Light CNN",
      "page": 58
    },
    {
      "level": "H1",
      "text": "主要是考虑到节约计算成本。在这项工作中，",
      "page": 58
    },
    {
      "level": "H1",
      "text": "的最后两层的激活来定义身份保留损失：",
      "page": 58
    },
    {
      "level": "H1",
      "text": "= ∑",
      "page": 58
    },
    {
      "level": "H1",
      "text": ") −𝜙",
      "page": 58
    },
    {
      "level": "H1",
      "text": "(𝑥)",
      "page": 58
    },
    {
      "level": "H1",
      "text": "௠ୀଵ",
      "page": 58
    },
    {
      "level": "H1",
      "text": "௡ୀଵ",
      "page": 58
    },
    {
      "level": "H1",
      "text": "௟ୀଵ",
      "page": 58
    },
    {
      "level": "H1",
      "text": "(3.6)",
      "page": 58
    },
    {
      "level": "H1",
      "text": "表示第",
      "page": 58
    },
    {
      "level": "H1",
      "text": "层的宽度和高度，",
      "page": 58
    },
    {
      "level": "H1",
      "text": "是特征图上",
      "page": 58
    },
    {
      "level": "H1",
      "text": "n, m",
      "page": 58
    },
    {
      "level": "H1",
      "text": "点的值。",
      "page": 58
    },
    {
      "level": "H1",
      "text": "3.2.5",
      "page": 58
    },
    {
      "level": "H1",
      "text": "像素级相似损失",
      "page": 58
    },
    {
      "level": "H1",
      "text": "对抗训练对超参数敏感而且往往难以训练。使用具有相对较小权重的像素级",
      "page": 58
    },
    {
      "level": "H1",
      "text": "损失中是稳定训练和加速优化的一种有效方法。像素级的",
      "page": 58
    },
    {
      "level": "H1",
      "text": "损失可表示为：",
      "page": 58
    },
    {
      "level": "H1",
      "text": "௣௜௫௘௟",
      "page": 58
    },
    {
      "level": "H1",
      "text": "(3.7)",
      "page": 58
    },
    {
      "level": "H1",
      "text": "个像素的像素级灰度值。",
      "page": 58
    },
    {
      "level": "H1",
      "text": "3.2.6",
      "page": 58
    },
    {
      "level": "H1",
      "text": "优化目标融合",
      "page": 58
    },
    {
      "level": "H1",
      "text": "通过合理的地选择上述损失函数以及对抗网络中的迭代优化，模型得以同时",
      "page": 58
    },
    {
      "level": "H1",
      "text": "Enc",
      "page": 58
    },
    {
      "level": "H1",
      "text": "Dec",
      "page": 58
    },
    {
      "level": "H1",
      "text": "Dis",
      "page": 58
    },
    {
      "level": "H1",
      "text": "三个模组。这些模组并不优化所有损失函数的和。具体的，",
      "page": 58
    },
    {
      "level": "H1",
      "text": "应该只尝试最小化",
      "page": 58
    },
    {
      "level": "H1",
      "text": "஽௜௦",
      "page": 58
    },
    {
      "level": "H1",
      "text": "。来自对抗性损失和对称性损失的误差信号不会反向",
      "page": 58
    },
    {
      "level": "H1",
      "text": "传播到",
      "page": 58
    },
    {
      "level": "H1",
      "text": "。难样本生成网络训练流程详述于算法",
      "page": 58
    },
    {
      "level": "H1",
      "text": "3.1",
      "page": 58
    },
    {
      "level": "H1",
      "text": "一系列取值在",
      "page": 58
    },
    {
      "level": "H1",
      "text": "之间的权衡参数用于平衡上述损失函数。算法",
      "page": 58
    },
    {
      "level": "H1",
      "text": "௙௘௔௧",
      "page": 58
    },
    {
      "level": "H1",
      "text": "的权衡参数。参数",
      "page": 58
    },
    {
      "level": "H1",
      "text": "用于对",
      "page": 58
    },
    {
      "level": "H1",
      "text": "௦௬௠",
      "page": 58
    },
    {
      "level": "H1",
      "text": "进行加权。因为",
      "page": 58
    },
    {
      "level": "H1",
      "text": "也接收来自",
      "page": 58
    },
    {
      "level": "H1",
      "text": "的误差信号，参数",
      "page": 58
    },
    {
      "level": "H1",
      "text": "用于加权",
      "page": 58
    },
    {
      "level": "H1",
      "text": "的能力。",
      "page": 58
    },
    {
      "level": "H1",
      "text": "3.4",
      "page": 58
    },
    {
      "level": "H1",
      "text": "中展示了难样本生成模型的一些输入与输出对。由于常见的量化指",
      "page": 58
    },
    {
      "level": "H1",
      "text": "标（例如，一组验证样本的对数似然（",
      "page": 58
    },
    {
      "level": "H1",
      "text": "log-likelihood",
      "page": 58
    },
    {
      "level": "H1",
      "text": "））通常不适用于感知生成模",
      "page": 58
    },
    {
      "level": "H1",
      "text": "[129]",
      "page": 58
    },
    {
      "level": "H1",
      "text": "节中采用视觉质量的定性比较和身份保持的定量评估来衡量系统",
      "page": 58
    },
    {
      "level": "H1",
      "text": "的有效性。",
      "page": 58
    },
    {
      "level": "H1",
      "text": "与利用其中间特征用于识别任务的先前生成方法不同，本章所得到的去除表",
      "page": 58
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 59
    },
    {
      "level": "H1",
      "text": "情和姿势的面部图像具有用于若干其他应用的潜力，例如面部表情、面部识别，",
      "page": 59
    },
    {
      "level": "H1",
      "text": "以及面部属性识别等。",
      "page": 59
    },
    {
      "level": "H1",
      "text": "3.4",
      "page": 59
    },
    {
      "level": "H1",
      "text": "CK +",
      "page": 59
    },
    {
      "level": "H1",
      "text": "MMI",
      "page": 59
    },
    {
      "level": "H1",
      "text": "Oulu-CASIA",
      "page": 59
    },
    {
      "level": "H1",
      "text": "数据集的难样本生成（",
      "page": 59
    },
    {
      "level": "H1",
      "text": "HNG",
      "page": 59
    },
    {
      "level": "H1",
      "text": "）网络的输入",
      "page": 59
    },
    {
      "level": "H1",
      "text": "对。每对中的上一行：数据库中具有不同表情的某一个体（从左到右：愤怒，厌恶，恐",
      "page": 59
    },
    {
      "level": "H1",
      "text": "惧，快乐，中立，悲伤和惊讶）。每对中的下一行：从上面一行中富有表情的脸部图像的",
      "page": 59
    },
    {
      "level": "H1",
      "text": "输入生成标准化的脸部图像。",
      "page": 59
    },
    {
      "level": "H1",
      "text": "Figure 3.4 Input-output pairs of the proposed reference generation (HNG) network from the",
      "page": 59
    },
    {
      "level": "H1",
      "text": "CK + , MMI and Oulu-CASIA dataset. Top row in each pair: a subject in a database with",
      "page": 59
    },
    {
      "level": "H1",
      "text": "different expressions (from left to right: angry, disgust, fear, happy, neutral, sad and",
      "page": 59
    },
    {
      "level": "H1",
      "text": "surprise). Bottom row in each pair: generated normalized face im- ages from the input of the",
      "page": 59
    },
    {
      "level": "H1",
      "text": "expressive face images in the row above.",
      "page": 59
    },
    {
      "level": "H1",
      "text": "3.3",
      "page": 59
    },
    {
      "level": "H1",
      "text": "径向度量学习",
      "page": 59
    },
    {
      "level": "H1",
      "text": "本章所提出的径向度量学习仅需要将查询样本的特征向量",
      "page": 59
    },
    {
      "level": "H1",
      "text": "与其生成的参",
      "page": 59
    },
    {
      "level": "H1",
      "text": "考图像的特征向量",
      "page": 59
    },
    {
      "level": "H1",
      "text": "及其簇中心",
      "page": 59
    },
    {
      "level": "H1",
      "text": "进行距离比较，并详述于算法",
      "page": 59
    },
    {
      "level": "H1",
      "text": "3.2",
      "page": 59
    },
    {
      "level": "H1",
      "text": "。通过引入",
      "page": 59
    },
    {
      "level": "H1",
      "text": "，以分别控制各个类内中心到类内样本的半径小于（",
      "page": 59
    },
    {
      "level": "H1",
      "text": "/ 2",
      "page": 59
    },
    {
      "level": "H1",
      "text": "），到生成的参",
      "page": 59
    },
    {
      "level": "H1",
      "text": "考图像的距离远于（",
      "page": 59
    },
    {
      "level": "H1",
      "text": "）。径向度量学习的损失函数的表述如下。",
      "page": 59
    },
    {
      "level": "H1",
      "text": "ℒ({𝑥",
      "page": 59
    },
    {
      "level": "H1",
      "text": "௜ୀଵ",
      "page": 59
    },
    {
      "level": "H1",
      "text": ", {𝑥",
      "page": 59
    },
    {
      "level": "H1",
      "text": "; 𝑓)",
      "page": 59
    },
    {
      "level": "H1",
      "text": "𝑚𝑎𝑥",
      "page": 59
    },
    {
      "level": "H1",
      "text": "0, D",
      "page": 59
    },
    {
      "level": "H1",
      "text": ", 𝐶",
      "page": 59
    },
    {
      "level": "H1",
      "text": "− 𝑇+",
      "page": 59
    },
    {
      "level": "H1",
      "text": "+ 𝑚𝑎𝑥",
      "page": 59
    },
    {
      "level": "H1",
      "text": "+ 𝑇−D",
      "page": 59
    },
    {
      "level": "H1",
      "text": "൯ቁቅ",
      "page": 59
    },
    {
      "level": "H1",
      "text": "(3.8)",
      "page": 59
    },
    {
      "level": "H1",
      "text": "基于难样本生成的人脸表情识别",
      "page": 60
    },
    {
      "level": "H1",
      "text": "3.2",
      "page": 60
    },
    {
      "level": "H1",
      "text": "径向度量学习算法",
      "page": 60
    },
    {
      "level": "H1",
      "text": "Input",
      "page": 60
    },
    {
      "level": "H1",
      "text": "随机选择",
      "page": 60
    },
    {
      "level": "H1",
      "text": "个查询样本",
      "page": 60
    },
    {
      "level": "H1",
      "text": "௜ୀଵ",
      "page": 60
    },
    {
      "level": "H1",
      "text": "及其生成的参考图像",
      "page": 60
    },
    {
      "level": "H1",
      "text": "Output:",
      "page": 60
    },
    {
      "level": "H1",
      "text": "人脸表情识别网络的参数",
      "page": 60
    },
    {
      "level": "H1",
      "text": "θFER",
      "page": 60
    },
    {
      "level": "H1",
      "text": "CNN",
      "page": 60
    },
    {
      "level": "H1",
      "text": "将图片映射到特征空间",
      "page": 60
    },
    {
      "level": "H1",
      "text": "𝑎𝑛𝑑 {𝑓",
      "page": 60
    },
    {
      "level": "H1",
      "text": "计算每一个类别的聚类中心",
      "page": 60
    },
    {
      "level": "H1",
      "text": "ୖ୑୐",
      "page": 60
    },
    {
      "level": "H1",
      "text": "max",
      "page": 60
    },
    {
      "level": "H1",
      "text": "0, −H",
      "page": 60
    },
    {
      "level": "H1",
      "text": ", C",
      "page": 60
    },
    {
      "level": "H1",
      "text": "+ 1",
      "page": 60
    },
    {
      "level": "H1",
      "text": "+ max",
      "page": 60
    },
    {
      "level": "H1",
      "text": "0, H",
      "page": 60
    },
    {
      "level": "H1",
      "text": "୧ୀଵ",
      "page": 60
    },
    {
      "level": "H1",
      "text": "ୱ୭୤୲୫ୟ୶",
      "page": 60
    },
    {
      "level": "H1",
      "text": "−log (e",
      "page": 60
    },
    {
      "level": "H1",
      "text": "ି୫ୟ୶",
      "page": 60
    },
    {
      "level": "H1",
      "text": "/ ∑e",
      "page": 60
    },
    {
      "level": "H1",
      "text": "计算联合损失",
      "page": 60
    },
    {
      "level": "H1",
      "text": "+ α ℒ",
      "page": 60
    },
    {
      "level": "H1",
      "text": "计算梯度",
      "page": 60
    },
    {
      "level": "H1",
      "text": "更新参数",
      "page": 60
    },
    {
      "level": "H1",
      "text": "End while",
      "page": 60
    },
    {
      "level": "H1",
      "text": "仅当从所有在线挖掘的示例",
      "page": 60
    },
    {
      "level": "H1",
      "text": "到其更新后的",
      "page": 60
    },
    {
      "level": "H1",
      "text": "的距离小于（",
      "page": 60
    },
    {
      "level": "H1",
      "text": "/ 2",
      "page": 60
    },
    {
      "level": "H1",
      "text": "）并且从",
      "page": 60
    },
    {
      "level": "H1",
      "text": "所有生成的参考",
      "page": 60
    },
    {
      "level": "H1",
      "text": "距离大于（",
      "page": 60
    },
    {
      "level": "H1",
      "text": "），损失",
      "page": 60
    },
    {
      "level": "H1",
      "text": "ℒ({𝑥",
      "page": 60
    },
    {
      "level": "H1",
      "text": ", {𝑥",
      "page": 60
    },
    {
      "level": "H1",
      "text": "; 𝑓)",
      "page": 60
    },
    {
      "level": "H1",
      "text": "才可以得到零值。对此损失的简化几何解释如图",
      "page": 60
    },
    {
      "level": "H1",
      "text": "3.5",
      "page": 60
    },
    {
      "level": "H1",
      "text": "所示。",
      "page": 60
    },
    {
      "level": "H1",
      "text": "通过为",
      "page": 60
    },
    {
      "level": "H1",
      "text": "和τ分配不同的值可以为网络调整难度，灵活的定义学习任务。不",
      "page": 60
    },
    {
      "level": "H1",
      "text": "同于中心损失（",
      "page": 60
    },
    {
      "level": "H1",
      "text": "center loss",
      "page": 60
    },
    {
      "level": "H1",
      "text": "[135]",
      "page": 60
    },
    {
      "level": "H1",
      "text": "要求类内变化为零（即",
      "page": 60
    },
    {
      "level": "H1",
      "text": "），因为人脸表情",
      "page": 60
    },
    {
      "level": "H1",
      "text": "识别训练集通常包含一些不可靠的标签",
      "page": 60
    },
    {
      "level": "H1",
      "text": "[93][94]",
      "page": 60
    },
    {
      "level": "H1",
      "text": "。但是，这两个超参数需要手动调整",
      "page": 60
    },
    {
      "level": "H1",
      "text": "和验证。类似于上一章所述方法，在此将参考距离",
      "page": 60
    },
    {
      "level": "H1",
      "text": "表示为希望自动训练的函数",
      "page": 60
    },
    {
      "level": "H1",
      "text": "T(·,·)",
      "page": 60
    },
    {
      "level": "H1",
      "text": "，而不是常数。受半正定（",
      "page": 60
    },
    {
      "level": "H1",
      "text": "positive semi-definite, PSD",
      "page": 60
    },
    {
      "level": "H1",
      "text": "）的马氏距离矩阵",
      "page": 60
    },
    {
      "level": "H1",
      "text": "可以通过文献",
      "page": 60
    },
    {
      "level": "H1",
      "text": "[87]",
      "page": 60
    },
    {
      "level": "H1",
      "text": "中的线性全连接层进行计算的启发，实现两个参数的自动训练。",
      "page": 60
    },
    {
      "level": "H1",
      "text": "由于参考距离",
      "page": 60
    },
    {
      "level": "H1",
      "text": "和距离函数",
      "page": 60
    },
    {
      "level": "H1",
      "text": "的差异需要以两个项分别计算。一种可能的解决",
      "page": 60
    },
    {
      "level": "H1",
      "text": "方案是通过线性全连接层计算直接计算（",
      "page": 60
    },
    {
      "level": "H1",
      "text": "）函数。",
      "page": 60
    },
    {
      "level": "H1",
      "text": "= ‖𝑓",
      "page": 60
    },
    {
      "level": "H1",
      "text": "= (𝑓",
      "page": 60
    },
    {
      "level": "H1",
      "text": "M(𝑓",
      "page": 60
    },
    {
      "level": "H1",
      "text": "(3.9)",
      "page": 60
    },
    {
      "level": "H1",
      "text": "由于度量矩阵",
      "page": 60
    },
    {
      "level": "H1",
      "text": "本身是二次型的，假设",
      "page": 60
    },
    {
      "level": "H1",
      "text": "具有简单的二次形式",
      "page": 60
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 61
    },
    {
      "level": "H1",
      "text": "3.5",
      "page": 61
    },
    {
      "level": "H1",
      "text": "本小节提出的的径向度量学习框架。没有边界的小圆圈是样本的特征表示（即，",
      "page": 61
    },
    {
      "level": "H1",
      "text": "面部表情图像），并且不同的类别由不同的颜色表示。具有彩色边框的小灰色圆圈是它们",
      "page": 61
    },
    {
      "level": "H1",
      "text": "相应的生成的参考（即，标准化的面部图像）。带有彩色边框的橙色点是每个类的聚类中",
      "page": 61
    },
    {
      "level": "H1",
      "text": "心。大虚线圆圈是特征空间中每个类别的边界，希望它们具有较小的半径并且彼此远离。",
      "page": 61
    },
    {
      "level": "H1",
      "text": "Figure 3.5  The proposed radial metric learning framework. A small circle without border",
      "page": 61
    },
    {
      "level": "H1",
      "text": "is the representation of a sample (",
      "page": 61
    },
    {
      "level": "H1",
      "text": "i.e",
      "page": 61
    },
    {
      "level": "H1",
      "text": "., facial expression image) and the different classes are",
      "page": 61
    },
    {
      "level": "H1",
      "text": "represented by different colors. The small gray circle with colored border are their",
      "page": 61
    },
    {
      "level": "H1",
      "text": "corresponding generated references (",
      "page": 61
    },
    {
      "level": "H1",
      "text": "i.e.,",
      "page": 61
    },
    {
      "level": "H1",
      "text": "normalized face images). The orange points with",
      "page": 61
    },
    {
      "level": "H1",
      "text": "colored border are the cluster centers of each classes. The big dashed circles are the",
      "page": 61
    },
    {
      "level": "H1",
      "text": "boundaries of each classes in the feature space, which are expected to have small radius and",
      "page": 61
    },
    {
      "level": "H1",
      "text": "far away from each other.",
      "page": 61
    },
    {
      "level": "H1",
      "text": "+ 𝑓",
      "page": 61
    },
    {
      "level": "H1",
      "text": "+ 𝑐",
      "page": 61
    },
    {
      "level": "H1",
      "text": ") + 𝑏",
      "page": 61
    },
    {
      "level": "H1",
      "text": "(3.10)",
      "page": 61
    },
    {
      "level": "H1",
      "text": "𝑑× 𝑑",
      "page": 61
    },
    {
      "level": "H1",
      "text": "大小的实对称矩阵，",
      "page": 61
    },
    {
      "level": "H1",
      "text": "维向量，",
      "page": 61
    },
    {
      "level": "H1",
      "text": "是偏置项。",
      "page": 61
    },
    {
      "level": "H1",
      "text": "新的二次表达式",
      "page": 61
    },
    {
      "level": "H1",
      "text": "T(𝑓",
      "page": 61
    },
    {
      "level": "H1",
      "text": ") −",
      "page": 61
    },
    {
      "level": "H1",
      "text": "被用以组合参考距离函数",
      "page": 61
    },
    {
      "level": "H1",
      "text": "氏距离度量函数",
      "page": 61
    },
    {
      "level": "H1",
      "text": "可得：",
      "page": 61
    },
    {
      "level": "H1",
      "text": "−2M",
      "page": 61
    },
    {
      "level": "H1",
      "text": "+ 2M",
      "page": 61
    },
    {
      "level": "H1",
      "text": "(3.11)",
      "page": 61
    },
    {
      "level": "H1",
      "text": "+ c",
      "page": 61
    },
    {
      "level": "H1",
      "text": "(3.12)",
      "page": 61
    },
    {
      "level": "H1",
      "text": "。假设",
      "page": 61
    },
    {
      "level": "H1",
      "text": "PSD",
      "page": 61
    },
    {
      "level": "H1",
      "text": "是负半定（",
      "page": 61
    },
    {
      "level": "H1",
      "text": "negative semi-",
      "page": 61
    },
    {
      "level": "H1",
      "text": "基于难样本生成的人脸表情识别",
      "page": 62
    },
    {
      "level": "H1",
      "text": "definite, NSD",
      "page": 62
    },
    {
      "level": "H1",
      "text": "可以被分别分解为",
      "page": 62
    },
    {
      "level": "H1",
      "text": "。那么",
      "page": 62
    },
    {
      "level": "H1",
      "text": "可以进一步",
      "page": 62
    },
    {
      "level": "H1",
      "text": "表述如下：",
      "page": 62
    },
    {
      "level": "H1",
      "text": "+ 𝑓",
      "page": 62
    },
    {
      "level": "H1",
      "text": "+  𝑐",
      "page": 62
    },
    {
      "level": "H1",
      "text": ") + 𝑏",
      "page": 62
    },
    {
      "level": "H1",
      "text": "(3.13)",
      "page": 62
    },
    {
      "level": "H1",
      "text": ") + 1",
      "page": 62
    },
    {
      "level": "H1",
      "text": ") + (L",
      "page": 62
    },
    {
      "level": "H1",
      "text": ") + 𝑐",
      "page": 62
    },
    {
      "level": "H1",
      "text": "(3.14)",
      "page": 62
    },
    {
      "level": "H1",
      "text": "由上述推导可以得到一种通用的，计算上可行的地适应学习损失函数。按照",
      "page": 62
    },
    {
      "level": "H1",
      "text": "先前的符号表示并将",
      "page": 62
    },
    {
      "level": "H1",
      "text": ", L",
      "page": 62
    },
    {
      "level": "H1",
      "text": ", 𝑐)",
      "page": 62
    },
    {
      "level": "H1",
      "text": "写作为可以通过线性全连接层学习的",
      "page": 62
    },
    {
      "level": "H1",
      "text": "可得：",
      "page": 62
    },
    {
      "level": "H1",
      "text": "ℒ(W, {𝑥",
      "page": 62
    },
    {
      "level": "H1",
      "text": "௜ୀଵ",
      "page": 62
    },
    {
      "level": "H1",
      "text": ", {𝑥",
      "page": 62
    },
    {
      "level": "H1",
      "text": "; 𝑓) =",
      "page": 62
    },
    {
      "level": "H1",
      "text": "𝑚𝑎𝑥",
      "page": 62
    },
    {
      "level": "H1",
      "text": ", 𝐶",
      "page": 62
    },
    {
      "level": "H1",
      "text": "+ 𝑚𝑎𝑥",
      "page": 62
    },
    {
      "level": "H1",
      "text": "0, H",
      "page": 62
    },
    {
      "level": "H1",
      "text": "(3.15)",
      "page": 62
    },
    {
      "level": "H1",
      "text": "此外，将（",
      "page": 62
    },
    {
      "level": "H1",
      "text": "τ/2",
      "page": 62
    },
    {
      "level": "H1",
      "text": "）简化为常数",
      "page": 62
    },
    {
      "level": "H1",
      "text": "，因为将其改为任何其他正值只会导致矩阵乘",
      "page": 62
    },
    {
      "level": "H1",
      "text": "以相应的因子，而神经网络完全可以自适应的调整。铰链损失（",
      "page": 62
    },
    {
      "level": "H1",
      "text": "hinge-loss",
      "page": 62
    },
    {
      "level": "H1",
      "text": "）函数",
      "page": 62
    },
    {
      "level": "H1",
      "text": "形式的最终损失函数如下：",
      "page": 62
    },
    {
      "level": "H1",
      "text": "0,1 −H",
      "page": 62
    },
    {
      "level": "H1",
      "text": "+ 1",
      "page": 62
    },
    {
      "level": "H1",
      "text": "(3.16)",
      "page": 62
    },
    {
      "level": "H1",
      "text": "通过这一系列操作，自适应阈值可以由线性全连接层端到端的学习",
      "page": 62
    },
    {
      "level": "H1",
      "text": "[87]",
      "page": 62
    },
    {
      "level": "H1",
      "text": "向度量学习损失也可以很容易地用作三重组损失及其衍生损失函数的替代。",
      "page": 62
    },
    {
      "level": "H1",
      "text": "在径向度量学习中，对于由",
      "page": 62
    },
    {
      "level": "H1",
      "text": "个训练样本的数据集，每次迭代即遍历所以训",
      "page": 62
    },
    {
      "level": "H1",
      "text": "练样本所需的特征提取次数为",
      "page": 62
    },
    {
      "level": "H1",
      "text": "次，总的距离比较的总次数为",
      "page": 62
    },
    {
      "level": "H1",
      "text": "。通常，",
      "page": 62
    },
    {
      "level": "H1",
      "text": "，例如数百张图片。三重组损失和",
      "page": 62
    },
    {
      "level": "H1",
      "text": "+1)",
      "page": 62
    },
    {
      "level": "H1",
      "text": "元组损失会进行",
      "page": 62
    },
    {
      "level": "H1",
      "text": "次比较，对",
      "page": 62
    },
    {
      "level": "H1",
      "text": "比度损失和",
      "page": 62
    },
    {
      "level": "H1",
      "text": "CCL",
      "page": 62
    },
    {
      "level": "H1",
      "text": "比较，而",
      "page": 62
    },
    {
      "level": "H1",
      "text": "N+M",
      "page": 62
    },
    {
      "level": "H1",
      "text": "元组簇损失在使用一些",
      "page": 62
    },
    {
      "level": "H1",
      "text": "FER",
      "page": 62
    },
    {
      "level": "H1",
      "text": "数据集",
      "page": 62
    },
    {
      "level": "H1",
      "text": "的特殊结构（即每个人具有所有",
      "page": 62
    },
    {
      "level": "H1",
      "text": "个表达式）的严格样本挖掘后需要",
      "page": 62
    },
    {
      "level": "H1",
      "text": "次比较，其中",
      "page": 62
    },
    {
      "level": "H1",
      "text": "是挖掘的正样本的数量和挖掘的负样本数量。即使对于中",
      "page": 62
    },
    {
      "level": "H1",
      "text": "等大小的数据集，将所有可能有意义的三元组加载到有限的内存中进行模型训练",
      "page": 62
    },
    {
      "level": "H1",
      "text": "也是难以处理的。而径向度量学习则可以适用于更大的数据集。利用预定义的锚",
      "page": 62
    },
    {
      "level": "H1",
      "text": "点（即",
      "page": 62
    },
    {
      "level": "H1",
      "text": "），径向度量学习也减轻了锚点选择的难度",
      "page": 62
    },
    {
      "level": "H1",
      "text": "[66]",
      "page": 62
    },
    {
      "level": "H1",
      "text": "与上一章所采用的双分支结构一样，径向度量学习损失用以代替",
      "page": 62
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 63
    },
    {
      "level": "H1",
      "text": "簇损失，并与交叉熵损失联合优化。",
      "page": 63
    },
    {
      "level": "H1",
      "text": "3.4",
      "page": 63
    },
    {
      "level": "H1",
      "text": "3.4.1",
      "page": 63
    },
    {
      "level": "H1",
      "text": "数据集",
      "page": 63
    },
    {
      "level": "H1",
      "text": "除了专用于人脸识别的数据集之外，用于面部识别的各种面部图像的大数据",
      "page": 63
    },
    {
      "level": "H1",
      "text": "集在线公开可用。使用",
      "page": 63
    },
    {
      "level": "H1",
      "text": "VGG-Face",
      "page": 63
    },
    {
      "level": "H1",
      "text": "[132]",
      "page": 63
    },
    {
      "level": "H1",
      "text": "的训练数据集扩展数据，用于中性面",
      "page": 63
    },
    {
      "level": "H1",
      "text": "生成。它包含大约",
      "page": 63
    },
    {
      "level": "H1",
      "text": "260",
      "page": 63
    },
    {
      "level": "H1",
      "text": "万张脸部图像，但这些图像中很少有满足我们对中性表情",
      "page": 63
    },
    {
      "level": "H1",
      "text": "的要求，正面没有遮挡，以及面部区域有足够分辨率。使用",
      "page": 63
    },
    {
      "level": "H1",
      "text": "Google Cloud Vision",
      "page": 63
    },
    {
      "level": "H1",
      "text": "API",
      "page": 63
    },
    {
      "level": "H1",
      "text": "删除那些模糊，高情感分数或佩戴有眼镜，倾斜角度超过",
      "page": 63
    },
    {
      "level": "H1",
      "text": "的图像。这些正",
      "page": 63
    },
    {
      "level": "H1",
      "text": "面和中性面部图像用作目标和指导集样本。与这些筛选过的图像来自相同个体的",
      "page": 63
    },
    {
      "level": "H1",
      "text": "不符合要求的图像被用作预训练阶段的输入。预处理包括对齐所有样本并裁剪为",
      "page": 63
    },
    {
      "level": "H1",
      "text": "64×64",
      "page": 63
    },
    {
      "level": "H1",
      "text": "灰度图像。在过滤之后，有大约",
      "page": 63
    },
    {
      "level": "H1",
      "text": "12000",
      "page": 63
    },
    {
      "level": "H1",
      "text": "目标图像（小于原始集合的",
      "page": 63
    },
    {
      "level": "H1",
      "text": "0.5",
      "page": 63
    },
    {
      "level": "H1",
      "text": "50000",
      "page": 63
    },
    {
      "level": "H1",
      "text": "输入目标对。这些数据用于预训练以初始化网络参数，然后使用",
      "page": 63
    },
    {
      "level": "H1",
      "text": "CMU",
      "page": 63
    },
    {
      "level": "H1",
      "text": "Multi-PIE",
      "page": 63
    },
    {
      "level": "H1",
      "text": "[102]",
      "page": 63
    },
    {
      "level": "H1",
      "text": "进行微调。",
      "page": 63
    },
    {
      "level": "H1",
      "text": "3.6",
      "page": 63
    },
    {
      "level": "H1",
      "text": "数据集的样本。每行包含同一个人的面部图像。",
      "page": 63
    },
    {
      "level": "H1",
      "text": "Figure 3.6  Samples from the VGG-Face dataset. Each row contains the face images of the",
      "page": 63
    },
    {
      "level": "H1",
      "text": "same person.",
      "page": 63
    },
    {
      "level": "H1",
      "text": "基于难样本生成的人脸表情识别",
      "page": 64
    },
    {
      "level": "H1",
      "text": "3.7",
      "page": 64
    },
    {
      "level": "H1",
      "text": "CMU Multi-PIE",
      "page": 64
    },
    {
      "level": "H1",
      "text": "数据集的样本。每行包含同一个人的面部图像。",
      "page": 64
    },
    {
      "level": "H1",
      "text": "Figure 3.7  Samples from the CMU Multi-PIE dataset. Each row contains images of the",
      "page": 64
    },
    {
      "level": "H1",
      "text": "same person.",
      "page": 64
    },
    {
      "level": "H1",
      "text": "[102]",
      "page": 64
    },
    {
      "level": "H1",
      "text": "包含超过",
      "page": 64
    },
    {
      "level": "H1",
      "text": "750,000",
      "page": 64
    },
    {
      "level": "H1",
      "text": "张来自",
      "page": 64
    },
    {
      "level": "H1",
      "text": "337",
      "page": 64
    },
    {
      "level": "H1",
      "text": "人的图像。这些图像拍摄自",
      "page": 64
    },
    {
      "level": "H1",
      "text": "个方向，以及",
      "page": 64
    },
    {
      "level": "H1",
      "text": "种照明条件。在采集阶段，有四个录音会话，指示受试者分",
      "page": 64
    },
    {
      "level": "H1",
      "text": "别展示中性，快乐，厌恶和惊讶的面部表情。相较于过滤的",
      "page": 64
    },
    {
      "level": "H1",
      "text": "VGG",
      "page": 64
    },
    {
      "level": "H1",
      "text": "人脸数据集，",
      "page": 64
    },
    {
      "level": "H1",
      "text": "它与人脸表情数据库更为相似。实际操作中只选择了几乎正面视图面（",
      "page": 64
    },
    {
      "level": "H1",
      "text": "-45°",
      "page": 64
    },
    {
      "level": "H1",
      "text": "45°",
      "page": 64
    },
    {
      "level": "H1",
      "text": "）的五组。来自",
      "page": 64
    },
    {
      "level": "H1",
      "text": "视图的中性图像用作目标图像和引导集。",
      "page": 64
    },
    {
      "level": "H1",
      "text": "3.4.2",
      "page": 64
    },
    {
      "level": "H1",
      "text": "预处理及训练流程",
      "page": 64
    },
    {
      "level": "H1",
      "text": "对于数据集中的原始图像，面部注册（",
      "page": 64
    },
    {
      "level": "H1",
      "text": "face registration",
      "page": 64
    },
    {
      "level": "H1",
      "text": "）是获得良好性能的",
      "page": 64
    },
    {
      "level": "H1",
      "text": "关键步骤。主动外观模型（",
      "page": 64
    },
    {
      "level": "H1",
      "text": "Active Appearance Model, AAM",
      "page": 64
    },
    {
      "level": "H1",
      "text": "[22]",
      "page": 64
    },
    {
      "level": "H1",
      "text": "IntraFace",
      "page": 64
    },
    {
      "level": "H1",
      "text": "[100]",
      "page": 64
    },
    {
      "level": "H1",
      "text": "用于定位",
      "page": 64
    },
    {
      "level": "H1",
      "text": "个面部标志。然后，进行面部配准（",
      "page": 64
    },
    {
      "level": "H1",
      "text": "face alignment",
      "page": 64
    },
    {
      "level": "H1",
      "text": "）以减少旋转",
      "page": 64
    },
    {
      "level": "H1",
      "text": "变化并基于这些标记的坐标将感兴趣区域（",
      "page": 64
    },
    {
      "level": "H1",
      "text": "region of interest",
      "page": 64
    },
    {
      "level": "H1",
      "text": "ROI",
      "page": 64
    },
    {
      "level": "H1",
      "text": "）裁剪为",
      "page": 64
    },
    {
      "level": "H1",
      "text": "64×64",
      "page": 64
    },
    {
      "level": "H1",
      "text": "的尺寸。接下来进行数据增强程序以增加训练图像的数量。在此选择从中心和四",
      "page": 64
    },
    {
      "level": "H1",
      "text": "个角落裁剪五个",
      "page": 64
    },
    {
      "level": "H1",
      "text": "60×60",
      "page": 64
    },
    {
      "level": "H1",
      "text": "大小的色块，水平翻转并将它们转换为灰度图像。使用标",
      "page": 64
    },
    {
      "level": "H1",
      "text": "准直方图均衡和线性平面拟合处理所有图像以去除不平衡照明。最后，将它们归",
      "page": 64
    },
    {
      "level": "H1",
      "text": "一化为零均值和单位方差向量。在测试阶段，使用单个尺寸为",
      "page": 64
    },
    {
      "level": "H1",
      "text": "的中心剪切",
      "page": 64
    },
    {
      "level": "H1",
      "text": "为输入数据。",
      "page": 64
    },
    {
      "level": "H1",
      "text": "经过滤的",
      "page": 64
    },
    {
      "level": "H1",
      "text": "VGG-FaceNet",
      "page": 64
    },
    {
      "level": "H1",
      "text": "Multi-PIE",
      "page": 64
    },
    {
      "level": "H1",
      "text": "图像用于预训练中性面生成网络并进行",
      "page": 64
    },
    {
      "level": "H1",
      "text": "300",
      "page": 64
    },
    {
      "level": "H1",
      "text": "个周期的训练，使用动量系数为",
      "page": 64
    },
    {
      "level": "H1",
      "text": "0.9",
      "page": 64
    },
    {
      "level": "H1",
      "text": "的随机梯度下降来优化损失函数。基于",
      "page": 64
    },
    {
      "level": "H1",
      "text": "使用验证集优化参数选择，初始网络学习速率、批量大小和权重衰减参数分别设",
      "page": 64
    },
    {
      "level": "H1",
      "text": "0.1",
      "page": 64
    },
    {
      "level": "H1",
      "text": "128",
      "page": 64
    },
    {
      "level": "H1",
      "text": "0.0001",
      "page": 64
    },
    {
      "level": "H1",
      "text": "。如果训练损失增加超过",
      "page": 64
    },
    {
      "level": "H1",
      "text": "％或者验证准确度在十个时",
      "page": 64
    },
    {
      "level": "H1",
      "text": "期内没有改善，则学习率减半并且重新加载具有最佳损失的先前网络。选择最高",
      "page": 64
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 65
    },
    {
      "level": "H1",
      "text": "精度的训练时代作为预训练的模型。在微调阶段，设置小批量（",
      "page": 65
    },
    {
      "level": "H1",
      "text": "mini-batch",
      "page": 65
    },
    {
      "level": "H1",
      "text": "）大小",
      "page": 65
    },
    {
      "level": "H1",
      "text": "为数据集中的表情类别数量的两倍。使用随机搜索用于从每个表情类中选择",
      "page": 65
    },
    {
      "level": "H1",
      "text": "图像以形成小批量集。元组大小设置为",
      "page": 65
    },
    {
      "level": "H1",
      "text": "。在所有的实验中，设置",
      "page": 65
    },
    {
      "level": "H1",
      "text": "0.1,",
      "page": 65
    },
    {
      "level": "H1",
      "text": "3 × 10",
      "page": 65
    },
    {
      "level": "H1",
      "text": "= 10",
      "page": 65
    },
    {
      "level": "H1",
      "text": "= 0.3",
      "page": 65
    },
    {
      "level": "H1",
      "text": "由手动确定调整。使用",
      "page": 65
    },
    {
      "level": "H1",
      "text": "Adam",
      "page": 65
    },
    {
      "level": "H1",
      "text": "[136]",
      "page": 65
    },
    {
      "level": "H1",
      "text": "进行随机优化，并",
      "page": 65
    },
    {
      "level": "H1",
      "text": "通过交叉验证选择其他超参数，例如联合学习的权重",
      "page": 65
    },
    {
      "level": "H1",
      "text": "和学习率。在测试阶段，",
      "page": 65
    },
    {
      "level": "H1",
      "text": "仅使用卷积层和具有",
      "page": 65
    },
    {
      "level": "H1",
      "text": "softmax",
      "page": 65
    },
    {
      "level": "H1",
      "text": "的表情分类分支来识别单个表情图像。",
      "page": 65
    },
    {
      "level": "H1",
      "text": "难样本生成编码器的细节与",
      "page": 65
    },
    {
      "level": "H1",
      "text": "[69]",
      "page": 65
    },
    {
      "level": "H1",
      "text": "保持一致。将隐向量",
      "page": 65
    },
    {
      "level": "H1",
      "text": "的维度固定为",
      "page": 65
    },
    {
      "level": "H1",
      "text": "256",
      "page": 65
    },
    {
      "level": "H1",
      "text": "过一系列反卷积操作（",
      "page": 65
    },
    {
      "level": "H1",
      "text": "fractional-strided convolutions, FConv",
      "page": 65
    },
    {
      "level": "H1",
      "text": "维的向量",
      "page": 65
    },
    {
      "level": "H1",
      "text": "z ∈",
      "page": 65
    },
    {
      "level": "H1",
      "text": "ଶହ଺",
      "page": 65
    },
    {
      "level": "H1",
      "text": "变换为合成图像",
      "page": 65
    },
    {
      "level": "H1",
      "text": "，其与",
      "page": 65
    },
    {
      "level": "H1",
      "text": "具有相同的大小。为了进一步将正面中",
      "page": 65
    },
    {
      "level": "H1",
      "text": "性脸分布的先验知识纳入训练过程，引入了一个鉴别器",
      "page": 65
    },
    {
      "level": "H1",
      "text": "Dis",
      "page": 65
    },
    {
      "level": "H1",
      "text": "来区分生成的面部图",
      "page": 65
    },
    {
      "level": "H1",
      "text": "像和指导集中的真实图像。",
      "page": 65
    },
    {
      "level": "H1",
      "text": "在卷积层中使用的非线性单元为",
      "page": 65
    },
    {
      "level": "H1",
      "text": "Leaky ReLU",
      "page": 65
    },
    {
      "level": "H1",
      "text": "[137]",
      "page": 65
    },
    {
      "level": "H1",
      "text": "，其中",
      "page": 65
    },
    {
      "level": "H1",
      "text": "LReLU(",
      "page": 65
    },
    {
      "level": "H1",
      "text": "𝑚𝑎𝑥(𝑥, 0) + σ𝑚𝑖𝑛(𝑥, 0)",
      "page": 65
    },
    {
      "level": "H1",
      "text": "。在实验中设置",
      "page": 65
    },
    {
      "level": "H1",
      "text": "𝜎= 0.3",
      "page": 65
    },
    {
      "level": "H1",
      "text": "。所有模型都使用深度学习框架",
      "page": 65
    },
    {
      "level": "H1",
      "text": "“Tensorflow",
      "page": 65
    },
    {
      "level": "H1",
      "text": "[138]",
      "page": 65
    },
    {
      "level": "H1",
      "text": "来实现。",
      "page": 65
    },
    {
      "level": "H1",
      "text": "3.8",
      "page": 65
    },
    {
      "level": "H1",
      "text": "输入，目标，由",
      "page": 65
    },
    {
      "level": "H1",
      "text": "HNG",
      "page": 65
    },
    {
      "level": "H1",
      "text": "网络生成的标准化面部的示例，由",
      "page": 65
    },
    {
      "level": "H1",
      "text": "网络生成标准化面",
      "page": 65
    },
    {
      "level": "H1",
      "text": "部而没有身份保持损失，并且仅使用自动编码器（",
      "page": 65
    },
    {
      "level": "H1",
      "text": "）结构重建中性面部。真实图像来自",
      "page": 65
    },
    {
      "level": "H1",
      "text": "CK +",
      "page": 65
    },
    {
      "level": "H1",
      "text": "数据集，其具有称为蔑视（",
      "page": 65
    },
    {
      "level": "H1",
      "text": "）的额外类别。",
      "page": 65
    },
    {
      "level": "H1",
      "text": "Figure 3.8  Examples of input, target, generated normalized face by HNG network,",
      "page": 65
    },
    {
      "level": "H1",
      "text": "generated normalized face by HNG network without identity-preserving loss and",
      "page": 65
    },
    {
      "level": "H1",
      "text": "reconstructed neutral face using only the auto-encoder (AE) structure. Real images are from",
      "page": 65
    },
    {
      "level": "H1",
      "text": "CK + dataset which has an additional calss called contempt (Co) class.",
      "page": 65
    },
    {
      "level": "H1",
      "text": "基于难样本生成的人脸表情识别",
      "page": 66
    },
    {
      "level": "H1",
      "text": "3.4.3",
      "page": 66
    },
    {
      "level": "H1",
      "text": "辅助网络的烧蚀实验",
      "page": 66
    },
    {
      "level": "H1",
      "text": "Light CNN",
      "page": 66
    },
    {
      "level": "H1",
      "text": "VGG-FaceNet",
      "page": 66
    },
    {
      "level": "H1",
      "text": "的前五层用于嵌入输入，目标或输出图像，用于",
      "page": 66
    },
    {
      "level": "H1",
      "text": "测量不同特征空间中的语义相似性。很明显，这两个网络会引入额外的计算成本。",
      "page": 66
    },
    {
      "level": "H1",
      "text": "本节的实验结果表明它们是必不可少的。",
      "page": 66
    },
    {
      "level": "H1",
      "text": "3.8",
      "page": 66
    },
    {
      "level": "H1",
      "text": "所示，在有和没有",
      "page": 66
    },
    {
      "level": "H1",
      "text": "的情况下训练的模型所生成的图像差异在视",
      "page": 66
    },
    {
      "level": "H1",
      "text": "觉外观较小。但具体的差异可以通过评估输入",
      "page": 66
    },
    {
      "level": "H1",
      "text": "输出图片间的身份相似性来量化",
      "page": 66
    },
    {
      "level": "H1",
      "text": "其对改善生成的面部的身份保持性的影响。在此使用的是完整的",
      "page": 66
    },
    {
      "level": "H1",
      "text": "VGG-",
      "page": 66
    },
    {
      "level": "H1",
      "text": "FaceNet",
      "page": 66
    },
    {
      "level": "H1",
      "text": "[132]",
      "page": 66
    },
    {
      "level": "H1",
      "text": "模型将输入输出图片提取出",
      "page": 66
    },
    {
      "level": "H1",
      "text": "1024",
      "page": 66
    },
    {
      "level": "H1",
      "text": "维的特征向量，并进行",
      "page": 66
    },
    {
      "level": "H1",
      "text": "距离计",
      "page": 66
    },
    {
      "level": "H1",
      "text": "算。图",
      "page": 66
    },
    {
      "level": "H1",
      "text": "3.9",
      "page": 66
    },
    {
      "level": "H1",
      "text": "展示了对于具有和不具有该损失的训练模型，面部表情图像与其对应",
      "page": 66
    },
    {
      "level": "H1",
      "text": "的合成结果之间的特征向量的",
      "page": 66
    },
    {
      "level": "H1",
      "text": "距离的分布。文献",
      "page": 66
    },
    {
      "level": "H1",
      "text": "中得出的经验值表明如果",
      "page": 66
    },
    {
      "level": "H1",
      "text": "他们的",
      "page": 66
    },
    {
      "level": "H1",
      "text": "距离小于阈值",
      "page": 66
    },
    {
      "level": "H1",
      "text": "1.242",
      "page": 66
    },
    {
      "level": "H1",
      "text": "，则考虑两个图片来自同一个人。所有使用身份保",
      "page": 66
    },
    {
      "level": "H1",
      "text": "留损失的合成图像都通过了",
      "page": 66
    },
    {
      "level": "H1",
      "text": "的人脸验证测试，但是当不使用身份保留损",
      "page": 66
    },
    {
      "level": "H1",
      "text": "失时，",
      "page": 66
    },
    {
      "level": "H1",
      "text": "％的图像识别为来自不同的人。",
      "page": 66
    },
    {
      "level": "H1",
      "text": "数据集合上的输入人脸与生成的归一化人脸对之间的",
      "page": 66
    },
    {
      "level": "H1",
      "text": "VGG-FaceNet L2",
      "page": 66
    },
    {
      "level": "H1",
      "text": "的直方图。蓝色：具有由",
      "page": 66
    },
    {
      "level": "H1",
      "text": "Light-CNN",
      "page": 66
    },
    {
      "level": "H1",
      "text": "计算的身份保留损失。橙色：没有身份保留损失。",
      "page": 66
    },
    {
      "level": "H1",
      "text": "Schroffet al",
      "page": 66
    },
    {
      "level": "H1",
      "text": "阈值。文献",
      "page": 66
    },
    {
      "level": "H1",
      "text": "LFW",
      "page": 66
    },
    {
      "level": "H1",
      "text": "数据集中聚类身份。如果没有",
      "page": 66
    },
    {
      "level": "H1",
      "text": "％生成的中性人脸将不会被视为与查询人脸具有同样的身份。",
      "page": 66
    },
    {
      "level": "H1",
      "text": "Figure 3.9  Histogram of VGG-Face net L2 error between the input face and the nor-",
      "page": 66
    },
    {
      "level": "H1",
      "text": "malized pairs on the FER data collection. Blue: with the identity preserving loss which",
      "page": 66
    },
    {
      "level": "H1",
      "text": "calculated by the Light CNN. Orange: without the identity preserving loss. The 1.242",
      "page": 66
    },
    {
      "level": "H1",
      "text": "threshold was used by Schroffet al.",
      "page": 66
    },
    {
      "level": "H1",
      "text": "to cluster identities in the LFW dataset. Without the",
      "page": 66
    },
    {
      "level": "H1",
      "text": "Light CNN, about 2% of the generated neutral faces would not be considered from the same",
      "page": 66
    },
    {
      "level": "H1",
      "text": "subject as the query faces.",
      "page": 66
    },
    {
      "level": "H3",
      "text": "3.9  FER",
      "page": 66
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 67
    },
    {
      "level": "H1",
      "text": "3.1",
      "page": 67
    },
    {
      "level": "H1",
      "text": "改变身份保存损失权重时的身份不一致百分比。",
      "page": 67
    },
    {
      "level": "H1",
      "text": "Table 3.1 The identity inconsistent percentage when changing the weight of identity",
      "page": 67
    },
    {
      "level": "H1",
      "text": "preserving loss.",
      "page": 67
    },
    {
      "level": "H1",
      "text": "0.001",
      "page": 67
    },
    {
      "level": "H1",
      "text": "0.005",
      "page": 67
    },
    {
      "level": "H1",
      "text": "0.01",
      "page": 67
    },
    {
      "level": "H1",
      "text": "0.015",
      "page": 67
    },
    {
      "level": "H1",
      "text": "0.02",
      "page": 67
    },
    {
      "level": "H1",
      "text": "0.025",
      "page": 67
    },
    {
      "level": "H1",
      "text": "0.03",
      "page": 67
    },
    {
      "level": "H1",
      "text": "0.035",
      "page": 67
    },
    {
      "level": "H1",
      "text": "0.04",
      "page": 67
    },
    {
      "level": "H1",
      "text": "0.05",
      "page": 67
    },
    {
      "level": "H1",
      "text": "Percentage(%)",
      "page": 67
    },
    {
      "level": "H1",
      "text": "2.13",
      "page": 67
    },
    {
      "level": "H1",
      "text": "1.77",
      "page": 67
    },
    {
      "level": "H1",
      "text": "1.06",
      "page": 67
    },
    {
      "level": "H1",
      "text": "0.32",
      "page": 67
    },
    {
      "level": "H1",
      "text": "0.13",
      "page": 67
    },
    {
      "level": "H1",
      "text": "0.11",
      "page": 67
    },
    {
      "level": "H1",
      "text": "0.1",
      "page": 67
    },
    {
      "level": "H1",
      "text": "VGG-FaceNet",
      "page": 67
    },
    {
      "level": "H1",
      "text": "用于计算特征层次的感知损失，期望使生成的结果保持更多感",
      "page": 67
    },
    {
      "level": "H1",
      "text": "知上重要的图像属性，例如锐利的边缘和纹理。根据经验，这种损失在实验中具",
      "page": 67
    },
    {
      "level": "H1",
      "text": "有最大的权重。在实践中，缺少这项损失时较难避免对抗训练的崩溃。表",
      "page": 67
    },
    {
      "level": "H1",
      "text": "通过调整身份保持损失的权重展示了其对身份保持特性的影响。",
      "page": 67
    },
    {
      "level": "H1",
      "text": "此外还分析了",
      "page": 67
    },
    {
      "level": "H1",
      "text": "RML",
      "page": 67
    },
    {
      "level": "H1",
      "text": "中不同超参数值的影响。",
      "page": 67
    },
    {
      "level": "H1",
      "text": "用于平衡",
      "page": 67
    },
    {
      "level": "H1",
      "text": "softmax",
      "page": 67
    },
    {
      "level": "H1",
      "text": "损失和度",
      "page": 67
    },
    {
      "level": "H1",
      "text": "量学习损失。从图",
      "page": 67
    },
    {
      "level": "H1",
      "text": "3.10",
      "page": 67
    },
    {
      "level": "H1",
      "text": "可以看出，当",
      "page": 67
    },
    {
      "level": "H1",
      "text": "α ϵ",
      "page": 67
    },
    {
      "level": "H1",
      "text": "[0.95,1]",
      "page": 67
    },
    {
      "level": "H1",
      "text": "时，精度最高。从图",
      "page": 67
    },
    {
      "level": "H1",
      "text": "3.11",
      "page": 67
    },
    {
      "level": "H1",
      "text": "看出网络对",
      "page": 67
    },
    {
      "level": "H1",
      "text": "[0.075,0.125]",
      "page": 67
    },
    {
      "level": "H1",
      "text": "不敏感。",
      "page": 67
    },
    {
      "level": "H1",
      "text": "当使用不同的",
      "page": 67
    },
    {
      "level": "H1",
      "text": "来平衡",
      "page": 67
    },
    {
      "level": "H1",
      "text": "损失和度量学习损失时，",
      "page": 67
    },
    {
      "level": "H1",
      "text": "CK +",
      "page": 67
    },
    {
      "level": "H1",
      "text": "类）数据集中",
      "page": 67
    },
    {
      "level": "H1",
      "text": "的面部识别准确性。",
      "page": 67
    },
    {
      "level": "H1",
      "text": "Figure 3.10  The Facial recognition accuracy in CK+ (7-class) dataset when using different",
      "page": 67
    },
    {
      "level": "H1",
      "text": "to balance the softmax loss and metric learning loss.",
      "page": 67
    },
    {
      "level": "H1",
      "text": "3.4.4",
      "page": 67
    },
    {
      "level": "H1",
      "text": "实验结果",
      "page": 67
    },
    {
      "level": "H1",
      "text": "为了评估所提出的方法的有效性，在实验环节中选取了四个公开的面部表情",
      "page": 67
    },
    {
      "level": "H1",
      "text": "数据集进行了实验，相应混淆矩阵如图",
      "page": 67
    },
    {
      "level": "H1",
      "text": "3.12",
      "page": 67
    },
    {
      "level": "H1",
      "text": "所示。",
      "page": 67
    },
    {
      "level": "H1",
      "text": "数据集",
      "page": 67
    },
    {
      "level": "H1",
      "text": "[97]",
      "page": 67
    },
    {
      "level": "H1",
      "text": "：进行了七类和八类表情识别实验（即没有或有中性表情）。",
      "page": 67
    },
    {
      "level": "H1",
      "text": "在没有中性样本的设置中，直接将查询样本与生成的归一化人脸进行比较。这不",
      "page": 67
    },
    {
      "level": "H1",
      "text": "仅放宽了对数据集的要求（即不需要同一个人的所有不同表情的图像，或具有真",
      "page": 67
    },
    {
      "level": "H1",
      "text": "基于难样本生成的人脸表情识别",
      "page": 68
    },
    {
      "level": "H1",
      "text": "实的中性参考图像）来提取解除身份信息的表情特征，但也减少了训练阶段的比",
      "page": 68
    },
    {
      "level": "H1",
      "text": "较次数。表",
      "page": 68
    },
    {
      "level": "H1",
      "text": "3.1",
      "page": 68
    },
    {
      "level": "H1",
      "text": "对训练时间进行了比较，本章所提出的方法大大减少了度量学习",
      "page": 68
    },
    {
      "level": "H1",
      "text": "部分的训练时间。虽然",
      "page": 68
    },
    {
      "level": "H1",
      "text": "[69]",
      "page": 68
    },
    {
      "level": "H1",
      "text": "IDFERM",
      "page": 68
    },
    {
      "level": "H1",
      "text": "在训练阶段需要额外的归一化面部生成（大",
      "page": 68
    },
    {
      "level": "H1",
      "text": "小时），但训练好的难样本生成网络适用于实验中所涉及的所有人脸表情识",
      "page": 68
    },
    {
      "level": "H1",
      "text": "别数据集，并不需要进行微调，可以看作是几个下游任务的现成工具。",
      "page": 68
    },
    {
      "level": "H1",
      "text": "3.11",
      "page": 68
    },
    {
      "level": "H1",
      "text": "当使用不同的",
      "page": 68
    },
    {
      "level": "H1",
      "text": "来平衡",
      "page": 68
    },
    {
      "level": "H1",
      "text": "softmax",
      "page": 68
    },
    {
      "level": "H1",
      "text": "损失和度量学习损失时，",
      "page": 68
    },
    {
      "level": "H1",
      "text": "CK +",
      "page": 68
    },
    {
      "level": "H1",
      "text": "类）数据集中",
      "page": 68
    },
    {
      "level": "H1",
      "text": "的面部识别准确性。",
      "page": 68
    },
    {
      "level": "H1",
      "text": "Figure 3.11  The Facial recognition accuracy in CK+ (7-class) dataset when using different",
      "page": 68
    },
    {
      "level": "H1",
      "text": "to balance the softmax loss and metric learning loss.",
      "page": 68
    },
    {
      "level": "H1",
      "text": "3.2",
      "page": 68
    },
    {
      "level": "H1",
      "text": "Titan X GPU",
      "page": 68
    },
    {
      "level": "H1",
      "text": "的度量学习在数据集上训练时间的比较。",
      "page": 68
    },
    {
      "level": "H1",
      "text": "Table 3.2 Comparation of the metric learning training time on the datasets with a Titan X",
      "page": 68
    },
    {
      "level": "H1",
      "text": "GPU.",
      "page": 68
    },
    {
      "level": "H1",
      "text": "Metric Learning",
      "page": 68
    },
    {
      "level": "H1",
      "text": "Training Time",
      "page": 68
    },
    {
      "level": "H1",
      "text": "CK+",
      "page": 68
    },
    {
      "level": "H1",
      "text": "(7-class)",
      "page": 68
    },
    {
      "level": "H1",
      "text": "(8-class)",
      "page": 68
    },
    {
      "level": "H1",
      "text": "MMI",
      "page": 68
    },
    {
      "level": "H1",
      "text": "Oulu-CASIA",
      "page": 68
    },
    {
      "level": "H1",
      "text": "VIS",
      "page": 68
    },
    {
      "level": "H1",
      "text": "Triplet Loss",
      "page": 68
    },
    {
      "level": "H1",
      "text": "[74]",
      "page": 68
    },
    {
      "level": "H1",
      "text": "5h 24mins",
      "page": 68
    },
    {
      "level": "H1",
      "text": "3h 14mins",
      "page": 68
    },
    {
      "level": "H1",
      "text": "2B(N+M) Softmax",
      "page": 68
    },
    {
      "level": "H1",
      "text": "[66]",
      "page": 68
    },
    {
      "level": "H1",
      "text": "1h 47mins",
      "page": 68
    },
    {
      "level": "H1",
      "text": "54 mins",
      "page": 68
    },
    {
      "level": "H1",
      "text": "Data Augmentation",
      "page": 68
    },
    {
      "level": "H1",
      "text": "3 h 11mins",
      "page": 68
    },
    {
      "level": "H1",
      "text": "2h 8mins",
      "page": 68
    },
    {
      "level": "H1",
      "text": "42 mins",
      "page": 68
    },
    {
      "level": "H1",
      "text": "1h 4 mins",
      "page": 68
    },
    {
      "level": "H1",
      "text": "30 mins",
      "page": 68
    },
    {
      "level": "H1",
      "text": "56 mins",
      "page": 68
    },
    {
      "level": "H1",
      "text": "在测试阶段，",
      "page": 68
    },
    {
      "level": "H1",
      "text": "在大约",
      "page": 68
    },
    {
      "level": "H1",
      "text": "50ms",
      "page": 68
    },
    {
      "level": "H1",
      "text": "内识别出查询图像的面部表情，可满足",
      "page": 68
    },
    {
      "level": "H1",
      "text": "大多数应用的实时性需求。基于视频的方法通常需要相对较长的采集视频时间（",
      "page": 68
    },
    {
      "level": "H1",
      "text": "0.25",
      "page": 68
    },
    {
      "level": "H1",
      "text": "秒）来拍摄整个表情变化过程。",
      "page": 68
    },
    {
      "level": "H1",
      "text": "中可以得到，使用自适应度量学习方法的解除身份的表情识别比先",
      "page": 68
    },
    {
      "level": "H1",
      "text": "前方法能获得更高的准确性。此外，可发现将查询样本与其生成的规范化面部进",
      "page": 68
    },
    {
      "level": "H1",
      "text": "行比较优于（",
      "page": 68
    },
    {
      "level": "H1",
      "text": "N+M",
      "page": 68
    },
    {
      "level": "H1",
      "text": "）元组簇损失中与所有其他表情进行比较。这说明（",
      "page": 68
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 69
    },
    {
      "level": "H1",
      "text": "组簇损失中的距离计算仍然有较大冗余。这与图",
      "page": 69
    },
    {
      "level": "H1",
      "text": "3.1",
      "page": 69
    },
    {
      "level": "H1",
      "text": "中所分析的表情关系一致。",
      "page": 69
    },
    {
      "level": "H1",
      "text": "作为一种有效的难样本生成方案，",
      "page": 69
    },
    {
      "level": "H1",
      "text": "HNG",
      "page": 69
    },
    {
      "level": "H1",
      "text": "能有效提供最具学习潜力的难负样本，",
      "page": 69
    },
    {
      "level": "H1",
      "text": "并且使得距离比较次数大大减少。",
      "page": 69
    },
    {
      "level": "H1",
      "text": "3.12",
      "page": 69
    },
    {
      "level": "H1",
      "text": "所提出的",
      "page": 69
    },
    {
      "level": "H1",
      "text": "IDFERM",
      "page": 69
    },
    {
      "level": "H1",
      "text": "的混淆矩阵在（左）",
      "page": 69
    },
    {
      "level": "H1",
      "text": "CK +",
      "page": 69
    },
    {
      "level": "H1",
      "text": "七类，（右）",
      "page": 69
    },
    {
      "level": "H1",
      "text": "八类数据库中评",
      "page": 69
    },
    {
      "level": "H1",
      "text": "估。预测标签和实况标签分别以纵坐标和横坐标显示。",
      "page": 69
    },
    {
      "level": "H1",
      "text": "Figure 3.12  Confusion matrix of the proposed IDFERM evaluated in the (left) CK+ seven-",
      "page": 69
    },
    {
      "level": "H1",
      "text": "class, (right) CK+ eight-class. The predicted labels and the ground truth labels are shown in",
      "page": 69
    },
    {
      "level": "H1",
      "text": "the ordinate and abscissa, respectively.",
      "page": 69
    },
    {
      "level": "H1",
      "text": "个表情数据集（没有中性表情）和",
      "page": 69
    },
    {
      "level": "H1",
      "text": "MMI",
      "page": 69
    },
    {
      "level": "H1",
      "text": "数据集",
      "page": 69
    },
    {
      "level": "H1",
      "text": "rank-1",
      "page": 69
    },
    {
      "level": "H1",
      "text": "识别准确性比较。",
      "page": 69
    },
    {
      "level": "H1",
      "text": "Table 3.3 Performance compares of the rank-1 recognition accuracy on the CK+ dataset in",
      "page": 69
    },
    {
      "level": "H1",
      "text": "terms of 7 expressions and the MMI dataset (without neutral expression).",
      "page": 69
    },
    {
      "level": "H1",
      "text": "Methods",
      "page": 69
    },
    {
      "level": "H1",
      "text": "CK+",
      "page": 69
    },
    {
      "level": "H1",
      "text": "seven-class",
      "page": 69
    },
    {
      "level": "H1",
      "text": "MSR",
      "page": 69
    },
    {
      "level": "H1",
      "text": "[140]",
      "page": 69
    },
    {
      "level": "H1",
      "text": "91.4%",
      "page": 69
    },
    {
      "level": "H1",
      "text": "N/A",
      "page": 69
    },
    {
      "level": "H1",
      "text": "BNBN [141]",
      "page": 69
    },
    {
      "level": "H1",
      "text": "96.7%",
      "page": 69
    },
    {
      "level": "H1",
      "text": "IBCNN",
      "page": 69
    },
    {
      "level": "H1",
      "text": "[142]",
      "page": 69
    },
    {
      "level": "H1",
      "text": "95.1%",
      "page": 69
    },
    {
      "level": "H1",
      "text": "STMExplet(video) [108]",
      "page": 69
    },
    {
      "level": "H1",
      "text": "94.19%",
      "page": 69
    },
    {
      "level": "H1",
      "text": "75.12%",
      "page": 69
    },
    {
      "level": "H1",
      "text": "DTAGN(video) [144]",
      "page": 69
    },
    {
      "level": "H1",
      "text": "97.25%",
      "page": 69
    },
    {
      "level": "H1",
      "text": "70.2%",
      "page": 69
    },
    {
      "level": "H1",
      "text": "IACNN [145]",
      "page": 69
    },
    {
      "level": "H1",
      "text": "95.37%",
      "page": 69
    },
    {
      "level": "H1",
      "text": "71.55%",
      "page": 69
    },
    {
      "level": "H1",
      "text": "2B(N+M) Softmax",
      "page": 69
    },
    {
      "level": "H1",
      "text": "[66]",
      "page": 69
    },
    {
      "level": "H1",
      "text": "97.1%",
      "page": 69
    },
    {
      "level": "H1",
      "text": "78.53%",
      "page": 69
    },
    {
      "level": "H1",
      "text": "Data Augmentation",
      "page": 69
    },
    {
      "level": "H1",
      "text": "[69]",
      "page": 69
    },
    {
      "level": "H1",
      "text": "97.49%",
      "page": 69
    },
    {
      "level": "H1",
      "text": "80.26%",
      "page": 69
    },
    {
      "level": "H1",
      "text": "98.35%",
      "page": 69
    },
    {
      "level": "H1",
      "text": "81.13%",
      "page": 69
    },
    {
      "level": "H1",
      "text": "与其他方法相比，本章所改进的方法在基于图像的",
      "page": 69
    },
    {
      "level": "H1",
      "text": "Oulu-",
      "page": 69
    },
    {
      "level": "H1",
      "text": "CASIA",
      "page": 69
    },
    {
      "level": "H1",
      "text": "等没有真实中性表情样本作为训练数据的数据库上具有较明显的提升。",
      "page": 69
    },
    {
      "level": "H1",
      "text": "3.3",
      "page": 69
    },
    {
      "level": "H1",
      "text": "所示，它在具有中性表情的数据集中也能通过数据增强的方式提升网络",
      "page": 69
    },
    {
      "level": "H3",
      "text": "3.3  CK +7",
      "page": 69
    },
    {
      "level": "H1",
      "text": "基于难样本生成的人脸表情识别",
      "page": 70
    },
    {
      "level": "H1",
      "text": "性能。通过添加生成的归一化人脸样本，中性表情类的识别准确度提高到",
      "page": 70
    },
    {
      "level": "H1",
      "text": "3.12",
      "page": 70
    },
    {
      "level": "H1",
      "text": "所示。",
      "page": 70
    },
    {
      "level": "H1",
      "text": "3.4",
      "page": 70
    },
    {
      "level": "H1",
      "text": "个表情（中性表情）对",
      "page": 70
    },
    {
      "level": "H1",
      "text": "CK +",
      "page": 70
    },
    {
      "level": "H1",
      "text": "数据集的",
      "page": 70
    },
    {
      "level": "H1",
      "text": "rank-1",
      "page": 70
    },
    {
      "level": "H1",
      "text": "识别准确度进行性能比较。",
      "page": 70
    },
    {
      "level": "H1",
      "text": "Table 3.4 Performance comparison of the rank-1 recognition accuracy on the CK+ dataset in",
      "page": 70
    },
    {
      "level": "H1",
      "text": "terms of the 8 expressions (with neutral expression).",
      "page": 70
    },
    {
      "level": "H1",
      "text": "Methods",
      "page": 70
    },
    {
      "level": "H1",
      "text": "CK+",
      "page": 70
    },
    {
      "level": "H1",
      "text": "eight-class",
      "page": 70
    },
    {
      "level": "H1",
      "text": "AUDB",
      "page": 70
    },
    {
      "level": "H1",
      "text": "[146]",
      "page": 70
    },
    {
      "level": "H1",
      "text": "93.70%",
      "page": 70
    },
    {
      "level": "H1",
      "text": "CNN+AD",
      "page": 70
    },
    {
      "level": "H1",
      "text": "[147]",
      "page": 70
    },
    {
      "level": "H1",
      "text": "96.4%",
      "page": 70
    },
    {
      "level": "H1",
      "text": "FN2EN",
      "page": 70
    },
    {
      "level": "H1",
      "text": "[148]",
      "page": 70
    },
    {
      "level": "H1",
      "text": "96.8%",
      "page": 70
    },
    {
      "level": "H1",
      "text": "IDFERM",
      "page": 70
    },
    {
      "level": "H1",
      "text": "97.76%",
      "page": 70
    },
    {
      "level": "H1",
      "text": "3.5",
      "page": 70
    },
    {
      "level": "H1",
      "text": "数据集中使用",
      "page": 70
    },
    {
      "level": "H1",
      "text": "Multi-PIE",
      "page": 70
    },
    {
      "level": "H1",
      "text": "不进行预训练的性能比较。",
      "page": 70
    },
    {
      "level": "H1",
      "text": "Table 3.5 Comparation of the performance with/without pre-training using Multi-PIE in",
      "page": 70
    },
    {
      "level": "H1",
      "text": "CK+ dataset.",
      "page": 70
    },
    {
      "level": "H1",
      "text": "2B(N+M)",
      "page": 70
    },
    {
      "level": "H1",
      "text": "[66]",
      "page": 70
    },
    {
      "level": "H1",
      "text": "Without",
      "page": 70
    },
    {
      "level": "H1",
      "text": "Pre-training",
      "page": 70
    },
    {
      "level": "H1",
      "text": "With",
      "page": 70
    },
    {
      "level": "H1",
      "text": "CK+(7-class)",
      "page": 70
    },
    {
      "level": "H1",
      "text": "97.03%",
      "page": 70
    },
    {
      "level": "H1",
      "text": "97.10%",
      "page": 70
    },
    {
      "level": "H1",
      "text": "98.32%",
      "page": 70
    },
    {
      "level": "H1",
      "text": "98.35%",
      "page": 70
    },
    {
      "level": "H1",
      "text": "MMI",
      "page": 70
    },
    {
      "level": "H1",
      "text": "78.46%",
      "page": 70
    },
    {
      "level": "H1",
      "text": "78.53%",
      "page": 70
    },
    {
      "level": "H1",
      "text": "81.11%",
      "page": 70
    },
    {
      "level": "H1",
      "text": "81.13%",
      "page": 70
    },
    {
      "level": "H1",
      "text": "数据集",
      "page": 70
    },
    {
      "level": "H1",
      "text": "[98]",
      "page": 70
    },
    {
      "level": "H1",
      "text": "：该数据集由",
      "page": 70
    },
    {
      "level": "H1",
      "text": "213",
      "page": 70
    },
    {
      "level": "H1",
      "text": "个视频序列组成，如",
      "page": 70
    },
    {
      "level": "H1",
      "text": "的设置，在此实验",
      "page": 70
    },
    {
      "level": "H1",
      "text": "中使用来自该数据集的",
      "page": 70
    },
    {
      "level": "H1",
      "text": "208",
      "page": 70
    },
    {
      "level": "H1",
      "text": "个序列包含",
      "page": 70
    },
    {
      "level": "H1",
      "text": "个受试者的正面视图。每个序列以中",
      "page": 70
    },
    {
      "level": "H1",
      "text": "性表情开始，并在序列的中间显示单个表情类型的峰值表情。最后，它返回到中",
      "page": 70
    },
    {
      "level": "H1",
      "text": "性表情。由于没有提供峰值帧的真实时间点，在每个图像序列的中间收集三个帧",
      "page": 70
    },
    {
      "level": "H1",
      "text": "并将它们与标签相关联，从而收集",
      "page": 70
    },
    {
      "level": "H1",
      "text": "624",
      "page": 70
    },
    {
      "level": "H1",
      "text": "个表情图像。",
      "page": 70
    },
    {
      "level": "H1",
      "text": "数据集划分为",
      "page": 70
    },
    {
      "level": "H1",
      "text": "集，用于个体独立（",
      "page": 70
    },
    {
      "level": "H1",
      "text": "person-independent",
      "page": 70
    },
    {
      "level": "H1",
      "text": "）的十折交叉验证（",
      "page": 70
    },
    {
      "level": "H1",
      "text": "ten-fold cross validation",
      "page": 70
    },
    {
      "level": "H1",
      "text": "通过选择具有三个图像的最高平均分数的类来获得序列级的表情预测。",
      "page": 70
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 71
    },
    {
      "level": "H1",
      "text": "3.13",
      "page": 71
    },
    {
      "level": "H1",
      "text": "所提出的",
      "page": 71
    },
    {
      "level": "H1",
      "text": "IDFERM",
      "page": 71
    },
    {
      "level": "H1",
      "text": "的混淆矩阵在（左）",
      "page": 71
    },
    {
      "level": "H1",
      "text": "MMI",
      "page": 71
    },
    {
      "level": "H1",
      "text": "和（右）",
      "page": 71
    },
    {
      "level": "H1",
      "text": "Oulu-CASIA",
      "page": 71
    },
    {
      "level": "H1",
      "text": "数据库中评",
      "page": 71
    },
    {
      "level": "H1",
      "text": "估。预测标签和实况标签分别以纵坐标和横坐标显示。",
      "page": 71
    },
    {
      "level": "H1",
      "text": "Figure 3.23  Confusion matrix of the proposed IDFERM evaluated in the (left) MMI and",
      "page": 71
    },
    {
      "level": "H1",
      "text": "(right) Oulu-CASIA database. The predicted labels and the ground truth labels are shown in",
      "page": 71
    },
    {
      "level": "H1",
      "text": "the ordinate and abscissa, respectively.",
      "page": 71
    },
    {
      "level": "H1",
      "text": "利用解除身份的人脸表情识别，所提出的方法相对于",
      "page": 71
    },
    {
      "level": "H1",
      "text": "数据集中的先前",
      "page": 71
    },
    {
      "level": "H1",
      "text": "方法实现了实质性改进，如表",
      "page": 71
    },
    {
      "level": "H1",
      "text": "3.3",
      "page": 71
    },
    {
      "level": "H1",
      "text": "所示。难样本生成可以通过在适用的",
      "page": 71
    },
    {
      "level": "H1",
      "text": "框架内纳入归一化面部的先验信息，并使用径向度量学习引入表情间类似关系来",
      "page": 71
    },
    {
      "level": "H1",
      "text": "进一步提高识别准确性。值得注意的是，",
      "page": 71
    },
    {
      "level": "H1",
      "text": "数据集中的图像序列包含完整的",
      "page": 71
    },
    {
      "level": "H1",
      "text": "表情变化过程，即从中性到峰值，然后放松回到中性，尤其适合基于时间序列的",
      "page": 71
    },
    {
      "level": "H1",
      "text": "方法。而本方法则无需使用所有帧，且不需要明确的峰值标签。",
      "page": 71
    },
    {
      "level": "H1",
      "text": "Oulu-CASIA VIS",
      "page": 71
    },
    {
      "level": "H1",
      "text": "数据集",
      "page": 71
    },
    {
      "level": "H1",
      "text": "[149]",
      "page": 71
    },
    {
      "level": "H1",
      "text": "：该数据集由",
      "page": 71
    },
    {
      "level": "H1",
      "text": "480",
      "page": 71
    },
    {
      "level": "H1",
      "text": "个人的",
      "page": 71
    },
    {
      "level": "H1",
      "text": "个图像序列组成。",
      "page": 71
    },
    {
      "level": "H1",
      "text": "该数据集在可见（",
      "page": 71
    },
    {
      "level": "H1",
      "text": "visible, VIS",
      "page": 71
    },
    {
      "level": "H1",
      "text": "）光正常照明条件下采集的，是",
      "page": 71
    },
    {
      "level": "H1",
      "text": "Oulu-CASIA NIR-",
      "page": 71
    },
    {
      "level": "H1",
      "text": "VIS",
      "page": 71
    },
    {
      "level": "H1",
      "text": "数据集的子集。每个人都像",
      "page": 71
    },
    {
      "level": "H1",
      "text": "数据集一样具有六个基本表情。与",
      "page": 71
    },
    {
      "level": "H1",
      "text": "CK +",
      "page": 71
    },
    {
      "level": "H1",
      "text": "据集类似，序列从中性表情开始，并在某一表情的峰值结束。在基于图片识别系",
      "page": 71
    },
    {
      "level": "H1",
      "text": "统中仅使用最后三帧，将其标记为该视频的表情类别。得到的图像总数为",
      "page": 71
    },
    {
      "level": "H1",
      "text": "1440",
      "page": 71
    },
    {
      "level": "H1",
      "text": "张。与",
      "page": 71
    },
    {
      "level": "H1",
      "text": "[66]",
      "page": 71
    },
    {
      "level": "H1",
      "text": "数据集设置一样，进行个体独立的十折交叉验证。",
      "page": 71
    },
    {
      "level": "H1",
      "text": "所示，在",
      "page": 71
    },
    {
      "level": "H1",
      "text": "数据集中，",
      "page": 71
    },
    {
      "level": "H1",
      "text": "在识别恐惧和快乐表情",
      "page": 71
    },
    {
      "level": "H1",
      "text": "方面表现良好，而愤怒则是最难识别的，其主要与厌恶相混淆。性能结果如表",
      "page": 71
    },
    {
      "level": "H1",
      "text": "3.6",
      "page": 71
    },
    {
      "level": "H1",
      "text": "所示。",
      "page": 71
    },
    {
      "level": "H1",
      "text": "基于难样本生成的人脸表情识别",
      "page": 72
    },
    {
      "level": "H1",
      "text": "3.6",
      "page": 72
    },
    {
      "level": "H1",
      "text": "个表情（无中性表情）对",
      "page": 72
    },
    {
      "level": "H1",
      "text": "Oulu-CASIA VIS",
      "page": 72
    },
    {
      "level": "H1",
      "text": "数据集的",
      "page": 72
    },
    {
      "level": "H1",
      "text": "rank-1",
      "page": 72
    },
    {
      "level": "H1",
      "text": "识别准确性进",
      "page": 72
    },
    {
      "level": "H1",
      "text": "行性能比较。",
      "page": 72
    },
    {
      "level": "H1",
      "text": "Table 3.6 Performance comparison of the rank-1 recognition accuracy on the Oulu-CASIA",
      "page": 72
    },
    {
      "level": "H1",
      "text": "VIS dataset in terms of the 6 expressions (without neutral expression).",
      "page": 72
    },
    {
      "level": "H1",
      "text": "Methods",
      "page": 72
    },
    {
      "level": "H1",
      "text": "STM-ExpLet(video)",
      "page": 72
    },
    {
      "level": "H1",
      "text": "[108]",
      "page": 72
    },
    {
      "level": "H1",
      "text": "74.59%",
      "page": 72
    },
    {
      "level": "H1",
      "text": "DTAGN(video)",
      "page": 72
    },
    {
      "level": "H1",
      "text": "[144]",
      "page": 72
    },
    {
      "level": "H1",
      "text": "81.46%",
      "page": 72
    },
    {
      "level": "H1",
      "text": "PPDN",
      "page": 72
    },
    {
      "level": "H1",
      "text": "[150]",
      "page": 72
    },
    {
      "level": "H1",
      "text": "84.59%",
      "page": 72
    },
    {
      "level": "H1",
      "text": "FN2EN",
      "page": 72
    },
    {
      "level": "H1",
      "text": "[148]",
      "page": 72
    },
    {
      "level": "H1",
      "text": "87.1%",
      "page": 72
    },
    {
      "level": "H1",
      "text": "IDFERM",
      "page": 72
    },
    {
      "level": "H1",
      "text": "88.25%",
      "page": 72
    },
    {
      "level": "H1",
      "text": "3.5",
      "page": 72
    },
    {
      "level": "H1",
      "text": "本章小结",
      "page": 72
    },
    {
      "level": "H1",
      "text": "本章所提出的",
      "page": 72
    },
    {
      "level": "H1",
      "text": "HNG",
      "page": 72
    },
    {
      "level": "H1",
      "text": "网络是一种新型的保持身份的中性人脸图像生成方法，",
      "page": 72
    },
    {
      "level": "H1",
      "text": "可以基于引导集数据分布的先验知识和人脸结构知识来合成归一化人脸图像。进",
      "page": 72
    },
    {
      "level": "H1",
      "text": "一步提出了一种新的人脸表情识别方法，将生成的标准化面作为难负样本，通过",
      "page": 72
    },
    {
      "level": "H1",
      "text": "的框架来解离表情与身份等因素。与先前的深度度量学习方法相",
      "page": 72
    },
    {
      "level": "H1",
      "text": "比，径向度量学习（",
      "page": 72
    },
    {
      "level": "H1",
      "text": "RML",
      "page": 72
    },
    {
      "level": "H1",
      "text": "）需要更少的距离比较。这种方法具有良好的泛化属性，",
      "page": 72
    },
    {
      "level": "H1",
      "text": "并在基于图像的三个数据集上超过了以前的最优结果",
      "page": 72
    },
    {
      "level": "H1",
      "text": "基于对抗训练的人脸身份与表情特征剥离及识别",
      "page": 74
    },
    {
      "level": "H1",
      "text": "为识别任务提取有辨别力的特征表达是识别系统的重要研究目标。本章的目",
      "page": 74
    },
    {
      "level": "H1",
      "text": "标是根据对任务的先验知识明确的去除与识别任务无关的因素后实现更好的泛",
      "page": 74
    },
    {
      "level": "H1",
      "text": "化。由于许多训练集包含使用多个感兴趣的语义变化标注的图像，如何利用这些",
      "page": 74
    },
    {
      "level": "H1",
      "text": "侧标签提升主要标签的识别效果是个有意义的问题。但是许多变换（例如性别）",
      "page": 74
    },
    {
      "level": "H1",
      "text": "类似于无监督图像转换任务中并不存在一对一的变化对以供参考的示例",
      "page": 74
    },
    {
      "level": "H1",
      "text": "[151],[152]",
      "page": 74
    },
    {
      "level": "H1",
      "text": "并且潜在变化是完全未定义或指定的，这使得此任务具有挑战性。",
      "page": 74
    },
    {
      "level": "H1",
      "text": "遵循先前多标签数据集中使用的术语（包括主任务标签和几个侧标签）",
      "page": 74
    },
    {
      "level": "H1",
      "text": "[153],[154],[155]",
      "page": 74
    },
    {
      "level": "H1",
      "text": "，本章提出定义三个互补部分，如图",
      "page": 74
    },
    {
      "level": "H1",
      "text": "4.1",
      "page": 74
    },
    {
      "level": "H1",
      "text": "所示。与侧标签相关的因素",
      "page": 74
    },
    {
      "level": "H1",
      "text": "被称为语义变量",
      "page": 74
    },
    {
      "level": "H1",
      "text": "，其可以是与主识别任务相关",
      "page": 74
    },
    {
      "level": "H1",
      "text": "不相关的（",
      "page": 74
    },
    {
      "level": "H1",
      "text": "task relevant/",
      "page": 74
    },
    {
      "level": "H1",
      "text": "irrelevant",
      "page": 74
    },
    {
      "level": "H1",
      "text": "），这取决于它们是否与主要识别任务边际独立。潜在变量",
      "page": 74
    },
    {
      "level": "H1",
      "text": "，其总结",
      "page": 74
    },
    {
      "level": "H1",
      "text": "了主要任务标签和语义标签均未指定的剩余属性。",
      "page": 74
    },
    {
      "level": "H1",
      "text": "DNN",
      "page": 74
    },
    {
      "level": "H1",
      "text": "如何系统地学习有辨别",
      "page": 74
    },
    {
      "level": "H1",
      "text": "力的特征表达",
      "page": 74
    },
    {
      "level": "H1",
      "text": "以便为主要识别任务提供信息，同时以可控的边际独立于多个",
      "page": 74
    },
    {
      "level": "H1",
      "text": "和未指定的",
      "page": 74
    },
    {
      "level": "H1",
      "text": "仍然具有挑战性。",
      "page": 74
    },
    {
      "level": "H1",
      "text": "预期的",
      "page": 74
    },
    {
      "level": "H1",
      "text": "的各因素分离的图示，其可被分解为有辨别力的特征表达",
      "page": 74
    },
    {
      "level": "H1",
      "text": "（红色），潜",
      "page": 74
    },
    {
      "level": "H1",
      "text": "在变量",
      "page": 74
    },
    {
      "level": "H1",
      "text": "（绿色）和语义变量",
      "page": 74
    },
    {
      "level": "H1",
      "text": "（蓝色）。本章的框架明确地要求它们相互边际独立。",
      "page": 74
    },
    {
      "level": "H1",
      "text": "主任务相关的",
      "page": 74
    },
    {
      "level": "H1",
      "text": "与主识别任务标签",
      "page": 74
    },
    {
      "level": "H1",
      "text": "相关。",
      "page": 74
    },
    {
      "level": "H1",
      "text": "Figure 4.1 Illustration of the expected separations of the observation",
      "page": 74
    },
    {
      "level": "H1",
      "text": ", which associated",
      "page": 74
    },
    {
      "level": "H1",
      "text": "with the discriminative representation",
      "page": 74
    },
    {
      "level": "H1",
      "text": "(red), latent variation",
      "page": 74
    },
    {
      "level": "H1",
      "text": "(green) and semantic",
      "page": 74
    },
    {
      "level": "H1",
      "text": "variations",
      "page": 74
    },
    {
      "level": "H1",
      "text": "(blue). Our framework explicitly enforces them marginally independent to each",
      "page": 74
    },
    {
      "level": "H1",
      "text": "other. The",
      "page": 74
    },
    {
      "level": "H1",
      "text": "and task-dependent",
      "page": 74
    },
    {
      "level": "H1",
      "text": "are related to the main-recognition task label",
      "page": 74
    },
    {
      "level": "H1",
      "text": "基于对抗训练的人脸身份与表情特征剥离及识别",
      "page": 75
    },
    {
      "level": "H1",
      "text": "已经有许多工作通过神经网络来强制要求主要任务特征对于单个任务无关",
      "page": 75
    },
    {
      "level": "H1",
      "text": "语义变量鲁棒。如第二章所述的度量学习",
      "page": 75
    },
    {
      "level": "H1",
      "text": "[66]",
      "page": 75
    },
    {
      "level": "H1",
      "text": "，或第三章所述的难样本生成",
      "page": 75
    },
    {
      "level": "H1",
      "text": "[68]",
      "page": 75
    },
    {
      "level": "H1",
      "text": "些方法可以进行预处理或度量学习提取姿势，表情或照明不变的面部识别等。这",
      "page": 75
    },
    {
      "level": "H1",
      "text": "些方法具有相同的缺点，即需要成对的样本进行有监督的图像转换训练。而这较",
      "page": 75
    },
    {
      "level": "H1",
      "text": "难进行扩展，因为需要控制的属性的数量可能很大。而且各任务关心的不变性在",
      "page": 75
    },
    {
      "level": "H1",
      "text": "任务之间可能存在很大差异，而度量学习等方法要求在每次需要新的不变性时设",
      "page": 75
    },
    {
      "level": "H1",
      "text": "计新的体系结构。",
      "page": 75
    },
    {
      "level": "H1",
      "text": "此外，他们的理论分析中的基本假设是该属性与主任务预测无关，这限制了",
      "page": 75
    },
    {
      "level": "H1",
      "text": "其分析任务相关语义标签的能力。这些标签通常用于通过多任务学习中的特征聚",
      "page": 75
    },
    {
      "level": "H1",
      "text": "合来实现属性增强识别（例如，性别，年龄和种族可以缩小用于面部识别的搜索",
      "page": 75
    },
    {
      "level": "H1",
      "text": "空间）",
      "page": 75
    },
    {
      "level": "H1",
      "text": "[156],[157]",
      "page": 75
    },
    {
      "level": "H1",
      "text": "但是在某些特定任务中也需要针对这些属性的不变性。例如化妆人脸识别系",
      "page": 75
    },
    {
      "level": "H1",
      "text": "统应该对年龄，头发颜色等变化鲁棒。同样，在预测人的信用和健康状况时，性",
      "page": 75
    },
    {
      "level": "H1",
      "text": "别和种族是公平分类的敏感因素。由于数据中的固有偏差，这些语义标签和主要",
      "page": 75
    },
    {
      "level": "H1",
      "text": "任务标签是相关的。一种可能的解决方案是将此属性设置为概率模型的随机变量",
      "page": 75
    },
    {
      "level": "H1",
      "text": "[158],[159],[160]",
      "page": 75
    },
    {
      "level": "H1",
      "text": "。由于一对分布之间的散度（",
      "page": 75
    },
    {
      "level": "H1",
      "text": "Divergence",
      "page": 75
    },
    {
      "level": "H1",
      "text": "）被用作损失函数，因此需要",
      "page": 75
    },
    {
      "level": "H1",
      "text": "使用的分布间距离计算的数量随着属性的数量的二次方增长，这对于实际操作中",
      "page": 75
    },
    {
      "level": "H1",
      "text": "的多种变化而言在计算上较为复杂。",
      "page": 75
    },
    {
      "level": "H1",
      "text": "另一个挑战是如何通过消除那些没有标签的潜在变量来实现更好的泛化。例",
      "page": 75
    },
    {
      "level": "H1",
      "text": "如，希望人脸识别系统不仅对有侧标签的表情鲁棒，而且还适用于使得没有侧标",
      "page": 75
    },
    {
      "level": "H1",
      "text": "签的不同种族不影响提取到的特征。这个问题与图像生成中的特征解构（",
      "page": 75
    },
    {
      "level": "H1",
      "text": "feature",
      "page": 75
    },
    {
      "level": "H1",
      "text": "disentanglements",
      "page": 75
    },
    {
      "level": "H1",
      "text": "[154],[161]",
      "page": 75
    },
    {
      "level": "H1",
      "text": "也有一些相似之处，而本章的目标是提高内容分类性能",
      "page": 75
    },
    {
      "level": "H1",
      "text": "而不是合成高质量图像。受上述因素的驱使，本章提出有必要设计一个系统能够",
      "page": 75
    },
    {
      "level": "H1",
      "text": "以无监督的方式消除一组任务无关",
      "page": 75
    },
    {
      "level": "H1",
      "text": "相关以及潜在的变化量，且不需要成对的语",
      "page": 75
    },
    {
      "level": "H1",
      "text": "义变换示例",
      "page": 75
    },
    {
      "level": "H1",
      "text": "[151],[152]",
      "page": 75
    },
    {
      "level": "H1",
      "text": "和潜在变量的标签。",
      "page": 75
    },
    {
      "level": "H1",
      "text": "具体而言，本章采用端到端的条件对抗性训练框架。其依赖于编码器",
      "page": 75
    },
    {
      "level": "H1",
      "text": "器架构，其中给定具有主任务标签",
      "page": 75
    },
    {
      "level": "H1",
      "text": "的输入图像",
      "page": 75
    },
    {
      "level": "H1",
      "text": "和希望被去除的语义变量标签",
      "page": 75
    },
    {
      "level": "H1",
      "text": "，编码器将",
      "page": 75
    },
    {
      "level": "H1",
      "text": "映射到具有辨别力的表示",
      "page": 75
    },
    {
      "level": "H1",
      "text": "和潜在变量",
      "page": 75
    },
    {
      "level": "H1",
      "text": "，并且训练解码器以给定",
      "page": 75
    },
    {
      "level": "H1",
      "text": "进行图像重建。语义鉴别器用于检测",
      "page": 75
    },
    {
      "level": "H1",
      "text": "中所包含",
      "page": 75
    },
    {
      "level": "H1",
      "text": "的信息，并且使用具",
      "page": 75
    },
    {
      "level": "H1",
      "text": "有相反目标的两个预测",
      "page": 75
    },
    {
      "level": "H1",
      "text": "的分类器，分别基于",
      "page": 75
    },
    {
      "level": "H1",
      "text": "，来约束潜在空间以同时操",
      "page": 75
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 76
    },
    {
      "level": "H1",
      "text": "纵多个语义变量以获得更好的可扩展性。",
      "page": 76
    },
    {
      "level": "H1",
      "text": "本章的主要贡献概括如下：",
      "page": 76
    },
    {
      "level": "H1",
      "text": "）通过系统地结合识别任务的先验知识，能够明确地提取具有所需不变性的具",
      "page": 76
    },
    {
      "level": "H1",
      "text": "有判别力的特征。待消除的多个语义变量可以是任务相关",
      "page": 76
    },
    {
      "level": "H1",
      "text": "独立的，并且未指定的",
      "page": 76
    },
    {
      "level": "H1",
      "text": "潜在变量也可以通过无监督的方式消除。",
      "page": 76
    },
    {
      "level": "H1",
      "text": "）引入语义鉴别器和两个相反的分类器来约束潜在空间，从而实现更简单的训",
      "page": 76
    },
    {
      "level": "H1",
      "text": "练流程和更好的可扩展性。",
      "page": 76
    },
    {
      "level": "H1",
      "text": "）分析了任务相关",
      "page": 76
    },
    {
      "level": "H1",
      "text": "独立的情景中的理论均衡条件。",
      "page": 76
    },
    {
      "level": "H1",
      "text": "Extrended YaleB",
      "page": 76
    },
    {
      "level": "H1",
      "text": "个化妆数据集，",
      "page": 76
    },
    {
      "level": "H1",
      "text": "CelebA",
      "page": 76
    },
    {
      "level": "H1",
      "text": "LFWA",
      "page": 76
    },
    {
      "level": "H1",
      "text": "DFW",
      "page": 76
    },
    {
      "level": "H1",
      "text": "的面部识别",
      "page": 76
    },
    {
      "level": "H1",
      "text": "基准测试中进行了大量实验，验证了它的有效性和通用性。",
      "page": 76
    },
    {
      "level": "H1",
      "text": "4.1",
      "page": 76
    },
    {
      "level": "H1",
      "text": "相关工作",
      "page": 76
    },
    {
      "level": "H1",
      "text": "多任务学习（",
      "page": 76
    },
    {
      "level": "H1",
      "text": "Multi-task learning",
      "page": 76
    },
    {
      "level": "H1",
      "text": "）是使用多类标签的典型方法",
      "page": 76
    },
    {
      "level": "H1",
      "text": "[156],[157]",
      "page": 76
    },
    {
      "level": "H1",
      "text": "。在许",
      "page": 76
    },
    {
      "level": "H1",
      "text": "多先前的工作中，联合学习主任务和与主任务相关的副任务可以帮助网络以聚合",
      "page": 76
    },
    {
      "level": "H1",
      "text": "方式改进性能，例如性别分类有助于身份识别。而本章的目标是明确的消除某些",
      "page": 76
    },
    {
      "level": "H1",
      "text": "语义属性的影响。",
      "page": 76
    },
    {
      "level": "H1",
      "text": "对抗生成网络引起了越来越多的关注。通常来说基础的",
      "page": 76
    },
    {
      "level": "H1",
      "text": "GAN",
      "page": 76
    },
    {
      "level": "H1",
      "text": "[127]",
      "page": 76
    },
    {
      "level": "H1",
      "text": "使用二元博",
      "page": 76
    },
    {
      "level": "H1",
      "text": "弈（即，生成器和鉴别器），擅长产生逼真的图像，但是它们在识别问题上的潜",
      "page": 76
    },
    {
      "level": "H1",
      "text": "力仍有待开发。典型的方法使用",
      "page": 76
    },
    {
      "level": "H1",
      "text": "作为图像的预处理步骤，类似于“去噪”，",
      "page": 76
    },
    {
      "level": "H1",
      "text": "然后使用这些处理过的图像进行正常的训练和测试。而本章将经过训练的对抗网",
      "page": 76
    },
    {
      "level": "H1",
      "text": "络直接部署为特征提取器，而不用进行第二阶段的训练",
      "page": 76
    },
    {
      "level": "H1",
      "text": "[130],[131]",
      "page": 76
    },
    {
      "level": "H1",
      "text": "与像素级",
      "page": 76
    },
    {
      "level": "H1",
      "text": "相比，本章采用的特征级竞争是一种更简单的训练方案，并",
      "page": 76
    },
    {
      "level": "H1",
      "text": "且可以很好地扩展到多个属性。而且像素级",
      "page": 76
    },
    {
      "level": "H1",
      "text": "通常不能消除与任务相关的语",
      "page": 76
    },
    {
      "level": "H1",
      "text": "义变量，例如从身份识别任务中消除性别因素就难以获得看起来真实的与后续网",
      "page": 76
    },
    {
      "level": "H1",
      "text": "络训练相似的面部图像，难以用来进行预处理。",
      "page": 76
    },
    {
      "level": "H1",
      "text": "此外，他们通常专注于特定任务的单一变量。实际上，大多数",
      "page": 76
    },
    {
      "level": "H1",
      "text": "和对抗",
      "page": 76
    },
    {
      "level": "H1",
      "text": "域适应（",
      "page": 76
    },
    {
      "level": "H1",
      "text": "Adversarial domain adaptation",
      "page": 76
    },
    {
      "level": "H1",
      "text": "[162],[163]",
      "page": 76
    },
    {
      "level": "H1",
      "text": "使用二元对抗性优化目标并且应",
      "page": 76
    },
    {
      "level": "H1",
      "text": "用于两个分布间。",
      "page": 76
    },
    {
      "level": "H1",
      "text": "值得注意的是有一些",
      "page": 76
    },
    {
      "level": "H1",
      "text": "相关变形，例如",
      "page": 76
    },
    {
      "level": "H1",
      "text": "simi-GAN",
      "page": 76
    },
    {
      "level": "H1",
      "text": "[164]",
      "page": 76
    },
    {
      "level": "H1",
      "text": "DR-GAN",
      "page": 76
    },
    {
      "level": "H1",
      "text": "[130]",
      "page": 76
    },
    {
      "level": "H1",
      "text": "基于对抗训练的人脸身份与表情特征剥离及识别",
      "page": 77
    },
    {
      "level": "H1",
      "text": "虑了多个侧标签。实际上他们仅为多分类任务添加了一个新的分支，但是他们的",
      "page": 77
    },
    {
      "level": "H1",
      "text": "竞争对抗性损失仍然只会通过使用两个分布（真实的或生成的）来混淆鉴别器，",
      "page": 77
    },
    {
      "level": "H1",
      "text": "而辅助多分类器分支中的不同类别之间不采用对抗策略。",
      "page": 77
    },
    {
      "level": "H1",
      "text": "本章所提出的方法在两个方面与它们不同：",
      "page": 77
    },
    {
      "level": "H1",
      "text": "）语义鉴别器的输入是特征，",
      "page": 77
    },
    {
      "level": "H1",
      "text": "而不是真实",
      "page": 77
    },
    {
      "level": "H1",
      "text": "合成图像",
      "page": 77
    },
    {
      "level": "H1",
      "text": "; 2",
      "page": 77
    },
    {
      "level": "H1",
      "text": "）编码器的目标需要匹配或对齐任意两个不同属性之间",
      "page": 77
    },
    {
      "level": "H1",
      "text": "的特征分布，而不仅仅是两个真",
      "page": 77
    },
    {
      "level": "H1",
      "text": "假分布，并且语义鉴别器中没有“真实”类别。",
      "page": 77
    },
    {
      "level": "H1",
      "text": "公平识别（",
      "page": 77
    },
    {
      "level": "H1",
      "text": "Fairness recognition",
      "page": 77
    },
    {
      "level": "H1",
      "text": "）也需要对某些任务相关变量不变，从而使预",
      "page": 77
    },
    {
      "level": "H1",
      "text": "测公平。由于使用历史数据训练的数据驱动模型很容易继承数据中的偏差，因此",
      "page": 77
    },
    {
      "level": "H1",
      "text": "Fair VAEs",
      "page": 77
    },
    {
      "level": "H1",
      "text": "使用具有最大均值差异（",
      "page": 77
    },
    {
      "level": "H1",
      "text": "maximum mean discrepancy, MMD",
      "page": 77
    },
    {
      "level": "H1",
      "text": "）正则化的",
      "page": 77
    },
    {
      "level": "H1",
      "text": "变分自动编码器结构来解决该问题。建议将具有不同语义变量的数据的表示分布",
      "page": 77
    },
    {
      "level": "H1",
      "text": "之间的",
      "page": 77
    },
    {
      "level": "H1",
      "text": "距离正则化，以实现公平性。这些方法具有相同的缺点，即用于正则化",
      "page": 77
    },
    {
      "level": "H1",
      "text": "的距离约束是成对的，这对于多个语义变量而言不能很好地扩展。",
      "page": 77
    },
    {
      "level": "H1",
      "text": "特征解构（",
      "page": 77
    },
    {
      "level": "H1",
      "text": "Feature disentanglement",
      "page": 77
    },
    {
      "level": "H1",
      "text": "）也与本章的工作密切相关。它试图根据",
      "page": 77
    },
    {
      "level": "H1",
      "text": "输入与单标签数据集设置中的图像变换任务的相关性将输入分成两个互补的特",
      "page": 77
    },
    {
      "level": "H1",
      "text": "征编码",
      "page": 77
    },
    {
      "level": "H1",
      "text": "[166]",
      "page": 77
    },
    {
      "level": "H1",
      "text": "。早期尝试使用双线性模型将文本与字体分开",
      "page": 77
    },
    {
      "level": "H1",
      "text": "[167]",
      "page": 77
    },
    {
      "level": "H1",
      "text": "。流形学习和",
      "page": 77
    },
    {
      "level": "H1",
      "text": "VAE",
      "page": 77
    },
    {
      "level": "H1",
      "text": "于将数字与风格分开",
      "page": 77
    },
    {
      "level": "H1",
      "text": "[168]",
      "page": 77
    },
    {
      "level": "H1",
      "text": "What-where",
      "page": 77
    },
    {
      "level": "H1",
      "text": "” 编码器将重建标准与辨别力",
      "page": 77
    },
    {
      "level": "H1",
      "text": "Discrimination",
      "page": 77
    },
    {
      "level": "H1",
      "text": "）相结合，以分离与标签相关的因素",
      "page": 77
    },
    {
      "level": "H1",
      "text": "[169]",
      "page": 77
    },
    {
      "level": "H1",
      "text": "。文献",
      "page": 77
    },
    {
      "level": "H1",
      "text": "[154],[170]",
      "page": 77
    },
    {
      "level": "H1",
      "text": "GAN",
      "page": 77
    },
    {
      "level": "H1",
      "text": "目标添加到",
      "page": 77
    },
    {
      "level": "H1",
      "text": "的目标中，进一步降低了复杂性。受它们的启发，本章的框架",
      "page": 77
    },
    {
      "level": "H1",
      "text": "隐性的要求",
      "page": 77
    },
    {
      "level": "H1",
      "text": "鲁棒，以便以简单而有效的方式获得更好的通用性。本章的核",
      "page": 77
    },
    {
      "level": "H1",
      "text": "心是去除",
      "page": 77
    },
    {
      "level": "H1",
      "text": "的识别任务，而非针对于图像类比任务",
      "page": 77
    },
    {
      "level": "H1",
      "text": "[154]",
      "page": 77
    },
    {
      "level": "H1",
      "text": "4.2",
      "page": 77
    },
    {
      "level": "H1",
      "text": "特征级弗兰肯斯坦框架",
      "page": 77
    },
    {
      "level": "H1",
      "text": "4.2.1",
      "page": 77
    },
    {
      "level": "H1",
      "text": "问题定义",
      "page": 77
    },
    {
      "level": "H1",
      "text": "首先将特征级弗兰肯斯坦（",
      "page": 77
    },
    {
      "level": "H1",
      "text": "Feature-level Frankenstein, FLF",
      "page": 77
    },
    {
      "level": "H1",
      "text": "）框架的任务规范",
      "page": 77
    },
    {
      "level": "H1",
      "text": "化如下：给定训练集",
      "page": 77
    },
    {
      "level": "H1",
      "text": "𝒟= {𝑥",
      "page": 77
    },
    {
      "level": "H1",
      "text": ", 𝑠",
      "page": 77
    },
    {
      "level": "H1",
      "text": ", 𝑦",
      "page": 77
    },
    {
      "level": "H1",
      "text": "}, ⋯, {𝑥",
      "page": 77
    },
    {
      "level": "H1",
      "text": "个样本",
      "page": 77
    },
    {
      "level": "H1",
      "text": "图像，语义变",
      "page": 77
    },
    {
      "level": "H1",
      "text": "量，类别",
      "page": 77
    },
    {
      "level": "H1",
      "text": "的表示为三个互补的特征表示，即有辨别力的表示",
      "page": 77
    },
    {
      "level": "H1",
      "text": "，语义变量",
      "page": 77
    },
    {
      "level": "H1",
      "text": "和潜在变量",
      "page": 77
    },
    {
      "level": "H1",
      "text": "。这三个特征向量彼此之间相互独立，如图",
      "page": 77
    },
    {
      "level": "H1",
      "text": "4.1",
      "page": 77
    },
    {
      "level": "H1",
      "text": "所示。对于人脸图",
      "page": 77
    },
    {
      "level": "H1",
      "text": "像而言，若主识别任务为身份，则典型的语义变量包括性别，表情等。所有未由",
      "page": 77
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 78
    },
    {
      "level": "H1",
      "text": "定义或相关的因素都归属于潜在变量。如第二节中所讨论的，",
      "page": 78
    },
    {
      "level": "H1",
      "text": "种可能的依赖性关系。与",
      "page": 78
    },
    {
      "level": "H1",
      "text": "相关的信息应该包含",
      "page": 78
    },
    {
      "level": "H1",
      "text": "和与主任务相关的",
      "page": 78
    },
    {
      "level": "H1",
      "text": "4.2",
      "page": 78
    },
    {
      "level": "H1",
      "text": "所提出的特征级弗兰肯斯坦框架，其中",
      "page": 78
    },
    {
      "level": "H1",
      "text": "被两个编码器编码成",
      "page": 78
    },
    {
      "level": "H1",
      "text": "部分（即，",
      "page": 78
    },
    {
      "level": "H1",
      "text": "），并且（",
      "page": 78
    },
    {
      "level": "H1",
      "text": "）的组合可以通过解码器重建为",
      "page": 78
    },
    {
      "level": "H1",
      "text": "。对抗训练的",
      "page": 78
    },
    {
      "level": "H1",
      "text": "dis",
      "page": 78
    },
    {
      "level": "H1",
      "text": "与分类器用于在潜",
      "page": 78
    },
    {
      "level": "H1",
      "text": "在的特征空间进行约束。",
      "page": 78
    },
    {
      "level": "H1",
      "text": "Figure 4.2 The proposed Feature-level Frankenstein framework, where the",
      "page": 78
    },
    {
      "level": "H1",
      "text": "is encoded into",
      "page": 78
    },
    {
      "level": "H1",
      "text": "3 parts (i.e.,",
      "page": 78
    },
    {
      "level": "H1",
      "text": "d, l, s",
      "page": 78
    },
    {
      "level": "H1",
      "text": ") by two encoders, and a combination of (",
      "page": 78
    },
    {
      "level": "H1",
      "text": ") can be reconstructed to",
      "page": 78
    },
    {
      "level": "H1",
      "text": "via decoder. The adversarial trained dis, classifiers are used to constrain the feature space.",
      "page": 78
    },
    {
      "level": "H1",
      "text": "对于潜在变量的编码，选择",
      "page": 78
    },
    {
      "level": "H1",
      "text": "为实数值的向量而不是独热（",
      "page": 78
    },
    {
      "level": "H1",
      "text": "one-hot",
      "page": 78
    },
    {
      "level": "H1",
      "text": "）向量，",
      "page": 78
    },
    {
      "level": "H1",
      "text": "以使网络能够推广到训练数据集中未包含的身份个体",
      "page": 78
    },
    {
      "level": "H1",
      "text": "[154],[171]",
      "page": 78
    },
    {
      "level": "H1",
      "text": "。而由于语义变量是",
      "page": 78
    },
    {
      "level": "H1",
      "text": "多标签任务中人为定义的。理论上，",
      "page": 78
    },
    {
      "level": "H1",
      "text": "可以是任何类型的数据（例如，连续值标",
      "page": 78
    },
    {
      "level": "H1",
      "text": "向量），只要能表示",
      "page": 78
    },
    {
      "level": "H1",
      "text": "的语义属性即可。为简单起见，在此考虑一种简单的情",
      "page": 78
    },
    {
      "level": "H1",
      "text": "况，其中",
      "page": 78
    },
    {
      "level": "H1",
      "text": "维的二元变量，即每一维度取值为",
      "page": 78
    },
    {
      "level": "H1",
      "text": "，用于",
      "page": 78
    },
    {
      "level": "H1",
      "text": "个待控制的语",
      "page": 78
    },
    {
      "level": "H1",
      "text": "义变量。对于多分类数据库中",
      "page": 78
    },
    {
      "level": "H1",
      "text": "类待控制标签，它们被分解为",
      "page": 78
    },
    {
      "level": "H1",
      "text": "个二元选择。",
      "page": 78
    },
    {
      "level": "H1",
      "text": "当语义变量是一维二元的伯努利变量时（即，",
      "page": 78
    },
    {
      "level": "H1",
      "text": "𝑠= {0,1}",
      "page": 78
    },
    {
      "level": "H1",
      "text": "），域自适应（",
      "page": 78
    },
    {
      "level": "H1",
      "text": "domain",
      "page": 78
    },
    {
      "level": "H1",
      "text": "adaptation",
      "page": 78
    },
    {
      "level": "H1",
      "text": "）可以看做是",
      "page": 78
    },
    {
      "level": "H1",
      "text": "FLF",
      "page": 78
    },
    {
      "level": "H1",
      "text": "模型的特殊情况。",
      "page": 78
    },
    {
      "level": "H1",
      "text": "4.2.2",
      "page": 78
    },
    {
      "level": "H1",
      "text": "框架结构",
      "page": 78
    },
    {
      "level": "H1",
      "text": "基于条件对抗训练的编码器",
      "page": 78
    },
    {
      "level": "H1",
      "text": "解码器架构，提出了图",
      "page": 78
    },
    {
      "level": "H1",
      "text": "中描述的模型以实",
      "page": 78
    },
    {
      "level": "H1",
      "text": "现目标。在推理阶段，测试图像被编码到隐空间中的",
      "page": 78
    },
    {
      "level": "H1",
      "text": "，并且",
      "page": 78
    },
    {
      "level": "H1",
      "text": "可以用于具",
      "page": 78
    },
    {
      "level": "H1",
      "text": "有关于",
      "page": 78
    },
    {
      "level": "H1",
      "text": "的不变性的识别任务。此外，用户可以选择",
      "page": 78
    },
    {
      "level": "H1",
      "text": "的组合，并使用解码",
      "page": 78
    },
    {
      "level": "H1",
      "text": "器生成图片以用于不同的图像变换。特征级弗兰肯斯坦框架（",
      "page": 78
    },
    {
      "level": "H1",
      "text": "）的训练流程",
      "page": 78
    },
    {
      "level": "H1",
      "text": "基于对抗训练的人脸身份与表情特征剥离及识别",
      "page": 79
    },
    {
      "level": "H1",
      "text": "详述于算法",
      "page": 79
    },
    {
      "level": "H1",
      "text": "4.1",
      "page": 79
    },
    {
      "level": "H1",
      "text": "对主要识别任务具有充分信息",
      "page": 79
    },
    {
      "level": "H1",
      "text": "具有参数",
      "page": 79
    },
    {
      "level": "H1",
      "text": "的辨别力编码器",
      "page": 79
    },
    {
      "level": "H1",
      "text": "将输入图像映射到其具有辨别力的特征表示",
      "page": 79
    },
    {
      "level": "H1",
      "text": "𝑑= 𝐸",
      "page": 79
    },
    {
      "level": "H1",
      "text": "(𝑥)",
      "page": 79
    },
    {
      "level": "H1",
      "text": "，其包含充分的信息用于主识别任务并且对于一些语义属性是不变的。",
      "page": 79
    },
    {
      "level": "H1",
      "text": "不变性指的是给定两个样本",
      "page": 79
    },
    {
      "level": "H1",
      "text": "来自主题类",
      "page": 79
    },
    {
      "level": "H1",
      "text": "= 𝑦",
      "page": 79
    },
    {
      "level": "H1",
      "text": "但具有不同的语义属性",
      "page": 79
    },
    {
      "level": "H1",
      "text": "，它们的",
      "page": 79
    },
    {
      "level": "H1",
      "text": "预计是相同的。给定获得的",
      "page": 79
    },
    {
      "level": "H1",
      "text": "，期望用分类器",
      "page": 79
    },
    {
      "level": "H1",
      "text": "测其对应的标签",
      "page": 79
    },
    {
      "level": "H1",
      "text": "以对分布",
      "page": 79
    },
    {
      "level": "H1",
      "text": "(𝑦|𝑥)",
      "page": 79
    },
    {
      "level": "H1",
      "text": "进行建模。",
      "page": 79
    },
    {
      "level": "H1",
      "text": "的任务和",
      "page": 79
    },
    {
      "level": "H1",
      "text": "的第一个目标是确",
      "page": 79
    },
    {
      "level": "H1",
      "text": "保主要识别任务的准确性。因此需最小化：",
      "page": 79
    },
    {
      "level": "H1",
      "text": "其中使用分类器的分类交叉熵损失。",
      "page": 79
    },
    {
      "level": "H1",
      "text": "𝑞(𝑥, 𝑠, 𝑦)",
      "page": 79
    },
    {
      "level": "H1",
      "text": "是经验观察得出的真实基础分布。",
      "page": 79
    },
    {
      "level": "H1",
      "text": "）消除语义变量",
      "page": 79
    },
    {
      "level": "H1",
      "text": "判别器",
      "page": 79
    },
    {
      "level": "H1",
      "text": "Dis",
      "page": 79
    },
    {
      "level": "H1",
      "text": "输出属性向量的概率",
      "page": 79
    },
    {
      "level": "H1",
      "text": "஽௜௦",
      "page": 79
    },
    {
      "level": "H1",
      "text": "(𝑠|𝑑)",
      "page": 79
    },
    {
      "level": "H1",
      "text": "在实际操作中是通过串联",
      "page": 79
    },
    {
      "level": "H1",
      "text": "和二元",
      "page": 79
    },
    {
      "level": "H1",
      "text": "属性代码",
      "page": 79
    },
    {
      "level": "H1",
      "text": "用于输入并使用",
      "page": 79
    },
    {
      "level": "H1",
      "text": "sigmoid",
      "page": 79
    },
    {
      "level": "H1",
      "text": "单元输出",
      "page": 79
    },
    {
      "level": "H1",
      "text": "[0,1]",
      "page": 79
    },
    {
      "level": "H1",
      "text": "值来实现的。它的损失取决于",
      "page": 79
    },
    {
      "level": "H1",
      "text": "编码器",
      "page": 79
    },
    {
      "level": "H1",
      "text": "的当前状态，并写成：",
      "page": 79
    },
    {
      "level": "H1",
      "text": "௠௜௡",
      "page": 79
    },
    {
      "level": "H1",
      "text": "௠௔௫",
      "page": 79
    },
    {
      "level": "H1",
      "text": "= 𝔼",
      "page": 79
    },
    {
      "level": "H1",
      "text": "−𝚕𝚘𝚐𝑝",
      "page": 79
    },
    {
      "level": "H1",
      "text": "(𝑠|𝐸",
      "page": 79
    },
    {
      "level": "H1",
      "text": "(𝑥))",
      "page": 79
    },
    {
      "level": "H1",
      "text": "(4.3)",
      "page": 79
    },
    {
      "level": "H1",
      "text": "具体地，",
      "page": 79
    },
    {
      "level": "H1",
      "text": "进行对抗性博弈，其中",
      "page": 79
    },
    {
      "level": "H1",
      "text": "被训练为通过最大化似然性",
      "page": 79
    },
    {
      "level": "H1",
      "text": "来正确检测数据的语义属性",
      "page": 79
    },
    {
      "level": "H1",
      "text": "通过最小化相同的可能性来去除",
      "page": 79
    },
    {
      "level": "H1",
      "text": "相关信息。式",
      "page": 79
    },
    {
      "level": "H1",
      "text": "4.3",
      "page": 79
    },
    {
      "level": "H1",
      "text": "相互独立。假设语义变化遵循伯努利分布，则将损",
      "page": 79
    },
    {
      "level": "H1",
      "text": "失表示为",
      "page": 79
    },
    {
      "level": "H1",
      "text": "−{𝑠𝚕𝚘𝚐𝐷𝑖𝑠(𝑑) + (1 −𝑠)𝚕𝚘𝚐(1 −𝐷𝑖𝑠(𝑑))}",
      "page": 79
    },
    {
      "level": "H1",
      "text": "。所提出的框架易于通过扩",
      "page": 79
    },
    {
      "level": "H1",
      "text": "展语义变量的维度来控制多个属性。对于",
      "page": 79
    },
    {
      "level": "H1",
      "text": "个待被消除的语义变量，损失函数可",
      "page": 79
    },
    {
      "level": "H1",
      "text": "用二元编码作为属性的值，也可以在推理阶段将每个属性视为",
      "page": 79
    },
    {
      "level": "H1",
      "text": "间的连续变",
      "page": 79
    },
    {
      "level": "H1",
      "text": "量，以控制在生成的图像中包含某特定属性的程度。",
      "page": 79
    },
    {
      "level": "H1",
      "text": "节所述，语义鉴别器（",
      "page": 79
    },
    {
      "level": "H1",
      "text": "semantic discriminator",
      "page": 79
    },
    {
      "level": "H1",
      "text": "）与传统的",
      "page": 79
    },
    {
      "level": "H1",
      "text": "GAN",
      "page": 79
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 80
    },
    {
      "level": "H1",
      "text": "大的区别，不仅仅是真",
      "page": 80
    },
    {
      "level": "H1",
      "text": "假分类。特征层级的竞争也类似于对抗性自编码器",
      "page": 80
    },
    {
      "level": "H1",
      "text": "[42]",
      "page": 80
    },
    {
      "level": "H1",
      "text": "自编码器要求中间隐变量与先验分布（例如高斯分布）匹配。",
      "page": 80
    },
    {
      "level": "H1",
      "text": "）消除语义变量",
      "page": 80
    },
    {
      "level": "H1",
      "text": "为了训练潜在变量编码器",
      "page": 80
    },
    {
      "level": "H1",
      "text": "，提出了一种对抗性网络，其中",
      "page": 80
    },
    {
      "level": "H1",
      "text": "用分类器",
      "page": 80
    },
    {
      "level": "H1",
      "text": "不是鉴别器进行极小极大迭代优化的博弈。",
      "page": 80
    },
    {
      "level": "H1",
      "text": "检查潜在变量",
      "page": 80
    },
    {
      "level": "H1",
      "text": "并且学习正确地从",
      "page": 80
    },
    {
      "level": "H1",
      "text": "中预测类标签，而",
      "page": 80
    },
    {
      "level": "H1",
      "text": "试图通过欺骗",
      "page": 80
    },
    {
      "level": "H1",
      "text": "做出错误预测来消除与主任务相关的因素",
      "page": 80
    },
    {
      "level": "H1",
      "text": "的真实值是不可观察的即无真实标签的，因此选择消除与",
      "page": 80
    },
    {
      "level": "H1",
      "text": "有关的信息。",
      "page": 80
    },
    {
      "level": "H1",
      "text": "和主要任务相关的",
      "page": 80
    },
    {
      "level": "H1",
      "text": "௠௜௡",
      "page": 80
    },
    {
      "level": "H1",
      "text": "௠௔௫",
      "page": 80
    },
    {
      "level": "H1",
      "text": "= 𝔼",
      "page": 80
    },
    {
      "level": "H1",
      "text": "−𝚕𝚘𝚐𝑝",
      "page": 80
    },
    {
      "level": "H1",
      "text": "(𝑦|𝐸",
      "page": 80
    },
    {
      "level": "H1",
      "text": "(𝑥))",
      "page": 80
    },
    {
      "level": "H1",
      "text": "(4.4)",
      "page": 80
    },
    {
      "level": "H1",
      "text": "在具体实现中使用",
      "page": 80
    },
    {
      "level": "H1",
      "text": "softmax",
      "page": 80
    },
    {
      "level": "H1",
      "text": "输出单元和交叉熵损失。与使用三个平行",
      "page": 80
    },
    {
      "level": "H1",
      "text": "VAE",
      "page": 80
    },
    {
      "level": "H1",
      "text": "络架构",
      "page": 80
    },
    {
      "level": "H1",
      "text": "[154]",
      "page": 80
    },
    {
      "level": "H1",
      "text": "相比，对抗性分类器有望减轻复杂的训练过程并促进收敛。",
      "page": 80
    },
    {
      "level": "H1",
      "text": "）消除语",
      "page": 80
    },
    {
      "level": "H1",
      "text": "的互补性约束",
      "page": 80
    },
    {
      "level": "H1",
      "text": "解码器",
      "page": 80
    },
    {
      "level": "H1",
      "text": "Dec",
      "page": 80
    },
    {
      "level": "H1",
      "text": "为一个反卷积网络，用于在给定串联特征编码",
      "page": 80
    },
    {
      "level": "H1",
      "text": "𝑑, 𝑠, 𝑙",
      "page": 80
    },
    {
      "level": "H1",
      "text": "的情况下生",
      "page": 80
    },
    {
      "level": "H1",
      "text": "特征级弗兰肯斯坦框架（",
      "page": 80
    },
    {
      "level": "H1",
      "text": "FLF",
      "page": 80
    },
    {
      "level": "H1",
      "text": "）的训练流程",
      "page": 80
    },
    {
      "level": "H1",
      "text": "初始化网络参数",
      "page": 80
    },
    {
      "level": "H1",
      "text": "在数据集中随机采样",
      "page": 80
    },
    {
      "level": "H1",
      "text": "{𝑥, 𝑠, 𝑦}",
      "page": 80
    },
    {
      "level": "H1",
      "text": "mini-batch",
      "page": 80
    },
    {
      "level": "H1",
      "text": "𝑑←𝐸",
      "page": 80
    },
    {
      "level": "H1",
      "text": "(𝑥)",
      "page": 80
    },
    {
      "level": "H1",
      "text": "𝑙←𝐸",
      "page": 80
    },
    {
      "level": "H1",
      "text": "←𝐷𝑒𝑐(𝑑, 𝑠, 𝑙)",
      "page": 80
    },
    {
      "level": "H1",
      "text": "஽௜௦",
      "page": 80
    },
    {
      "level": "H1",
      "text": "(𝑠|𝐸",
      "page": 80
    },
    {
      "level": "H1",
      "text": "௥௘௖",
      "page": 80
    },
    {
      "level": "H1",
      "text": "∥𝐷𝑒𝑐(𝑑, 𝑙, 𝑠) −𝑥∥",
      "page": 80
    },
    {
      "level": "H1",
      "text": "依据梯度更新网络参数",
      "page": 80
    },
    {
      "level": "H1",
      "text": "−𝛼ℒ",
      "page": 80
    },
    {
      "level": "H1",
      "text": "+ 𝛽ℒ",
      "page": 80
    },
    {
      "level": "H1",
      "text": "(𝜆ℒ",
      "page": 80
    },
    {
      "level": "H1",
      "text": "ೝ೐೎",
      "page": 80
    },
    {
      "level": "H1",
      "text": "ௗ௜௦",
      "page": 80
    },
    {
      "level": "H1",
      "text": "基于对抗训练的人脸身份与表情特征剥离及识别",
      "page": 81
    },
    {
      "level": "H1",
      "text": "成新版本的图像。这三个部分应包含足够的信息以允许使用输入图像的",
      "page": 81
    },
    {
      "level": "H1",
      "text": "𝑑, 𝑠, 𝑙",
      "page": 81
    },
    {
      "level": "H1",
      "text": "。重构相似性可定义为重建后的图像与输入图像的均方误差（",
      "page": 81
    },
    {
      "level": "H1",
      "text": "mean squared",
      "page": 81
    },
    {
      "level": "H1",
      "text": "error, MSE",
      "page": 81
    },
    {
      "level": "H1",
      "text": "(4.5)",
      "page": 81
    },
    {
      "level": "H1",
      "text": "该损失可以使特征编码",
      "page": 81
    },
    {
      "level": "H1",
      "text": "互补性的包含重建图像所需的内容。",
      "page": 81
    },
    {
      "level": "H1",
      "text": "4.2.3",
      "page": 81
    },
    {
      "level": "H1",
      "text": "独立性分析",
      "page": 81
    },
    {
      "level": "H1",
      "text": "FLF",
      "page": 81
    },
    {
      "level": "H1",
      "text": "框架通过一系列设计使得三个互补的部分彼此不相关。",
      "page": 81
    },
    {
      "level": "H1",
      "text": "独立，因为在框架设计中",
      "page": 81
    },
    {
      "level": "H1",
      "text": "使用的二元特征向量几乎无法包含其他信息。",
      "page": 81
    },
    {
      "level": "H1",
      "text": "要识别任务有效边际独立于",
      "page": 81
    },
    {
      "level": "H1",
      "text": "主要是通过最大化主要任务预测的准确性（式",
      "page": 81
    },
    {
      "level": "H1",
      "text": "4.1",
      "page": 81
    },
    {
      "level": "H1",
      "text": "以及在给定",
      "page": 81
    },
    {
      "level": "H1",
      "text": "的情况下预测语义变量的不确定性（式",
      "page": 81
    },
    {
      "level": "H1",
      "text": "4.3",
      "page": 81
    },
    {
      "level": "H1",
      "text": "）来实现的。给定",
      "page": 81
    },
    {
      "level": "H1",
      "text": "小化在式",
      "page": 81
    },
    {
      "level": "H1",
      "text": "4.4",
      "page": 81
    },
    {
      "level": "H1",
      "text": "中进行主要任务（",
      "page": 81
    },
    {
      "level": "H1",
      "text": "）预测的确定性，可以使",
      "page": 81
    },
    {
      "level": "H1",
      "text": "边际独立于",
      "page": 81
    },
    {
      "level": "H1",
      "text": "和一些",
      "page": 81
    },
    {
      "level": "H1",
      "text": "与任务相关的",
      "page": 81
    },
    {
      "level": "H1",
      "text": "考虑到框架的复杂性，并没有严格要求学到的",
      "page": 81
    },
    {
      "level": "H1",
      "text": "边际独立于任务无关的",
      "page": 81
    },
    {
      "level": "H1",
      "text": "在数据集中",
      "page": 81
    },
    {
      "level": "H1",
      "text": "也不存在真实标签以监督",
      "page": 81
    },
    {
      "level": "H1",
      "text": "边际独立于潜在变量",
      "page": 81
    },
    {
      "level": "H1",
      "text": "。因此，",
      "page": 81
    },
    {
      "level": "H1",
      "text": "的输出限制为一个合适的较短维度以形成信息瓶颈，从而隐性地要求",
      "page": 81
    },
    {
      "level": "H1",
      "text": "中包含很少的其余信息",
      "page": 81
    },
    {
      "level": "H1",
      "text": "[173]",
      "page": 81
    },
    {
      "level": "H1",
      "text": "。另外，重建损失被用作补充约束，这避免了",
      "page": 81
    },
    {
      "level": "H1",
      "text": "不包含任何内容。若",
      "page": 81
    },
    {
      "level": "H1",
      "text": "中包含较多其余信息则较难实现其各自的分类任",
      "page": 81
    },
    {
      "level": "H1",
      "text": "务和生成任务。",
      "page": 81
    },
    {
      "level": "H1",
      "text": "4.2.4",
      "page": 81
    },
    {
      "level": "H1",
      "text": "平衡条件",
      "page": 81
    },
    {
      "level": "H1",
      "text": "若干取值在",
      "page": 81
    },
    {
      "level": "H1",
      "text": "之间的超参数用于平衡选择的损失函数。训练",
      "page": 81
    },
    {
      "level": "H1",
      "text": "以最小化",
      "page": 81
    },
    {
      "level": "H1",
      "text": "(−ℒ",
      "page": 81
    },
    {
      "level": "H1",
      "text": "+ 𝜆ℒ",
      "page": 81
    },
    {
      "level": "H1",
      "text": "௥௘௖",
      "page": 81
    },
    {
      "level": "H1",
      "text": "用于加权潜在特征与类别标签的相关性以及重建的质量。",
      "page": 81
    },
    {
      "level": "H1",
      "text": "通过最小化",
      "page": 81
    },
    {
      "level": "H1",
      "text": "஽௜௦",
      "page": 81
    },
    {
      "level": "H1",
      "text": "−𝛼ℒ",
      "page": 81
    },
    {
      "level": "H1",
      "text": "+ 𝛽ℒ",
      "page": 81
    },
    {
      "level": "H1",
      "text": "来更新",
      "page": 81
    },
    {
      "level": "H1",
      "text": "用作互补性约束，",
      "page": 81
    },
    {
      "level": "H1",
      "text": "通常被",
      "page": 81
    },
    {
      "level": "H1",
      "text": "赋予相对较小的值。为简单起见，可省略此项来分析",
      "page": 81
    },
    {
      "level": "H1",
      "text": "的功能。消除语义变量的",
      "page": 81
    },
    {
      "level": "H1",
      "text": "优化目标可以表述为：",
      "page": 81
    },
    {
      "level": "H1",
      "text": "௠௜௡",
      "page": 81
    },
    {
      "level": "H1",
      "text": "௠௔௫",
      "page": 81
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 82
    },
    {
      "level": "H1",
      "text": "为解释在非参数假设下（",
      "page": 82
    },
    {
      "level": "H1",
      "text": "non-parametric assumptions",
      "page": 82
    },
    {
      "level": "H1",
      "text": "）即假设模型具有无限的能力",
      "page": 82
    },
    {
      "level": "H1",
      "text": "infinite capacity",
      "page": 82
    },
    {
      "level": "H1",
      "text": "），对抗博弈中如何平衡保留",
      "page": 82
    },
    {
      "level": "H1",
      "text": "和消除",
      "page": 82
    },
    {
      "level": "H1",
      "text": "的任务，针对",
      "page": 82
    },
    {
      "level": "H1",
      "text": "独立于",
      "page": 82
    },
    {
      "level": "H1",
      "text": "不独立于",
      "page": 82
    },
    {
      "level": "H1",
      "text": "两种情况进行了讨论。",
      "page": 82
    },
    {
      "level": "H1",
      "text": "考虑到",
      "page": 82
    },
    {
      "level": "H1",
      "text": "都使用从",
      "page": 82
    },
    {
      "level": "H1",
      "text": "通过确定性变换而得来的",
      "page": 82
    },
    {
      "level": "H1",
      "text": "，再此用",
      "page": 82
    },
    {
      "level": "H1",
      "text": "定性变换（",
      "page": 82
    },
    {
      "level": "H1",
      "text": "deterministic transformation",
      "page": 82
    },
    {
      "level": "H1",
      "text": "），因此",
      "page": 82
    },
    {
      "level": "H1",
      "text": "(𝑑∣𝑥)",
      "page": 82
    },
    {
      "level": "H1",
      "text": "𝛿(⋅)",
      "page": 82
    },
    {
      "level": "H1",
      "text": "表示的",
      "page": 82
    },
    {
      "level": "H1",
      "text": "delta",
      "page": 82
    },
    {
      "level": "H1",
      "text": "也具有",
      "page": 82
    },
    {
      "level": "H1",
      "text": "中的随机性并且具有其自身的隐式分布，可改写为：",
      "page": 82
    },
    {
      "level": "H1",
      "text": "௠௜௡",
      "page": 82
    },
    {
      "level": "H1",
      "text": "஽௜௦",
      "page": 82
    },
    {
      "level": "H1",
      "text": "௠௔௫",
      "page": 82
    },
    {
      "level": "H1",
      "text": "为分析新目标方程的均衡条件，首先推导出给定",
      "page": 82
    },
    {
      "level": "H1",
      "text": "的最优",
      "page": 82
    },
    {
      "level": "H1",
      "text": "𝐷𝑖𝑠",
      "page": 82
    },
    {
      "level": "H1",
      "text": "，然后证",
      "page": 82
    },
    {
      "level": "H1",
      "text": "明其全局最优性。对于给定的固定",
      "page": 82
    },
    {
      "level": "H1",
      "text": "，最优",
      "page": 82
    },
    {
      "level": "H1",
      "text": "(𝑦∣𝑑) = 𝑞",
      "page": 82
    },
    {
      "level": "H1",
      "text": "(𝑦∣𝑑)",
      "page": 82
    },
    {
      "level": "H1",
      "text": "，并且最",
      "page": 82
    },
    {
      "level": "H1",
      "text": "Dis",
      "page": 82
    },
    {
      "level": "H1",
      "text": "对应于",
      "page": 82
    },
    {
      "level": "H1",
      "text": "(𝑠∣𝑑) = 𝑞",
      "page": 82
    },
    {
      "level": "H1",
      "text": "(𝑠∣𝑑)",
      "page": 82
    },
    {
      "level": "H1",
      "text": "。最优",
      "page": 82
    },
    {
      "level": "H1",
      "text": "都是编码器",
      "page": 82
    },
    {
      "level": "H1",
      "text": "函数。因此通过将",
      "page": 82
    },
    {
      "level": "H1",
      "text": "代入到式",
      "page": 82
    },
    {
      "level": "H1",
      "text": "4.7",
      "page": 82
    },
    {
      "level": "H1",
      "text": "中，其可化为仅关于",
      "page": 82
    },
    {
      "level": "H1",
      "text": "的最小化问题：",
      "page": 82
    },
    {
      "level": "H1",
      "text": "𝐻(𝑞",
      "page": 82
    },
    {
      "level": "H1",
      "text": "(𝑦∣𝑑)) −𝛼𝐻(𝑞",
      "page": 82
    },
    {
      "level": "H1",
      "text": "(𝑠∣𝑑))",
      "page": 82
    },
    {
      "level": "H1",
      "text": "(4.8)",
      "page": 82
    },
    {
      "level": "H1",
      "text": "(𝑦∣𝑑))",
      "page": 82
    },
    {
      "level": "H1",
      "text": "分别为",
      "page": 82
    },
    {
      "level": "H1",
      "text": "的条件熵。",
      "page": 82
    },
    {
      "level": "H1",
      "text": "根据以上分析结果，优化目标由两个具有不同符号的条件熵组成。最小化第",
      "page": 82
    },
    {
      "level": "H1",
      "text": "一项可增加基于",
      "page": 82
    },
    {
      "level": "H1",
      "text": "的确定性用于主任务识别。相反，最小化有负号的第二",
      "page": 82
    },
    {
      "level": "H1",
      "text": "项相当于最大化基于",
      "page": 82
    },
    {
      "level": "H1",
      "text": "的不确定性，这可以从具有辨别力的特征表示",
      "page": 82
    },
    {
      "level": "H1",
      "text": "滤除关于语义变量",
      "page": 82
    },
    {
      "level": "H1",
      "text": "的信息。",
      "page": 82
    },
    {
      "level": "H1",
      "text": "对于属性",
      "page": 82
    },
    {
      "level": "H1",
      "text": "完全独立于主识别任务的情况，这两个项可以同时达到最优，从",
      "page": 82
    },
    {
      "level": "H1",
      "text": "而实现双赢均衡。例如，通过移除面部图像上的照明效果，可以更好地识别身份。",
      "page": 82
    },
    {
      "level": "H1",
      "text": "在使用理想的神经网络模型下，无论",
      "page": 82
    },
    {
      "level": "H1",
      "text": "的值如何，最优平衡解都是相同的。",
      "page": 82
    },
    {
      "level": "H1",
      "text": "也可能遇到两个目标相互竞争的情况。例如解除与主任务相关的语义变量可",
      "page": 82
    },
    {
      "level": "H1",
      "text": "能会损害主任务识别的性能。因此这两个熵的最优性不能同时实现，两个目标在",
      "page": 82
    },
    {
      "level": "H1",
      "text": "最终均衡中的相对强度由",
      "page": 82
    },
    {
      "level": "H1",
      "text": "控制。",
      "page": 82
    },
    {
      "level": "H1",
      "text": "基于对抗训练的人脸身份与表情特征剥离及识别",
      "page": 83
    },
    {
      "level": "H1",
      "text": "为了验证特征级弗兰肯斯坦（",
      "page": 83
    },
    {
      "level": "H1",
      "text": "FLF",
      "page": 83
    },
    {
      "level": "H1",
      "text": "）框架的性能和效果，在三个不同的识别",
      "page": 83
    },
    {
      "level": "H1",
      "text": "任务上定量地评估具有的期望不变性的判别表示。通过测量与每个特征表示部分",
      "page": 83
    },
    {
      "level": "H1",
      "text": "中包含的语义变量",
      "page": 83
    },
    {
      "level": "H1",
      "text": "或主任务标签",
      "page": 83
    },
    {
      "level": "H1",
      "text": "相关联的信息以进行分离效果的评估。",
      "page": 83
    },
    {
      "level": "H1",
      "text": "在所有实验中，对于训练编码器",
      "page": 83
    },
    {
      "level": "H1",
      "text": "解码器网络，判别器和分类器，利用",
      "page": 83
    },
    {
      "level": "H1",
      "text": "Adam",
      "page": 83
    },
    {
      "level": "H1",
      "text": "[136]",
      "page": 83
    },
    {
      "level": "H1",
      "text": "进行优化，学习率设置为",
      "page": 83
    },
    {
      "level": "H1",
      "text": "0.001",
      "page": 83
    },
    {
      "level": "H1",
      "text": "beta",
      "page": 83
    },
    {
      "level": "H1",
      "text": "0.9",
      "page": 83
    },
    {
      "level": "H1",
      "text": "。使用可变权重作为判别器损失系数",
      "page": 83
    },
    {
      "level": "H1",
      "text": "。最初将",
      "page": 83
    },
    {
      "level": "H1",
      "text": "设置为",
      "page": 83
    },
    {
      "level": "H1",
      "text": "，并按普通自动编码器训练模型的编码器",
      "page": 83
    },
    {
      "level": "H1",
      "text": "解码器。然后，",
      "page": 83
    },
    {
      "level": "H1",
      "text": "500,000",
      "page": 83
    },
    {
      "level": "H1",
      "text": "次迭代中线性增加到",
      "page": 83
    },
    {
      "level": "H1",
      "text": "0.5",
      "page": 83
    },
    {
      "level": "H1",
      "text": "，以缓慢地鼓励模型提取对",
      "page": 83
    },
    {
      "level": "H1",
      "text": "不变的特",
      "page": 83
    },
    {
      "level": "H1",
      "text": "征向量。若无此设置，",
      "page": 83
    },
    {
      "level": "H1",
      "text": "往往受到来自判别器的损失函数的影响太大，即使对于",
      "page": 83
    },
    {
      "level": "H1",
      "text": "值也是如此。所有模型都使用",
      "page": 83
    },
    {
      "level": "H1",
      "text": "TensorFlow",
      "page": 83
    },
    {
      "level": "H1",
      "text": "[138]",
      "page": 83
    },
    {
      "level": "H1",
      "text": "实现。",
      "page": 83
    },
    {
      "level": "H1",
      "text": "4.3.1",
      "page": 83
    },
    {
      "level": "H1",
      "text": "对光照鲁棒的人脸识别",
      "page": 83
    },
    {
      "level": "H1",
      "text": "对于光照不敏感的人脸识别任务使用的是扩展的",
      "page": 83
    },
    {
      "level": "H1",
      "text": "Yale-B",
      "page": 83
    },
    {
      "level": "H1",
      "text": "数据集",
      "page": 83
    },
    {
      "level": "H1",
      "text": "[174]",
      "page": 83
    },
    {
      "level": "H1",
      "text": "。它包括",
      "page": 83
    },
    {
      "level": "H1",
      "text": "个志愿者的",
      "page": 83
    },
    {
      "level": "H1",
      "text": "个不同照明条件下的面部图像，即前，左上，右上，左下",
      "page": 83
    },
    {
      "level": "H1",
      "text": "或右下。该数据集的目标是使用",
      "page": 83
    },
    {
      "level": "H1",
      "text": "预测图片的身份",
      "page": 83
    },
    {
      "level": "H1",
      "text": "。这里要去除的语义变量",
      "page": 83
    },
    {
      "level": "H1",
      "text": "是光照条件。而潜在变量",
      "page": 83
    },
    {
      "level": "H1",
      "text": "可以包括背景、表情等没有标签或者难以量化的信息，",
      "page": 83
    },
    {
      "level": "H1",
      "text": "但该数据集的背景和表情均较为单一。本文遵循",
      "page": 83
    },
    {
      "level": "H1",
      "text": "[159],[175]",
      "page": 83
    },
    {
      "level": "H1",
      "text": "使用两层",
      "page": 83
    },
    {
      "level": "H1",
      "text": "结构和其训",
      "page": 83
    },
    {
      "level": "H1",
      "text": "测试集划分。",
      "page": 83
    },
    {
      "level": "H1",
      "text": "进行人脸识别的结果展示在表",
      "page": 83
    },
    {
      "level": "H1",
      "text": "4.1",
      "page": 83
    },
    {
      "level": "H1",
      "text": "中。期望基于",
      "page": 83
    },
    {
      "level": "H1",
      "text": "分类有较低的准确性。更好的有判别力的特征表示",
      "page": 83
    },
    {
      "level": "H1",
      "text": "具有更高的",
      "page": 83
    },
    {
      "level": "H1",
      "text": "分类准确度和",
      "page": 83
    },
    {
      "level": "H1",
      "text": "更低的预测",
      "page": 83
    },
    {
      "level": "H1",
      "text": "的准确度。要消除的",
      "page": 83
    },
    {
      "level": "H1",
      "text": "Extended YaleB",
      "page": 83
    },
    {
      "level": "H1",
      "text": "上的照明条件，是与主",
      "page": 83
    },
    {
      "level": "H1",
      "text": "要任务无关的语义变量。",
      "page": 83
    },
    {
      "level": "H1",
      "text": "框架针对解除光照条件影响的优势体现于将准确度",
      "page": 83
    },
    {
      "level": "H1",
      "text": "提高到了",
      "page": 83
    },
    {
      "level": "H1",
      "text": "90.1",
      "page": 83
    },
    {
      "level": "H1",
      "text": "％，而最佳的基线方法则为",
      "page": 83
    },
    {
      "level": "H1",
      "text": "86.6",
      "page": 83
    },
    {
      "level": "H1",
      "text": "％的准确度。尽管使用",
      "page": 83
    },
    {
      "level": "H1",
      "text": "Lambertian",
      "page": 83
    },
    {
      "level": "H1",
      "text": "模型可以很好地模拟光照条件，但本章选择使用通用的神经网络来学习提取不变",
      "page": 83
    },
    {
      "level": "H1",
      "text": "特征，因此所提出的方法可以很容易地扩展到其他应用。",
      "page": 83
    },
    {
      "level": "H1",
      "text": "在去除",
      "page": 83
    },
    {
      "level": "H1",
      "text": "方面，如表",
      "page": 83
    },
    {
      "level": "H1",
      "text": "所示从",
      "page": 83
    },
    {
      "level": "H1",
      "text": "的分类的准确度从",
      "page": 83
    },
    {
      "level": "H1",
      "text": "56.5",
      "page": 83
    },
    {
      "level": "H1",
      "text": "％下降到",
      "page": 83
    },
    {
      "level": "H1",
      "text": "26.2",
      "page": 83
    },
    {
      "level": "H1",
      "text": "％几乎减半，因此",
      "page": 83
    },
    {
      "level": "H1",
      "text": "框架可以过滤光照条件的变化。值得注意的是，",
      "page": 83
    },
    {
      "level": "H1",
      "text": "种照明的机会概率，当",
      "page": 83
    },
    {
      "level": "H1",
      "text": "被完全消除时，应当接近",
      "page": 83
    },
    {
      "level": "H1",
      "text": "％而非",
      "page": 83
    },
    {
      "level": "H3",
      "text": "4. 3",
      "page": 83
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 84
    },
    {
      "level": "H1",
      "text": "4.1",
      "page": 84
    },
    {
      "level": "H1",
      "text": "分类准确性比较。",
      "page": 84
    },
    {
      "level": "H1",
      "text": "[159]",
      "page": 84
    },
    {
      "level": "H1",
      "text": "中的设置，利用",
      "page": 84
    },
    {
      "level": "H1",
      "text": "Logistics",
      "page": 84
    },
    {
      "level": "H1",
      "text": "回归分类器来预测",
      "page": 84
    },
    {
      "level": "H1",
      "text": "的准确",
      "page": 84
    },
    {
      "level": "H1",
      "text": "性并使用原始",
      "page": 84
    },
    {
      "level": "H1",
      "text": "来预测",
      "page": 84
    },
    {
      "level": "H1",
      "text": "Table 4.1 Classification accuracy comparisons. *Following the setting in",
      "page": 84
    },
    {
      "level": "H1",
      "text": ", we utilize the",
      "page": 84
    },
    {
      "level": "H1",
      "text": "Logistics Regression classifier for the accuracy of predicting the",
      "page": 84
    },
    {
      "level": "H1",
      "text": "and using original",
      "page": 84
    },
    {
      "level": "H1",
      "text": "predict",
      "page": 84
    },
    {
      "level": "H1",
      "text": "Method",
      "page": 84
    },
    {
      "level": "H1",
      "text": "(𝑦∣𝑑)",
      "page": 84
    },
    {
      "level": "H1",
      "text": "(𝑠∣𝑑)",
      "page": 84
    },
    {
      "level": "H1",
      "text": "(𝑦∣𝑙)",
      "page": 84
    },
    {
      "level": "H1",
      "text": "(𝑠∣𝑙)",
      "page": 84
    },
    {
      "level": "H1",
      "text": "Original",
      "page": 84
    },
    {
      "level": "H1",
      "text": "78.0%",
      "page": 84
    },
    {
      "level": "H1",
      "text": "96.1%",
      "page": 84
    },
    {
      "level": "H1",
      "text": "[175]",
      "page": 84
    },
    {
      "level": "H1",
      "text": "82%",
      "page": 84
    },
    {
      "level": "H1",
      "text": "Louizos",
      "page": 84
    },
    {
      "level": "H1",
      "text": "84.6%",
      "page": 84
    },
    {
      "level": "H1",
      "text": "56.5%",
      "page": 84
    },
    {
      "level": "H1",
      "text": "Daniel",
      "page": 84
    },
    {
      "level": "H1",
      "text": "[176]",
      "page": 84
    },
    {
      "level": "H1",
      "text": "86.6%",
      "page": 84
    },
    {
      "level": "H1",
      "text": "47.9%",
      "page": 84
    },
    {
      "level": "H1",
      "text": "Proposed",
      "page": 84
    },
    {
      "level": "H1",
      "text": "90.1",
      "page": 84
    },
    {
      "level": "H1",
      "text": "26.2",
      "page": 84
    },
    {
      "level": "H1",
      "text": "8.7",
      "page": 84
    },
    {
      "level": "H1",
      "text": "30.5",
      "page": 84
    },
    {
      "level": "H1",
      "text": "4.3.2",
      "page": 84
    },
    {
      "level": "H1",
      "text": "化妆人脸识别",
      "page": 84
    },
    {
      "level": "H1",
      "text": "本小节在三个化妆表情识别基准数据库上评估",
      "page": 84
    },
    {
      "level": "H1",
      "text": "FLF",
      "page": 84
    },
    {
      "level": "H1",
      "text": "学习到的具有判别力的",
      "page": 84
    },
    {
      "level": "H1",
      "text": "特征表示对化妆鲁棒。使用",
      "page": 84
    },
    {
      "level": "H1",
      "text": "CelebA",
      "page": 84
    },
    {
      "level": "H1",
      "text": "[177]",
      "page": 84
    },
    {
      "level": "H1",
      "text": "数据集训练",
      "page": 84
    },
    {
      "level": "H1",
      "text": "框架，该数据集是一个面",
      "page": 84
    },
    {
      "level": "H1",
      "text": "部数据集，具有来自",
      "page": 84
    },
    {
      "level": "H1",
      "text": "10K",
      "page": 84
    },
    {
      "level": "H1",
      "text": "多个个体的",
      "page": 84
    },
    {
      "level": "H1",
      "text": "202,599",
      "page": 84
    },
    {
      "level": "H1",
      "text": "个面部图像，具有",
      "page": 84
    },
    {
      "level": "H1",
      "text": "个不同的属",
      "page": 84
    },
    {
      "level": "H1",
      "text": "性标签，其中每个标签都是二元值。其图像数量远超于在此使用的三个化妆人脸",
      "page": 84
    },
    {
      "level": "H1",
      "text": "数据集。基于",
      "page": 84
    },
    {
      "level": "H1",
      "text": "VGG-16",
      "page": 84
    },
    {
      "level": "H1",
      "text": "[29]",
      "page": 84
    },
    {
      "level": "H1",
      "text": "，并且在测试阶段中提取的",
      "page": 84
    },
    {
      "level": "H1",
      "text": "用于开集识别（",
      "page": 84
    },
    {
      "level": "H1",
      "text": "open-set identifications",
      "page": 84
    },
    {
      "level": "H1",
      "text": "），而不需要使用化妆数据集进行微调。",
      "page": 84
    },
    {
      "level": "H1",
      "text": "PR 2017 Dataset",
      "page": 84
    },
    {
      "level": "H1",
      "text": "[178]",
      "page": 84
    },
    {
      "level": "H1",
      "text": "收集了来自互联网的",
      "page": 84
    },
    {
      "level": "H1",
      "text": "203",
      "page": 84
    },
    {
      "level": "H1",
      "text": "名女性的",
      "page": 84
    },
    {
      "level": "H1",
      "text": "406",
      "page": 84
    },
    {
      "level": "H1",
      "text": "个化妆和非化妆",
      "page": 84
    },
    {
      "level": "H1",
      "text": "图像。",
      "page": 84
    },
    {
      "level": "H1",
      "text": "TCSVT 2014",
      "page": 84
    },
    {
      "level": "H1",
      "text": "数据集包含",
      "page": 84
    },
    {
      "level": "H1",
      "text": "1002",
      "page": 84
    },
    {
      "level": "H1",
      "text": "个面部图像",
      "page": 84
    },
    {
      "level": "H1",
      "text": "[179]",
      "page": 84
    },
    {
      "level": "H1",
      "text": "FAM",
      "page": 84
    },
    {
      "level": "H1",
      "text": "数据集涉及",
      "page": 84
    },
    {
      "level": "H1",
      "text": "222",
      "page": 84
    },
    {
      "level": "H1",
      "text": "男性和",
      "page": 84
    },
    {
      "level": "H1",
      "text": "297",
      "page": 84
    },
    {
      "level": "H1",
      "text": "名女性，其中总共",
      "page": 84
    },
    {
      "level": "H1",
      "text": "1038",
      "page": 84
    },
    {
      "level": "H1",
      "text": "个图像属于",
      "page": 84
    },
    {
      "level": "H1",
      "text": "519",
      "page": 84
    },
    {
      "level": "H1",
      "text": "个受试者",
      "page": 84
    },
    {
      "level": "H1",
      "text": "[180]",
      "page": 84
    },
    {
      "level": "H1",
      "text": "。值得注意的",
      "page": 84
    },
    {
      "level": "H1",
      "text": "是，所有这些图像都是在不受控制的情况下获得的。遵循",
      "page": 84
    },
    {
      "level": "H1",
      "text": "[181]",
      "page": 84
    },
    {
      "level": "H1",
      "text": "提供的训练测试标",
      "page": 84
    },
    {
      "level": "H1",
      "text": "准，在表",
      "page": 84
    },
    {
      "level": "H1",
      "text": "4.3",
      "page": 84
    },
    {
      "level": "H1",
      "text": "和先前最先进方法的",
      "page": 84
    },
    {
      "level": "H1",
      "text": "rank-1",
      "page": 84
    },
    {
      "level": "H1",
      "text": "平均准确度作了定量评估比",
      "page": 84
    },
    {
      "level": "H1",
      "text": "VGG",
      "page": 84
    },
    {
      "level": "H1",
      "text": "基线和",
      "page": 84
    },
    {
      "level": "H1",
      "text": "的良好表现受益于",
      "page": 84
    },
    {
      "level": "H1",
      "text": "的大规模训练数据集。值得注",
      "page": 84
    },
    {
      "level": "H1",
      "text": "意的是，文献",
      "page": 84
    },
    {
      "level": "H1",
      "text": "甚至使用了比",
      "page": 84
    },
    {
      "level": "H1",
      "text": "更大的",
      "page": 84
    },
    {
      "level": "H1",
      "text": "MS-Celeb-1M",
      "page": 84
    },
    {
      "level": "H1",
      "text": "[182]",
      "page": 84
    },
    {
      "level": "H1",
      "text": "数据库用于化妆",
      "page": 84
    },
    {
      "level": "H1",
      "text": "人脸识别。",
      "page": 84
    },
    {
      "level": "H1",
      "text": "通过关于化妆识别数据集的先验知识，",
      "page": 84
    },
    {
      "level": "H1",
      "text": "系统性地强制了网络应当对对化",
      "page": 84
    },
    {
      "level": "H1",
      "text": "妆相关属性不变，其包含",
      "page": 84
    },
    {
      "level": "H1",
      "text": "相关变量（例如，头发颜色）和身份无关变量（例",
      "page": 84
    },
    {
      "level": "H1",
      "text": "如，微笑",
      "page": 84
    },
    {
      "level": "H1",
      "text": "不笑）。根据对式",
      "page": 84
    },
    {
      "level": "H1",
      "text": "4.8",
      "page": 84
    },
    {
      "level": "H1",
      "text": "的分析，消除这些与",
      "page": 84
    },
    {
      "level": "H1",
      "text": "相关的属性通常会降低原",
      "page": 84
    },
    {
      "level": "H1",
      "text": "数据集中的识别准确度，但在化妆人脸识别数据集上实现更好的泛化",
      "page": 84
    },
    {
      "level": "H1",
      "text": "基于对抗训练的人脸身份与表情特征剥离及识别",
      "page": 85
    },
    {
      "level": "H1",
      "text": "能力。",
      "page": 85
    },
    {
      "level": "H1",
      "text": "由于化妆人脸识别数据集中的个体很可能会更改这些属性，因此",
      "page": 85
    },
    {
      "level": "H1",
      "text": "FLF",
      "page": 85
    },
    {
      "level": "H1",
      "text": "以提取更专注、更具判别力的特征，以获得更好的泛化性能。",
      "page": 85
    },
    {
      "level": "H1",
      "text": "通过以可控方式利用",
      "page": 85
    },
    {
      "level": "H1",
      "text": "CelebA",
      "page": 85
    },
    {
      "level": "H1",
      "text": "中有价值的标签即同时包括主要任务的身份标",
      "page": 85
    },
    {
      "level": "H1",
      "text": "签和化妆属性标签，",
      "page": 85
    },
    {
      "level": "H1",
      "text": "相较于",
      "page": 85
    },
    {
      "level": "H1",
      "text": "VGG",
      "page": 85
    },
    {
      "level": "H1",
      "text": "基线实现了超过",
      "page": 85
    },
    {
      "level": "H1",
      "text": "％的提升，并且在所有",
      "page": 85
    },
    {
      "level": "H1",
      "text": "数据集中关于",
      "page": 85
    },
    {
      "level": "H1",
      "text": "TPR@FPR=0.1%",
      "page": 85
    },
    {
      "level": "H1",
      "text": "优于先前最优方法超过",
      "page": 85
    },
    {
      "level": "H1",
      "text": "5.5",
      "page": 85
    },
    {
      "level": "H1",
      "text": "LFWA",
      "page": 85
    },
    {
      "level": "H1",
      "text": "[177]",
      "page": 85
    },
    {
      "level": "H1",
      "text": "数据集提供的",
      "page": 85
    },
    {
      "level": "H1",
      "text": "个面部属性的总结。希望网络学习对于化妆",
      "page": 85
    },
    {
      "level": "H1",
      "text": "人脸识别任务的粗体和斜体属性是不变的。",
      "page": 85
    },
    {
      "level": "H1",
      "text": "在消除这些属性时",
      "page": 85
    },
    {
      "level": "H1",
      "text": "数据集中识别准确",
      "page": 85
    },
    {
      "level": "H1",
      "text": "度的降低。",
      "page": 85
    },
    {
      "level": "H1",
      "text": "Table 4.2 Summary of the 40 face attributes provided with the CelebA and LFWA dataset.",
      "page": 85
    },
    {
      "level": "H1",
      "text": "We expect the network learns to be invariant to the bolded and italicized attributes for our",
      "page": 85
    },
    {
      "level": "H1",
      "text": "makeup face recognition task. *We noticed the degrades of recognition accuracy in CelebA",
      "page": 85
    },
    {
      "level": "H1",
      "text": "dataset when dispelling these attributes.",
      "page": 85
    },
    {
      "level": "H1",
      "text": "Att.",
      "page": 85
    },
    {
      "level": "H1",
      "text": "Attr.Def",
      "page": 85
    },
    {
      "level": "H1",
      "text": "Att.Def",
      "page": 85
    },
    {
      "level": "H1",
      "text": "5’O Shadow",
      "page": 85
    },
    {
      "level": "H1",
      "text": "Gray Hair",
      "page": 85
    },
    {
      "level": "H1",
      "text": "Male",
      "page": 85
    },
    {
      "level": "H1",
      "text": "Sideburns",
      "page": 85
    },
    {
      "level": "H1",
      "text": "Arched Eyebr",
      "page": 85
    },
    {
      "level": "H1",
      "text": "Big Lips",
      "page": 85
    },
    {
      "level": "H1",
      "text": "MouthOpen",
      "page": 85
    },
    {
      "level": "H1",
      "text": "Smiling",
      "page": 85
    },
    {
      "level": "H1",
      "text": "Bushy Eyebr",
      "page": 85
    },
    {
      "level": "H1",
      "text": "Big Nose",
      "page": 85
    },
    {
      "level": "H1",
      "text": "Mustache",
      "page": 85
    },
    {
      "level": "H1",
      "text": "StraightHair",
      "page": 85
    },
    {
      "level": "H1",
      "text": "Attractive",
      "page": 85
    },
    {
      "level": "H1",
      "text": "Blurry",
      "page": 85
    },
    {
      "level": "H1",
      "text": "NarrowEyes",
      "page": 85
    },
    {
      "level": "H1",
      "text": "WavyHair",
      "page": 85
    },
    {
      "level": "H1",
      "text": "Eyes Bags",
      "page": 85
    },
    {
      "level": "H1",
      "text": "Chubby",
      "page": 85
    },
    {
      "level": "H1",
      "text": "No Beard",
      "page": 85
    },
    {
      "level": "H1",
      "text": "Earrings",
      "page": 85
    },
    {
      "level": "H1",
      "text": "Bald",
      "page": 85
    },
    {
      "level": "H1",
      "text": "DoubleChin",
      "page": 85
    },
    {
      "level": "H1",
      "text": "Oval Face",
      "page": 85
    },
    {
      "level": "H1",
      "text": "Hat",
      "page": 85
    },
    {
      "level": "H1",
      "text": "Bangs",
      "page": 85
    },
    {
      "level": "H1",
      "text": "Eyeglasses",
      "page": 85
    },
    {
      "level": "H1",
      "text": "Pale Skin",
      "page": 85
    },
    {
      "level": "H1",
      "text": "Lipstick",
      "page": 85
    },
    {
      "level": "H1",
      "text": "Black Hair",
      "page": 85
    },
    {
      "level": "H1",
      "text": "Goatee",
      "page": 85
    },
    {
      "level": "H1",
      "text": "Pointy Nose",
      "page": 85
    },
    {
      "level": "H1",
      "text": "Necklace",
      "page": 85
    },
    {
      "level": "H1",
      "text": "Blond Hair",
      "page": 85
    },
    {
      "level": "H1",
      "text": "Makeup",
      "page": 85
    },
    {
      "level": "H1",
      "text": "Hairline",
      "page": 85
    },
    {
      "level": "H1",
      "text": "Necktie",
      "page": 85
    },
    {
      "level": "H1",
      "text": "BrownHair",
      "page": 85
    },
    {
      "level": "H1",
      "text": "Cheekbones",
      "page": 85
    },
    {
      "level": "H1",
      "text": "RosyCheeks",
      "page": 85
    },
    {
      "level": "H1",
      "text": "Young",
      "page": 85
    },
    {
      "level": "H1",
      "text": "4.3",
      "page": 85
    },
    {
      "level": "H1",
      "text": "PR 2017",
      "page": 85
    },
    {
      "level": "H1",
      "text": "TCSVT 2014",
      "page": 85
    },
    {
      "level": "H1",
      "text": "FAM",
      "page": 85
    },
    {
      "level": "H1",
      "text": "（从左到右）三个化妆数据集上比较",
      "page": 85
    },
    {
      "level": "H1",
      "text": "rank-1",
      "page": 85
    },
    {
      "level": "H1",
      "text": "Table 4.3 Comparisons of the rank-1 accuracy and TPR@FPR=0.1% on 3 makeup datasets.",
      "page": 85
    },
    {
      "level": "H3",
      "text": "4.2  CelebA",
      "page": 85
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 86
    },
    {
      "level": "H1",
      "text": "4.3.3",
      "page": 86
    },
    {
      "level": "H1",
      "text": "人脸身份与属性识别",
      "page": 86
    },
    {
      "level": "H1",
      "text": "此外也在",
      "page": 86
    },
    {
      "level": "H1",
      "text": "CelebA",
      "page": 86
    },
    {
      "level": "H1",
      "text": "数据库中使用独立于个体的",
      "page": 86
    },
    {
      "level": "H1",
      "text": "折交叉验证进行开集人脸身",
      "page": 86
    },
    {
      "level": "H1",
      "text": "份识别实验。在表格",
      "page": 86
    },
    {
      "level": "H1",
      "text": "4.2",
      "page": 86
    },
    {
      "level": "H1",
      "text": "中，展示了哪些",
      "page": 86
    },
    {
      "level": "H1",
      "text": "个属性可以增加",
      "page": 86
    },
    {
      "level": "H1",
      "text": "的泛化能力，",
      "page": 86
    },
    {
      "level": "H1",
      "text": "个属性会降低",
      "page": 86
    },
    {
      "level": "H1",
      "text": "库上的测试准确度，但能提高化妆人脸识别系统的性",
      "page": 86
    },
    {
      "level": "H1",
      "text": "能。在消除了",
      "page": 86
    },
    {
      "level": "H1",
      "text": "种属性后，",
      "page": 86
    },
    {
      "level": "H1",
      "text": "FLF",
      "page": 86
    },
    {
      "level": "H1",
      "text": "数据库上的准确性明显优于其",
      "page": 86
    },
    {
      "level": "H1",
      "text": "VGG",
      "page": 86
    },
    {
      "level": "H1",
      "text": "基线。",
      "page": 86
    },
    {
      "level": "H1",
      "text": "原始的",
      "page": 86
    },
    {
      "level": "H1",
      "text": "网络无法使用属性标签，",
      "page": 86
    },
    {
      "level": "H1",
      "text": "19-head",
      "page": 86
    },
    {
      "level": "H1",
      "text": "是其使用典型的多任务学",
      "page": 86
    },
    {
      "level": "H1",
      "text": "习构建的框架，在最后的全连接层有",
      "page": 86
    },
    {
      "level": "H1",
      "text": "个分支，其中一个用于身份另外",
      "page": 86
    },
    {
      "level": "H1",
      "text": "于各属性识别。但这样包含属性标签不仅无法使得身份分支不包含",
      "page": 86
    },
    {
      "level": "H1",
      "text": "中属性，",
      "page": 86
    },
    {
      "level": "H1",
      "text": "反而会被与任务无关的",
      "page": 86
    },
    {
      "level": "H1",
      "text": "分心，而在卷积层的主干中包含更多的无关属性信息。",
      "page": 86
    },
    {
      "level": "H1",
      "text": "需要注意的是",
      "page": 86
    },
    {
      "level": "H1",
      "text": "本质上是一个属性识别数据集，很少有先前工作使用它作",
      "page": 86
    },
    {
      "level": "H1",
      "text": "为身份识别的测试数据集。",
      "page": 86
    },
    {
      "level": "H1",
      "text": "数据集的人脸身份识别准确性。",
      "page": 86
    },
    {
      "level": "H1",
      "text": "Table 4.4 Face recognition accuracy on CelebA dataset.",
      "page": 86
    },
    {
      "level": "H1",
      "text": "Methods",
      "page": 86
    },
    {
      "level": "H1",
      "text": "Rank-1 accuracy",
      "page": 86
    },
    {
      "level": "H1",
      "text": "85.4%",
      "page": 86
    },
    {
      "level": "H1",
      "text": "19-head (1ID+18attr)",
      "page": 86
    },
    {
      "level": "H1",
      "text": "81.1%",
      "page": 86
    },
    {
      "level": "H1",
      "text": "92.7%",
      "page": 86
    },
    {
      "level": "H1",
      "text": "22.7%)",
      "page": 86
    },
    {
      "level": "H1",
      "text": "LFWA",
      "page": 86
    },
    {
      "level": "H1",
      "text": "数据集的面部属性识别精度。两个数据集分别进行训练和测试。",
      "page": 86
    },
    {
      "level": "H1",
      "text": "Table 4.4 Face attribute recognition accuracy on CelebA and LFWA dataset. Two datasets",
      "page": 86
    },
    {
      "level": "H1",
      "text": "are trained and tested separately.",
      "page": 86
    },
    {
      "level": "H1",
      "text": "backbone",
      "page": 86
    },
    {
      "level": "H1",
      "text": "[177]",
      "page": 86
    },
    {
      "level": "H1",
      "text": "AlexNet",
      "page": 86
    },
    {
      "level": "H1",
      "text": "[28]",
      "page": 86
    },
    {
      "level": "H1",
      "text": "87.30%",
      "page": 86
    },
    {
      "level": "H1",
      "text": "83.85%",
      "page": 86
    },
    {
      "level": "H1",
      "text": "[184]",
      "page": 86
    },
    {
      "level": "H1",
      "text": "VGG-16",
      "page": 86
    },
    {
      "level": "H1",
      "text": "[29]",
      "page": 86
    },
    {
      "level": "H1",
      "text": "91.20%",
      "page": 86
    },
    {
      "level": "H1",
      "text": "[185]",
      "page": 86
    },
    {
      "level": "H1",
      "text": "InceptionResNet",
      "page": 86
    },
    {
      "level": "H1",
      "text": "[187]",
      "page": 86
    },
    {
      "level": "H1",
      "text": "87.82%",
      "page": 86
    },
    {
      "level": "H1",
      "text": "83.16%",
      "page": 86
    },
    {
      "level": "H1",
      "text": "[186]",
      "page": 86
    },
    {
      "level": "H1",
      "text": "ResNet50",
      "page": 86
    },
    {
      "level": "H1",
      "text": "[31]",
      "page": 86
    },
    {
      "level": "H1",
      "text": "91.81%",
      "page": 86
    },
    {
      "level": "H1",
      "text": "85.28%",
      "page": 86
    },
    {
      "level": "H1",
      "text": "93.26%",
      "page": 86
    },
    {
      "level": "H1",
      "text": "4.3.4",
      "page": 86
    },
    {
      "level": "H1",
      "text": "伪装人脸识别",
      "page": 86
    },
    {
      "level": "H1",
      "text": "野外伪装人脸（",
      "page": 86
    },
    {
      "level": "H1",
      "text": "disgust face in the wild, DFW",
      "page": 86
    },
    {
      "level": "H1",
      "text": "[188]",
      "page": 86
    },
    {
      "level": "H1",
      "text": "数据集是最近发布的，其",
      "page": 86
    },
    {
      "level": "H1",
      "text": "中包含来自",
      "page": 86
    },
    {
      "level": "H1",
      "text": "1000",
      "page": 86
    },
    {
      "level": "H1",
      "text": "个受试者的",
      "page": 86
    },
    {
      "level": "H1",
      "text": "11157",
      "page": 86
    },
    {
      "level": "H1",
      "text": "张图像。主流方法通常选择",
      "page": 86
    },
    {
      "level": "H1",
      "text": "作为预训",
      "page": 86
    },
    {
      "level": "H3",
      "text": "4.4 CelebA",
      "page": 86
    },
    {
      "level": "H1",
      "text": "基于对抗训练的人脸身份与表情特征剥离及识别",
      "page": 87
    },
    {
      "level": "H1",
      "text": "练数据集，尽管它与",
      "page": 87
    },
    {
      "level": "H1",
      "text": "CelebA",
      "page": 87
    },
    {
      "level": "H1",
      "text": "的图像风格差距略大于",
      "page": 87
    },
    {
      "level": "H1",
      "text": "与化妆数据集。在表",
      "page": 87
    },
    {
      "level": "H1",
      "text": "4.5",
      "page": 87
    },
    {
      "level": "H1",
      "text": "中，相较于",
      "page": 87
    },
    {
      "level": "H1",
      "text": "VGG",
      "page": 87
    },
    {
      "level": "H1",
      "text": "基线，关于",
      "page": 87
    },
    {
      "level": "H1",
      "text": "GAR @ 1",
      "page": 87
    },
    {
      "level": "H1",
      "text": "FAR",
      "page": 87
    },
    {
      "level": "H1",
      "text": "GAR@0.1%FAR",
      "page": 87
    },
    {
      "level": "H1",
      "text": "FLF",
      "page": 87
    },
    {
      "level": "H1",
      "text": "20.9",
      "page": 87
    },
    {
      "level": "H1",
      "text": "％。它还可以用作预训练方案（",
      "page": 87
    },
    {
      "level": "H1",
      "text": "FLF + MIRA",
      "page": 87
    },
    {
      "level": "H1",
      "text": "），以与最先进的方",
      "page": 87
    },
    {
      "level": "H1",
      "text": "法互补，以获得更好的性能。",
      "page": 87
    },
    {
      "level": "H1",
      "text": "数据集的人脸身份识别准确度。",
      "page": 87
    },
    {
      "level": "H1",
      "text": "Table 4.5 Face recognition on DFW dataset.",
      "page": 87
    },
    {
      "level": "H1",
      "text": "Methods",
      "page": 87
    },
    {
      "level": "H1",
      "text": "@1%FAR",
      "page": 87
    },
    {
      "level": "H1",
      "text": "@0.1%FAR",
      "page": 87
    },
    {
      "level": "H1",
      "text": "[188]",
      "page": 87
    },
    {
      "level": "H1",
      "text": "33.76%",
      "page": 87
    },
    {
      "level": "H1",
      "text": "17.73%",
      "page": 87
    },
    {
      "level": "H1",
      "text": "51.78% (",
      "page": 87
    },
    {
      "level": "H1",
      "text": "18.02%) 38.64% (",
      "page": 87
    },
    {
      "level": "H1",
      "text": "20.91%)",
      "page": 87
    },
    {
      "level": "H1",
      "text": "MIRA",
      "page": 87
    },
    {
      "level": "H1",
      "text": "89.04%",
      "page": 87
    },
    {
      "level": "H1",
      "text": "75.08%",
      "page": 87
    },
    {
      "level": "H1",
      "text": "4.4",
      "page": 87
    },
    {
      "level": "H1",
      "text": "本章小结",
      "page": 87
    },
    {
      "level": "H1",
      "text": "本章提出了一种解决方案来以可控方式提取具有所需语义不变性的具有判",
      "page": 87
    },
    {
      "level": "H1",
      "text": "别力的表示，而不需要成对的语义变量变换示例和潜在变量标签。它的识别可使",
      "page": 87
    },
    {
      "level": "H1",
      "text": "用对抗训练中的编码器与分类器而不需要生成图像作为训练数据。实验结果表明",
      "page": 87
    },
    {
      "level": "H1",
      "text": "该框架能有效地学习到将输入分解为三个相互独立的部分，并且这三个部分是相",
      "page": 87
    },
    {
      "level": "H1",
      "text": "互补充的。将来计划在隐私数据等方面展开更深入的工作。",
      "page": 87
    },
    {
      "level": "H3",
      "text": "4.5 DFW",
      "page": 87
    },
    {
      "level": "H1",
      "text": "基于人脸图片集的身份识别",
      "page": 88
    },
    {
      "level": "H1",
      "text": "最近几年无约束人脸识别在计算机视觉研究界受到了广泛关注",
      "page": 88
    },
    {
      "level": "H1",
      "text": "[27]",
      "page": 88
    },
    {
      "level": "H1",
      "text": "。最初，基",
      "page": 88
    },
    {
      "level": "H1",
      "text": "于单个图像的人脸识别是人脸识别的主流，例如，野外标记人脸（",
      "page": 88
    },
    {
      "level": "H1",
      "text": "Labeled Faces",
      "page": 88
    },
    {
      "level": "H1",
      "text": "in the Wild, LFW",
      "page": 88
    },
    {
      "level": "H1",
      "text": "）数据库的人脸验证任务",
      "page": 88
    },
    {
      "level": "H1",
      "text": "[25]",
      "page": 88
    },
    {
      "level": "H1",
      "text": "。相机和数字存储技术的日益普及推",
      "page": 88
    },
    {
      "level": "H1",
      "text": "动了人脸识别研究进入下一阶段，即利用视频进行面部验证，例如（",
      "page": 88
    },
    {
      "level": "H1",
      "text": "YouTube Faces,",
      "page": 88
    },
    {
      "level": "H1",
      "text": "YTF",
      "page": 88
    },
    {
      "level": "H1",
      "text": "）数据集",
      "page": 88
    },
    {
      "level": "H1",
      "text": "[35]",
      "page": 88
    },
    {
      "level": "H1",
      "text": "LFW",
      "page": 88
    },
    {
      "level": "H1",
      "text": "数据集具有众所周知的正面姿态选择偏差，即其",
      "page": 88
    },
    {
      "level": "H1",
      "text": "主要样本均为正脸图像或视频帧",
      "page": 88
    },
    {
      "level": "H1",
      "text": "[189]",
      "page": 88
    },
    {
      "level": "H1",
      "text": "此外，与",
      "page": 88
    },
    {
      "level": "H1",
      "text": "数据集所常用的人脸验证问题相比，开集人脸识别",
      "page": 88
    },
    {
      "level": "H1",
      "text": "open-set face identification",
      "page": 88
    },
    {
      "level": "H1",
      "text": "）实际上更具挑战性",
      "page": 88
    },
    {
      "level": "H1",
      "text": "[190]",
      "page": 88
    },
    {
      "level": "H1",
      "text": "。如图",
      "page": 88
    },
    {
      "level": "H1",
      "text": "5.1",
      "page": 88
    },
    {
      "level": "H1",
      "text": "所示，对于每个查",
      "page": 88
    },
    {
      "level": "H1",
      "text": "询样本（",
      "page": 88
    },
    {
      "level": "H1",
      "text": "probe sample",
      "page": 88
    },
    {
      "level": "H1",
      "text": "），其需要与每个候选样本（",
      "page": 88
    },
    {
      "level": "H1",
      "text": "gallery sample",
      "page": 88
    },
    {
      "level": "H1",
      "text": "）进行相似度比",
      "page": 88
    },
    {
      "level": "H1",
      "text": "较。即对于拥有",
      "page": 88
    },
    {
      "level": "H1",
      "text": "个候选人的任务，需要进行",
      "page": 88
    },
    {
      "level": "H1",
      "text": "次人脸验证。这就要求每次验",
      "page": 88
    },
    {
      "level": "H1",
      "text": "证的计算量要控制在较小的程度。",
      "page": 88
    },
    {
      "level": "H1",
      "text": "用于基于图像集的",
      "page": 88
    },
    {
      "level": "H1",
      "text": "面部验证（左侧）和开放式",
      "page": 88
    },
    {
      "level": "H1",
      "text": "鉴别（右侧）的典型聚",
      "page": 88
    },
    {
      "level": "H1",
      "text": "合方法的图示。每组独立地表示为单个特征向量。",
      "page": 88
    },
    {
      "level": "H1",
      "text": "Figure 5.1  Illustration of the typical aggregation method for image set-based 1:1 face",
      "page": 88
    },
    {
      "level": "H1",
      "text": "verification (above) and open-set 1:",
      "page": 88
    },
    {
      "level": "H1",
      "text": "identification (bottom). Each set is independently",
      "page": 88
    },
    {
      "level": "H1",
      "text": "represented as a single feature vector.",
      "page": 88
    },
    {
      "level": "H1",
      "text": "IARPA Janus",
      "page": 88
    },
    {
      "level": "H1",
      "text": "基准测试（",
      "page": 88
    },
    {
      "level": "H1",
      "text": "IJB-A",
      "page": 88
    },
    {
      "level": "H1",
      "text": "[36]",
      "page": 88
    },
    {
      "level": "H1",
      "text": "IJB-B",
      "page": 88
    },
    {
      "level": "H1",
      "text": "[37]",
      "page": 88
    },
    {
      "level": "H1",
      "text": "IJB-C",
      "page": 88
    },
    {
      "level": "H1",
      "text": "[38]",
      "page": 88
    },
    {
      "level": "H1",
      "text": "）提供了一种更加真实",
      "page": 88
    },
    {
      "level": "H1",
      "text": "的无约束面部验证和识别的基准测试库。他们使用一组包含具有大幅度头部旋转，",
      "page": 88
    },
    {
      "level": "H1",
      "text": "复杂表情和照明的无序面部图像和",
      "page": 88
    },
    {
      "level": "H1",
      "text": "或视频）作为表示一个人的最小单位。其中的",
      "page": 88
    },
    {
      "level": "H1",
      "text": "图像或视频样本可以来自于该个体的各类证件照片，历史自拍头像，在不同检查",
      "page": 88
    },
    {
      "level": "H1",
      "text": "点拍摄的图像以及视频中的面部。这种定义更类似于真实世界的生物特征识别场",
      "page": 88
    },
    {
      "level": "H1",
      "text": "基于人脸图片集的身份识别",
      "page": 89
    },
    {
      "level": "H1",
      "text": "[36]",
      "page": 89
    },
    {
      "level": "H1",
      "text": "。从多个视图，背景环境和相机参数捕获人脸无疑会较视频帧引入更大的变",
      "page": 89
    },
    {
      "level": "H1",
      "text": "化，但也提供了更多补充信息，有望在实际应用中实现更好的性能",
      "page": 89
    },
    {
      "level": "H1",
      "text": "[30]",
      "page": 89
    },
    {
      "level": "H1",
      "text": "考虑到上述因素，本章建议充分利用图像集内部和集间关系来进行人脸验证",
      "page": 89
    },
    {
      "level": "H1",
      "text": "和识别。",
      "page": 89
    },
    {
      "level": "H1",
      "text": "(a)",
      "page": 89
    },
    {
      "level": "H1",
      "text": "(b)",
      "page": 89
    },
    {
      "level": "H1",
      "text": "5.2",
      "page": 89
    },
    {
      "level": "H1",
      "text": "YTF",
      "page": 89
    },
    {
      "level": "H1",
      "text": "IJB-A",
      "page": 89
    },
    {
      "level": "H1",
      "text": "数据集的测试集中的典型示例，其比较了先前方法",
      "page": 89
    },
    {
      "level": "H1",
      "text": "NAN",
      "page": 89
    },
    {
      "level": "H1",
      "text": "[193]",
      "page": 89
    },
    {
      "level": "H1",
      "text": "计算的图像的权重（即重要性），以及",
      "page": 89
    },
    {
      "level": "H1",
      "text": "DAC",
      "page": 89
    },
    {
      "level": "H1",
      "text": "的权重建议。",
      "page": 89
    },
    {
      "level": "H1",
      "text": "通常在红色框中为",
      "page": 89
    },
    {
      "level": "H1",
      "text": "图像对提供相似的分数，而低质量的分数不会引入更多的补充信息。",
      "page": 89
    },
    {
      "level": "H1",
      "text": "的建议考虑其冗",
      "page": 89
    },
    {
      "level": "H1",
      "text": "余度，并为低质量版本提供较低的权重。",
      "page": 89
    },
    {
      "level": "H1",
      "text": "Figure 5.2  Typical examples in the test set of (a) YTF and (b) IJB-A dataset showing the",
      "page": 89
    },
    {
      "level": "H1",
      "text": "weights (i.e., importance) of images calculated by the previous method NAN",
      "page": 89
    },
    {
      "level": "H1",
      "text": ", and",
      "page": 89
    },
    {
      "level": "H1",
      "text": "proposed DAC. NAN usually gives similar scores for the image pairs in red box, while the",
      "page": 89
    },
    {
      "level": "H1",
      "text": "low-quality one does not introduce more complimentary information. The proposed DAC",
      "page": 89
    },
    {
      "level": "H1",
      "text": "considers their redundancy and give a lower weight for the low quality version.",
      "page": 89
    },
    {
      "level": "H1",
      "text": "从多个图像中提取并聚合身份信息通常采用的策略是平均",
      "page": 89
    },
    {
      "level": "H1",
      "text": "最大池化",
      "page": 89
    },
    {
      "level": "H1",
      "text": "average/max pooling",
      "page": 89
    },
    {
      "level": "H1",
      "text": "[132],[192]",
      "page": 89
    },
    {
      "level": "H1",
      "text": "。即将各图像所提取的特征向量的每个维度进行",
      "page": 89
    },
    {
      "level": "H1",
      "text": "平均或取最大值从而融合为一个单一的向量。由于每幅图像的重要性不同，有必",
      "page": 89
    },
    {
      "level": "H1",
      "text": "要对每个图像的特征向量进行加权，再进行加权平均。为此文献",
      "page": 89
    },
    {
      "level": "H1",
      "text": "开发了一种",
      "page": 89
    },
    {
      "level": "H1",
      "text": "基于神经网络的图像质量评估模块（",
      "page": 89
    },
    {
      "level": "H1",
      "text": "），其输入为某个图像的特征向量，输",
      "page": 89
    },
    {
      "level": "H1",
      "text": "出为其对应的权重值。较大的权重对应于更重要",
      "page": 89
    },
    {
      "level": "H1",
      "text": "有用的图像。这个决策过程对每",
      "page": 89
    },
    {
      "level": "H1",
      "text": "一帧而言是独立的。使用这种策略，正面和清晰的人脸图像将受到",
      "page": 89
    },
    {
      "level": "H1",
      "text": "的青睐，",
      "page": 89
    },
    {
      "level": "H1",
      "text": "拥有较大的权重。然而这可能导致冗余，并且模型可能无法利用集合中的多样性。",
      "page": 89
    },
    {
      "level": "H1",
      "text": "所示，某些低质量的模糊正面图像在一个图像集中可能被赋予相对大的",
      "page": 89
    },
    {
      "level": "H1",
      "text": "权重，有时与同姿态的最清晰图像的权重一样大。然而在拥有最清晰版本时，其",
      "page": 89
    },
    {
      "level": "H1",
      "text": "相同姿态的较模糊版本往往能提供的额外信息极少，反而引入了大量噪声。与此",
      "page": 89
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 90
    },
    {
      "level": "H1",
      "text": "同时，有价值的侧面视图等则被几乎被系统忽略。由此可见，分配权重时应当基",
      "page": 90
    },
    {
      "level": "H1",
      "text": "于图片集中的其他图片进行决策以充分考虑其冗余性与互补性。",
      "page": 90
    },
    {
      "level": "H1",
      "text": "基于这种考虑，将注意力分配机制定义为马尔可夫决策过程（",
      "page": 90
    },
    {
      "level": "H1",
      "text": "Markov",
      "page": 90
    },
    {
      "level": "H1",
      "text": "Decision Process, MDP",
      "page": 90
    },
    {
      "level": "H1",
      "text": "），并使用演员",
      "page": 90
    },
    {
      "level": "H1",
      "text": "评论员（",
      "page": 90
    },
    {
      "level": "H1",
      "text": "Actor-critic",
      "page": 90
    },
    {
      "level": "H1",
      "text": "）强化学习",
      "page": 90
    },
    {
      "level": "H1",
      "text": "Reinforcement learning, RL",
      "page": 90
    },
    {
      "level": "H1",
      "text": "）来进行模型训练。提出的依赖性感知的注意力控制",
      "page": 90
    },
    {
      "level": "H1",
      "text": "dependency-aware attention control, DAC",
      "page": 90
    },
    {
      "level": "H1",
      "text": "）模块学习一种策略以观察该组中的其",
      "page": 90
    },
    {
      "level": "H1",
      "text": "他图像的同时逐步确定每个图像的重要性（即权重）。该方法不仅明确地学习强",
      "page": 90
    },
    {
      "level": "H1",
      "text": "调高质量图像并削弱低质量图像，而且还考虑图像集内部的依赖性以减少冗余并",
      "page": 90
    },
    {
      "level": "H1",
      "text": "保留信息多样性带来的好处。",
      "page": 90
    },
    {
      "level": "H1",
      "text": "此外，由于姿态，照明条件，分辨率等因素的变化，提取在整个集合中的共",
      "page": 90
    },
    {
      "level": "H1",
      "text": "有特征，即集合级的不变特征具有挑战性。一些方法提出聚合两个比较集合中所",
      "page": 90
    },
    {
      "level": "H1",
      "text": "有图像对的图像级成对相似性",
      "page": 90
    },
    {
      "level": "H1",
      "text": "[194],[195]",
      "page": 90
    },
    {
      "level": "H1",
      "text": "。如果",
      "page": 90
    },
    {
      "level": "H1",
      "text": "是集合中的平均图像数量，则该方",
      "page": 90
    },
    {
      "level": "H1",
      "text": "法每个匹配操作表现出",
      "page": 90
    },
    {
      "level": "H1",
      "text": "𝒪(𝑛",
      "page": 90
    },
    {
      "level": "H1",
      "text": "的计算复杂度，并且每集合表现出",
      "page": 90
    },
    {
      "level": "H1",
      "text": "𝒪(𝑛)",
      "page": 90
    },
    {
      "level": "H1",
      "text": "空间复杂度，",
      "page": 90
    },
    {
      "level": "H1",
      "text": "这对于开集人脸识别而言运算量较大。通常查询样本和候选样本的特征提取是独",
      "page": 90
    },
    {
      "level": "H1",
      "text": "立的过程",
      "page": 90
    },
    {
      "level": "H1",
      "text": "[190]",
      "page": 90
    },
    {
      "level": "H1",
      "text": "由于姿态变化是",
      "page": 90
    },
    {
      "level": "H1",
      "text": "IJB-A / B / C",
      "page": 90
    },
    {
      "level": "H1",
      "text": "数据集和实际应用中的主要以及最具挑战性的",
      "page": 90
    },
    {
      "level": "H1",
      "text": "变化因素。并且先验知识已知正面和侧面人脸的结构明显不同。因此，严格的要",
      "page": 90
    },
    {
      "level": "H1",
      "text": "求正面图片的特征向量与侧面图像的特征向量相似并不合理。本章提出了一种无",
      "page": 90
    },
    {
      "level": "H1",
      "text": "参数姿态引导表示（",
      "page": 90
    },
    {
      "level": "H1",
      "text": "pose-guided representation, PGR",
      "page": 90
    },
    {
      "level": "H1",
      "text": "）方案来模拟集合间的依赖",
      "page": 90
    },
    {
      "level": "H1",
      "text": "性。它较好地平衡了计算成本和补充信息的利用。此外进一步提出了一种基于度",
      "page": 90
    },
    {
      "level": "H1",
      "text": "量学习的",
      "page": 90
    },
    {
      "level": "H1",
      "text": "PGR",
      "page": 90
    },
    {
      "level": "H1",
      "text": "通过训练特征提取器根据其身份和姿势在特征空间中映射样本来",
      "page": 90
    },
    {
      "level": "H1",
      "text": "进一步去除测试阶段中的姿态检测环节。",
      "page": 90
    },
    {
      "level": "H1",
      "text": "总的来说，本章做出了以下贡献。",
      "page": 90
    },
    {
      "level": "H1",
      "text": "）在基于视觉的识别任务中使用深度演员",
      "page": 90
    },
    {
      "level": "H1",
      "text": "评论家强化学习（",
      "page": 90
    },
    {
      "level": "H1",
      "text": "deep actor-",
      "page": 90
    },
    {
      "level": "H1",
      "text": "critic reinforcement learning",
      "page": 90
    },
    {
      "level": "H1",
      "text": "）依赖性感知的注意力控制（",
      "page": 90
    },
    {
      "level": "H1",
      "text": "能是在无序样本集中探索丰富相关线索的通用解决方案。其参数可以在仅给定图",
      "page": 90
    },
    {
      "level": "H1",
      "text": "片集级标注的常用基于集的识别训练库中训练，而不需要额外的监督信号（例如，",
      "page": 90
    },
    {
      "level": "H1",
      "text": "人为标记的图片质量标签）。本章还表明它与基于时序的注意力模型相兼容。",
      "page": 90
    },
    {
      "level": "H1",
      "text": "）为了进一步提高样本效率，引入了基于信任区域的经验回放机制，加",
      "page": 90
    },
    {
      "level": "H1",
      "text": "基于人脸图片集的身份识别",
      "page": 91
    },
    {
      "level": "H1",
      "text": "快训练速度，实现更强的收敛性能。",
      "page": 91
    },
    {
      "level": "H1",
      "text": "）姿势引导表示（",
      "page": 91
    },
    {
      "level": "H1",
      "text": "pose-guided representation, PGR",
      "page": 91
    },
    {
      "level": "H1",
      "text": "）方案利用人脸先验知",
      "page": 91
    },
    {
      "level": "H1",
      "text": "识较好地平衡了较大姿态变化情况下的计算成本和信息利用率。此外，可以通过",
      "page": 91
    },
    {
      "level": "H1",
      "text": "度量学习来移除测试阶段的姿态检测。",
      "page": 91
    },
    {
      "level": "H1",
      "text": "）模块化的特征级聚合还继承了传统池化策略的优点，例如，允许不同",
      "page": 91
    },
    {
      "level": "H1",
      "text": "数量的输入以及保证时间和存储器效率。",
      "page": 91
    },
    {
      "level": "H1",
      "text": "本章展示了该方法在具有挑战性的",
      "page": 91
    },
    {
      "level": "H1",
      "text": "IARPA Janus",
      "page": 91
    },
    {
      "level": "H1",
      "text": "人脸识别基准测试中获得了",
      "page": 91
    },
    {
      "level": "H1",
      "text": "最优的准确度结果，并且在几个基于视频的人脸识别任务中也得到了很好的效果，",
      "page": 91
    },
    {
      "level": "H1",
      "text": "YTF",
      "page": 91
    },
    {
      "level": "H1",
      "text": "Celebrity-1000",
      "page": 91
    },
    {
      "level": "H1",
      "text": "两个数据库。",
      "page": 91
    },
    {
      "level": "H1",
      "text": "本章的其余部分安排如下。第",
      "page": 91
    },
    {
      "level": "H1",
      "text": "5.1",
      "page": 91
    },
    {
      "level": "H1",
      "text": "节简要回顾了相关文献。第",
      "page": 91
    },
    {
      "level": "H1",
      "text": "5.2",
      "page": 91
    },
    {
      "level": "H1",
      "text": "节详细介",
      "page": 91
    },
    {
      "level": "H1",
      "text": "绍了图片集内部依赖控制的同",
      "page": 91
    },
    {
      "level": "H1",
      "text": "异策略（",
      "page": 91
    },
    {
      "level": "H1",
      "text": "on/off-policy",
      "page": 91
    },
    {
      "level": "H1",
      "text": "）演员",
      "page": 91
    },
    {
      "level": "H1",
      "text": "评论员（",
      "page": 91
    },
    {
      "level": "H1",
      "text": "Actor-critic",
      "page": 91
    },
    {
      "level": "H1",
      "text": "模型。第",
      "page": 91
    },
    {
      "level": "H1",
      "text": "5.3",
      "page": 91
    },
    {
      "level": "H1",
      "text": "节提出了用于集合间交互的无参数和度量学习姿势引导表示。第",
      "page": 91
    },
    {
      "level": "H1",
      "text": "5.4",
      "page": 91
    },
    {
      "level": "H1",
      "text": "节展示了所提出算法在各个数据集上的数值结果，并进行了充分的消融研究。最",
      "page": 91
    },
    {
      "level": "H1",
      "text": "后，第",
      "page": 91
    },
    {
      "level": "H1",
      "text": "5.5",
      "page": 91
    },
    {
      "level": "H1",
      "text": "节为本章小结。",
      "page": 91
    },
    {
      "level": "H1",
      "text": "相关工作",
      "page": 91
    },
    {
      "level": "H1",
      "text": "基于图片集合的数据集中的多图像设置类似于基于视频的识别任务中的多",
      "page": 91
    },
    {
      "level": "H1",
      "text": "个帧。然而，与视频数据集不同，集合内的图片往往没有时间结构，通常是无序",
      "page": 91
    },
    {
      "level": "H1",
      "text": "的，并且集内部",
      "page": 91
    },
    {
      "level": "H1",
      "text": "集合间的变化更具挑战性",
      "page": 91
    },
    {
      "level": "H1",
      "text": "[36]",
      "page": 91
    },
    {
      "level": "H1",
      "text": "。基于图片集合的任务有两种常用",
      "page": 91
    },
    {
      "level": "H1",
      "text": "解决方案，即基于流形的方法和基于图像的方法。在第一类中，每个集",
      "page": 91
    },
    {
      "level": "H1",
      "text": "视频通常",
      "page": 91
    },
    {
      "level": "H1",
      "text": "进行流形建模，并测量流形级的相似性或距离。基于流形的方法通常无法处理无",
      "page": 91
    },
    {
      "level": "H1",
      "text": "约束人脸识别任务中常见的较大的外观变化",
      "page": 91
    },
    {
      "level": "H1",
      "text": "[11]",
      "page": 91
    },
    {
      "level": "H1",
      "text": "。在基于图像的方法中，查询集",
      "page": 91
    },
    {
      "level": "H1",
      "text": "probe set",
      "page": 91
    },
    {
      "level": "H1",
      "text": "）和候选集（",
      "page": 91
    },
    {
      "level": "H1",
      "text": "gallery set",
      "page": 91
    },
    {
      "level": "H1",
      "text": "）进行验证时，通常将每个查询集中的图片都",
      "page": 91
    },
    {
      "level": "H1",
      "text": "与每个候选集中的图片两两配对进行相似度比较",
      "page": 91
    },
    {
      "level": "H1",
      "text": "[24],[36]",
      "page": 91
    },
    {
      "level": "H1",
      "text": "。这将需要集中图片数量",
      "page": 91
    },
    {
      "level": "H1",
      "text": "的平方次比较，使得其运算效率较低。",
      "page": 91
    },
    {
      "level": "H1",
      "text": "Yang",
      "page": 91
    },
    {
      "level": "H1",
      "text": "等人提出了一种注意模型",
      "page": 91
    },
    {
      "level": "H1",
      "text": "[193]",
      "page": 91
    },
    {
      "level": "H1",
      "text": "，将集",
      "page": 91
    },
    {
      "level": "H1",
      "text": "中的所有特征聚合到一个特征向量中。其为每个特征提供独立的质量评估，并以",
      "page": 91
    },
    {
      "level": "H1",
      "text": "此为权重进行加权平均。最后，查询集（",
      "page": 91
    },
    {
      "level": "H1",
      "text": "）各只",
      "page": 91
    },
    {
      "level": "H1",
      "text": "有一个特征向量，因此仅需要一次配对来测量两组的相似性。文献",
      "page": 91
    },
    {
      "level": "H1",
      "text": "[196]",
      "page": 91
    },
    {
      "level": "H1",
      "text": "提出将聚",
      "page": 91
    },
    {
      "level": "H1",
      "text": "合特征向上采样为图像，然后将其提供给基于图像的人脸识别网络。但是，先前",
      "page": 91
    },
    {
      "level": "H1",
      "text": "的方法对于图像的加权决策不会像本章提出的",
      "page": 91
    },
    {
      "level": "H1",
      "text": "DAC",
      "page": 91
    },
    {
      "level": "H1",
      "text": "方法考虑其他图像。",
      "page": 91
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 92
    },
    {
      "level": "H1",
      "text": "增强学习通过训练一个智能体（",
      "page": 92
    },
    {
      "level": "H1",
      "text": "agent",
      "page": 92
    },
    {
      "level": "H1",
      "text": "）与动态环境进行互动（通过反复试验），",
      "page": 92
    },
    {
      "level": "H1",
      "text": "目的是最大化其累积奖励（",
      "page": 92
    },
    {
      "level": "H1",
      "text": "accumulated reward",
      "page": 92
    },
    {
      "level": "H1",
      "text": "）。最近，具有卷积神经网络",
      "page": 92
    },
    {
      "level": "H1",
      "text": "convolutional neural networks, CNN",
      "page": 92
    },
    {
      "level": "H1",
      "text": "）的深度增强学习在",
      "page": 92
    },
    {
      "level": "H1",
      "text": "Atari",
      "page": 92
    },
    {
      "level": "H1",
      "text": "游戏中实现了人",
      "page": 92
    },
    {
      "level": "H1",
      "text": "类级别的性能",
      "page": 92
    },
    {
      "level": "H1",
      "text": "[197]",
      "page": 92
    },
    {
      "level": "H1",
      "text": "CNN",
      "page": 92
    },
    {
      "level": "H1",
      "text": "是表示无限状态空间的理想近似函数",
      "page": 92
    },
    {
      "level": "H1",
      "text": "[198]",
      "page": 92
    },
    {
      "level": "H1",
      "text": "。解决增强学",
      "page": 92
    },
    {
      "level": "H1",
      "text": "习问题有两个主流方法：基于价值函数的方法和基于策略梯度的方法。第一类，",
      "page": 92
    },
    {
      "level": "H1",
      "text": "Q-learning",
      "page": 92
    },
    {
      "level": "H1",
      "text": "，是离散动作任务的通用解决方案，它选择导致最大奖励输出的",
      "page": 92
    },
    {
      "level": "H1",
      "text": "。第二类对连续动作空间有效，它使用输出作为概率来选择每个动作，",
      "page": 92
    },
    {
      "level": "H1",
      "text": "但不知道采取该动作的价值",
      "page": 92
    },
    {
      "level": "H1",
      "text": "[199]",
      "page": 92
    },
    {
      "level": "H1",
      "text": "。还有一种混合这两种方法的的演员",
      "page": 92
    },
    {
      "level": "H1",
      "text": "评论家方法，",
      "page": 92
    },
    {
      "level": "H1",
      "text": "其中参数化的策略被称为演员，而需要学习得到的价值函数被称为评论家",
      "page": 92
    },
    {
      "level": "H1",
      "text": "[200]",
      "page": 92
    },
    {
      "level": "H1",
      "text": "由于它本质上是一种策略梯度方法，但它也可以用于连续的动作空间。",
      "page": 92
    },
    {
      "level": "H1",
      "text": "基于策略和演员",
      "page": 92
    },
    {
      "level": "H1",
      "text": "评论家的方法比基于值的方法具有更快的收敛特性，但它",
      "page": 92
    },
    {
      "level": "H1",
      "text": "们通常具有低样本效率，高方差和经常收敛到局部最优的缺点",
      "page": 92
    },
    {
      "level": "H1",
      "text": "[201]",
      "page": 92
    },
    {
      "level": "H1",
      "text": "。因为它们通",
      "page": 92
    },
    {
      "level": "H1",
      "text": "常通过同策略（",
      "page": 92
    },
    {
      "level": "H1",
      "text": "on-policy",
      "page": 92
    },
    {
      "level": "H1",
      "text": "）算法学习",
      "page": 92
    },
    {
      "level": "H1",
      "text": "[202]",
      "page": 92
    },
    {
      "level": "H1",
      "text": "，这使得策略预测仅基于当前策略。即使",
      "page": 92
    },
    {
      "level": "H1",
      "text": "Asynchronous Advantage Actor-Critic",
      "page": 92
    },
    {
      "level": "H1",
      "text": "A3C",
      "page": 92
    },
    {
      "level": "H1",
      "text": "）方法也需要为每个梯度更新步骤",
      "page": 92
    },
    {
      "level": "H1",
      "text": "收集新的样本",
      "page": 92
    },
    {
      "level": "H1",
      "text": "[203]",
      "page": 92
    },
    {
      "level": "H1",
      "text": "。而学习有效策略的梯度步骤的数量随着任务复杂性而增加。",
      "page": 92
    },
    {
      "level": "H1",
      "text": "相反，异策略（",
      "page": 92
    },
    {
      "level": "H1",
      "text": "off-policy",
      "page": 92
    },
    {
      "level": "H1",
      "text": "）学习旨在重用过去的经验，即使用动作重放方法存储",
      "page": 92
    },
    {
      "level": "H1",
      "text": "的其先前迭代中的所有策略来预测当前策略。尽管异策略对于基于价值的方法而",
      "page": 92
    },
    {
      "level": "H1",
      "text": "言相对简单，但这对于传统的策略梯度公式来说并不是直接可行的",
      "page": 92
    },
    {
      "level": "H1",
      "text": "。因此，",
      "page": 92
    },
    {
      "level": "H1",
      "text": "在本文中将重点放在将演员",
      "page": 92
    },
    {
      "level": "H1",
      "text": "评论家方法的稳定性与异策略增强学习的效率相结",
      "page": 92
    },
    {
      "level": "H1",
      "text": "合，这利用了深度增强学习的最新进展",
      "page": 92
    },
    {
      "level": "H1",
      "text": "，尤其是异策略算法",
      "page": 92
    },
    {
      "level": "H1",
      "text": "[203],[204]",
      "page": 92
    },
    {
      "level": "H1",
      "text": "除了在机器人和控制方面的传统应用外，增强学习最近还成功应用于一些视",
      "page": 92
    },
    {
      "level": "H1",
      "text": "觉识别任务。",
      "page": 92
    },
    {
      "level": "H1",
      "text": "Mnih",
      "page": 92
    },
    {
      "level": "H1",
      "text": "等人引入周期性注意模型以从图像中聚焦于选定的区域或位",
      "page": 92
    },
    {
      "level": "H1",
      "text": "置以进行数字检测和分类",
      "page": 92
    },
    {
      "level": "H1",
      "text": "[205]",
      "page": 92
    },
    {
      "level": "H1",
      "text": "。将该想法扩展到身份对齐，通过迭代地去除每个",
      "page": 92
    },
    {
      "level": "H1",
      "text": "图像中的不相关像素",
      "page": 92
    },
    {
      "level": "H1",
      "text": "[206]",
      "page": 92
    },
    {
      "level": "H1",
      "text": "。基于值的",
      "page": 92
    },
    {
      "level": "H1",
      "text": "学习方法通过丢弃低效的查询-候选帧对",
      "page": 92
    },
    {
      "level": "H1",
      "text": "并在处理足够数量的帧对之后停止比较，来控制计算量，实现目标跟踪和视频验",
      "page": 92
    },
    {
      "level": "H1",
      "text": "[195],[207]",
      "page": 92
    },
    {
      "level": "H1",
      "text": "。但是，这将不可避免地导致丢失未使用帧对中的信息，并且仅适用于",
      "page": 92
    },
    {
      "level": "H1",
      "text": "验证。策略梯度",
      "page": 92
    },
    {
      "level": "H1",
      "text": "评论家增强学习在视觉识别方面的应用还有待拓展。",
      "page": 92
    },
    {
      "level": "H1",
      "text": "深度度量学习通过特征转换学习新的特征空间",
      "page": 92
    },
    {
      "level": "H1",
      "text": "[68]",
      "page": 92
    },
    {
      "level": "H1",
      "text": "。其通过构建样本元组",
      "page": 92
    },
    {
      "level": "H1",
      "text": "tuple",
      "page": 92
    },
    {
      "level": "H1",
      "text": "）并且要求具有相同类标签的样本接近而具有不同标签的样本之间的距离",
      "page": 92
    },
    {
      "level": "H1",
      "text": "高于阈值",
      "page": 92
    },
    {
      "level": "H1",
      "text": "[66]",
      "page": 92
    },
    {
      "level": "H1",
      "text": "。它在验证任务中很流行。在这里，不根据主题标识设置距离约束，",
      "page": 92
    },
    {
      "level": "H1",
      "text": "基于人脸图片集的身份识别",
      "page": 93
    },
    {
      "level": "H1",
      "text": "而是选择姿势类来对齐查询集（",
      "page": 93
    },
    {
      "level": "H1",
      "text": "probe set",
      "page": 93
    },
    {
      "level": "H1",
      "text": "）和候选集（",
      "page": 93
    },
    {
      "level": "H1",
      "text": "gallery set",
      "page": 93
    },
    {
      "level": "H1",
      "text": "时序模型广泛用于视频分类，基于视频的识别和基于时序的动作检测等。文",
      "page": 93
    },
    {
      "level": "H1",
      "text": "[208]",
      "page": 93
    },
    {
      "level": "H1",
      "text": "提出使用递归神经网络（",
      "page": 93
    },
    {
      "level": "H1",
      "text": "recursive neural network, RNN",
      "page": 93
    },
    {
      "level": "H1",
      "text": "）对帧之间的时序信",
      "page": 93
    },
    {
      "level": "H1",
      "text": "息建模。后来开发了",
      "page": 93
    },
    {
      "level": "H1",
      "text": "3D CNN",
      "page": 93
    },
    {
      "level": "H1",
      "text": "以直接从视频剪辑中提取空间",
      "page": 93
    },
    {
      "level": "H1",
      "text": "时间特征",
      "page": 93
    },
    {
      "level": "H1",
      "text": "[209]",
      "page": 93
    },
    {
      "level": "H1",
      "text": "。但是，",
      "page": 93
    },
    {
      "level": "H1",
      "text": "DAC",
      "page": 93
    },
    {
      "level": "H1",
      "text": "模块不兼容。最近开发了两种类型的时序注意力机制。第一种方法首",
      "page": 93
    },
    {
      "level": "H1",
      "text": "先使用空间卷积，然后使用全连接（",
      "page": 93
    },
    {
      "level": "H1",
      "text": "fully connected, FC",
      "page": 93
    },
    {
      "level": "H1",
      "text": "[191]",
      "page": 93
    },
    {
      "level": "H1",
      "text": "层将模型限",
      "page": 93
    },
    {
      "level": "H1",
      "text": "制为固定长度的视频片段。第二种方法选择时间卷积而不是",
      "page": 93
    },
    {
      "level": "H1",
      "text": "[210]",
      "page": 93
    },
    {
      "level": "H1",
      "text": "。虽然",
      "page": 93
    },
    {
      "level": "H1",
      "text": "使用时间卷积进行固定长度剪辑的动作分析，但本章表明它对于具有可变长度的",
      "page": 93
    },
    {
      "level": "H1",
      "text": "基于视频的人脸识别是有前途的。",
      "page": 93
    },
    {
      "level": "H1",
      "text": "5.2",
      "page": 93
    },
    {
      "level": "H1",
      "text": "集内依赖性控制",
      "page": 93
    },
    {
      "level": "H1",
      "text": "本章所提出的框架的流程图如图",
      "page": 93
    },
    {
      "level": "H1",
      "text": "5.3",
      "page": 93
    },
    {
      "level": "H1",
      "text": "所示。它采用一组面部图像作为输入，",
      "page": 93
    },
    {
      "level": "H1",
      "text": "并用两个主要模块处理它们，并输出单个（无",
      "page": 93
    },
    {
      "level": "H1",
      "text": "PGR",
      "page": 93
    },
    {
      "level": "H1",
      "text": "时）或者三个（带有",
      "page": 93
    },
    {
      "level": "H1",
      "text": "特征向量作为其特征表达用于识别任务。采用现代",
      "page": 93
    },
    {
      "level": "H1",
      "text": "CNN",
      "page": 93
    },
    {
      "level": "H1",
      "text": "模块将图像嵌入到低维",
      "page": 93
    },
    {
      "level": "H1",
      "text": "度隐空间（",
      "page": 93
    },
    {
      "level": "H1",
      "text": "latent space",
      "page": 93
    },
    {
      "level": "H1",
      "text": "）中，进而降低了计算成本，并为增强学习提供了远小于",
      "page": 93
    },
    {
      "level": "H1",
      "text": "原始图片的可行的状态空间。然后接入",
      "page": 93
    },
    {
      "level": "H1",
      "text": "模块，它作为注意力模型读入所有",
      "page": 93
    },
    {
      "level": "H1",
      "text": "特征向量，并在特征级别将它们进行自适应加权的线性组合。",
      "page": 93
    },
    {
      "level": "H1",
      "text": "模块可以进一",
      "page": 93
    },
    {
      "level": "H1",
      "text": "步利用人脸的先验知识来解决具较大的姿态变化的集合。",
      "page": 93
    },
    {
      "level": "H1",
      "text": "本章所提出的基于图片集的人脸识别。",
      "page": 93
    },
    {
      "level": "H1",
      "text": "Figure 5.3  Our network architecture for image set-based face recognition.",
      "page": 93
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 94
    },
    {
      "level": "H1",
      "text": "5.2.1",
      "page": 94
    },
    {
      "level": "H1",
      "text": "基于演员",
      "page": 94
    },
    {
      "level": "H1",
      "text": "评论家增强学习的图片集人脸识别",
      "page": 94
    },
    {
      "level": "H1",
      "text": "在基于集合的识别任务中的",
      "page": 94
    },
    {
      "level": "H1",
      "text": ", 𝑦",
      "page": 94
    },
    {
      "level": "H1",
      "text": "௠ୀଵ",
      "page": 94
    },
    {
      "level": "H1",
      "text": "，其中",
      "page": 94
    },
    {
      "level": "H1",
      "text": "是具有不同数",
      "page": 94
    },
    {
      "level": "H1",
      "text": "是集合中的第",
      "page": 94
    },
    {
      "level": "H1",
      "text": "个图像",
      "page": 94
    },
    {
      "level": "H1",
      "text": "视频帧），",
      "page": 94
    },
    {
      "level": "H1",
      "text": "是相应的集合的身份标签。将每个图像",
      "page": 94
    },
    {
      "level": "H1",
      "text": "输入到模型中，",
      "page": 94
    },
    {
      "level": "H1",
      "text": "并使用神经嵌入网络提取其相应的特征表示",
      "page": 94
    },
    {
      "level": "H1",
      "text": "。采用目前较为成熟的",
      "page": 94
    },
    {
      "level": "H1",
      "text": "GoogLeNet",
      "page": 94
    },
    {
      "level": "H1",
      "text": "[211]",
      "page": 94
    },
    {
      "level": "H1",
      "text": "ResNet",
      "page": 94
    },
    {
      "level": "H1",
      "text": "[31]",
      "page": 94
    },
    {
      "level": "H1",
      "text": "来提取",
      "page": 94
    },
    {
      "level": "H1",
      "text": "128",
      "page": 94
    },
    {
      "level": "H1",
      "text": "维的特征向量作为每个图像的特征表示。",
      "page": 94
    },
    {
      "level": "H1",
      "text": "已经在多个人脸识别基准测试中表现出优异的性能，而此",
      "page": 94
    },
    {
      "level": "H1",
      "text": "模块也可以替换为其他先进的",
      "page": 94
    },
    {
      "level": "H1",
      "text": "CNN",
      "page": 94
    },
    {
      "level": "H1",
      "text": "模型。在本章节的其余部分，将简单地将神",
      "page": 94
    },
    {
      "level": "H1",
      "text": "经嵌入网络称为",
      "page": 94
    },
    {
      "level": "H1",
      "text": "，并在适当的位置省略上标索引",
      "page": 94
    },
    {
      "level": "H1",
      "text": "（身份）以提高可读性。",
      "page": 94
    },
    {
      "level": "H1",
      "text": "由于使用固定的已经训练好的神经网络从图像中直接提取特征，因此特征表",
      "page": 94
    },
    {
      "level": "H1",
      "text": "达也同图片一样有较大的变化。硬注意力方案",
      "page": 94
    },
    {
      "level": "H1",
      "text": "[195]",
      "page": 94
    },
    {
      "level": "H1",
      "text": "简单的丢弃其中一些样本可能",
      "page": 94
    },
    {
      "level": "H1",
      "text": "导致集合中丢失太多信息",
      "page": 94
    },
    {
      "level": "H1",
      "text": "[193]",
      "page": 94
    },
    {
      "level": "H1",
      "text": "DAC",
      "page": 94
    },
    {
      "level": "H1",
      "text": "可以被视为一种软注意力方案。即定义每",
      "page": 94
    },
    {
      "level": "H1",
      "text": "个图片的特征向量在加权求和运算中的重要性。",
      "page": 94
    },
    {
      "level": "H1",
      "text": "对集内依赖性建模的解决方案是将其视为马尔可夫决策过程（",
      "page": 94
    },
    {
      "level": "H1",
      "text": "MDP",
      "page": 94
    },
    {
      "level": "H1",
      "text": "）。在每",
      "page": 94
    },
    {
      "level": "H1",
      "text": "个时间步骤",
      "page": 94
    },
    {
      "level": "H1",
      "text": "，智能体（",
      "page": 94
    },
    {
      "level": "H1",
      "text": "agent",
      "page": 94
    },
    {
      "level": "H1",
      "text": "）在状态空间",
      "page": 94
    },
    {
      "level": "H1",
      "text": "中接收状态",
      "page": 94
    },
    {
      "level": "H1",
      "text": "，并且根据策略",
      "page": 94
    },
    {
      "level": "H1",
      "text": "𝜋(𝑎",
      "page": 94
    },
    {
      "level": "H1",
      "text": "，从动作空间",
      "page": 94
    },
    {
      "level": "H1",
      "text": "中选择动作",
      "page": 94
    },
    {
      "level": "H1",
      "text": "作为智能体的行为。然后被选择的动作将确定下",
      "page": 94
    },
    {
      "level": "H1",
      "text": "一个状态，即",
      "page": 94
    },
    {
      "level": "H1",
      "text": "௧ାଵ",
      "page": 94
    },
    {
      "level": "H1",
      "text": "或终止，并从环境接收奖励",
      "page": 94
    },
    {
      "level": "H1",
      "text": ", 𝑎",
      "page": 94
    },
    {
      "level": "H1",
      "text": ") ∈ℛ⊆ℝ",
      "page": 94
    },
    {
      "level": "H1",
      "text": "。训练的目标是找",
      "page": 94
    },
    {
      "level": "H1",
      "text": "𝛾∈[0,1)",
      "page": 94
    },
    {
      "level": "H1",
      "text": "是权衡即时和未来长期奖励重要性的平衡因子",
      "page": 94
    },
    {
      "level": "H1",
      "text": "[198]",
      "page": 94
    },
    {
      "level": "H1",
      "text": "在基于图像集的人脸识别应用中，定义动作",
      "page": 94
    },
    {
      "level": "H1",
      "text": ", ⋯, 𝑎",
      "page": 94
    },
    {
      "level": "H1",
      "text": "为每个图像的特征",
      "page": 94
    },
    {
      "level": "H1",
      "text": "௜ୀଵ",
      "page": 94
    },
    {
      "level": "H1",
      "text": "的权重。",
      "page": 94
    },
    {
      "level": "H1",
      "text": "是集合中图像（或帧）的数量。软注意力机制的的权重",
      "page": 94
    },
    {
      "level": "H1",
      "text": "初始化为",
      "page": 94
    },
    {
      "level": "H1",
      "text": "，并逐步更新。状态",
      "page": 94
    },
    {
      "level": "H1",
      "text": "𝑡−1",
      "page": 94
    },
    {
      "level": "H1",
      "text": "个已经计算权重的特征和",
      "page": 94
    },
    {
      "level": "H1",
      "text": "𝑇−(𝑡−1)",
      "page": 94
    },
    {
      "level": "H1",
      "text": "待加权特征相关。相较于在图像层级研究图像间的关系，使用",
      "page": 94
    },
    {
      "level": "H1",
      "text": "维的紧凑嵌入",
      "page": 94
    },
    {
      "level": "H1",
      "text": "特征向量大大缩小了状态空间并使增强学习训练更为可行。在实际应用中，",
      "page": 94
    },
    {
      "level": "H1",
      "text": "和在时间",
      "page": 94
    },
    {
      "level": "H1",
      "text": "步时其余特征在使用更新后权重聚合的串联向量。而终止状态意味",
      "page": 94
    },
    {
      "level": "H1",
      "text": "着该集合中的所有图像都已被遍历。",
      "page": 94
    },
    {
      "level": "H1",
      "text": "೔సభ",
      "page": 94
    },
    {
      "level": "H1",
      "text": "𝐶𝑜𝑛𝑐𝑎𝑡𝑒𝑛𝑎𝑡𝑒{𝑓",
      "page": 94
    },
    {
      "level": "H1",
      "text": "(5.1)",
      "page": 94
    },
    {
      "level": "H1",
      "text": "在实际操作中，",
      "page": 94
    },
    {
      "level": "H1",
      "text": "后添加数个全连接层",
      "page": 94
    },
    {
      "level": "H1",
      "text": "softmax",
      "page": 94
    },
    {
      "level": "H1",
      "text": "以计算交叉熵损",
      "page": 94
    },
    {
      "level": "H1",
      "text": "基于人脸图片集的身份识别",
      "page": 95
    },
    {
      "level": "H1",
      "text": "个元素。",
      "page": 95
    },
    {
      "level": "H1",
      "text": "𝑔(⋅)",
      "page": 95
    },
    {
      "level": "H1",
      "text": "表示加权平均聚合函数，",
      "page": 95
    },
    {
      "level": "H1",
      "text": "将使用更新后的权重聚合的",
      "page": 95
    },
    {
      "level": "H1",
      "text": "映射到",
      "page": 95
    },
    {
      "level": "H1",
      "text": "。奖励的定义如下：",
      "page": 95
    },
    {
      "level": "H1",
      "text": "௜ୀଵ",
      "page": 95
    },
    {
      "level": "H1",
      "text": "(with updated 𝑎",
      "page": 95
    },
    {
      "level": "H1",
      "text": "at step 𝑡)",
      "page": 95
    },
    {
      "level": "H1",
      "text": "(5.2)",
      "page": 95
    },
    {
      "level": "H1",
      "text": "其中铰链损耗项用作正则化以促进冗余减少并且由λ控制权重。它还有助于稳定",
      "page": 95
    },
    {
      "level": "H1",
      "text": "训练过程。",
      "page": 95
    },
    {
      "level": "H1",
      "text": "考虑到动作空间为连续空间",
      "page": 95
    },
    {
      "level": "H1",
      "text": "𝒜∈ℝ",
      "page": 95
    },
    {
      "level": "H1",
      "text": "，基于值的增强学习（例如，",
      "page": 95
    },
    {
      "level": "H1",
      "text": "Q-Learning",
      "page": 95
    },
    {
      "level": "H1",
      "text": "不能解决该任务。本章采用演员",
      "page": 95
    },
    {
      "level": "H1",
      "text": "评论员网络，根据对集合内其他特征的观察，对",
      "page": 95
    },
    {
      "level": "H1",
      "text": "每个特征进行评分。在基于策略的方法中，训练目标是找到参数化策略",
      "page": 95
    },
    {
      "level": "H1",
      "text": "其在给定起始状态的情况下使预期奖励",
      "page": 95
    },
    {
      "level": "H1",
      "text": "𝐽(𝜃)",
      "page": 95
    },
    {
      "level": "H1",
      "text": "最大化。遵循策略梯度理论",
      "page": 95
    },
    {
      "level": "H1",
      "text": "[201]",
      "page": 95
    },
    {
      "level": "H1",
      "text": "，给定",
      "page": 95
    },
    {
      "level": "H1",
      "text": "目标函数的参数的梯度具有以下形式：",
      "page": 95
    },
    {
      "level": "H1",
      "text": "𝐽(𝜃) = 𝔼[𝛻",
      "page": 95
    },
    {
      "level": "H1",
      "text": "log𝜋",
      "page": 95
    },
    {
      "level": "H1",
      "text": ")(𝑄(𝑠",
      "page": 95
    },
    {
      "level": "H1",
      "text": ", 𝑎",
      "page": 95
    },
    {
      "level": "H1",
      "text": ") −𝑏(𝑠",
      "page": 95
    },
    {
      "level": "H1",
      "text": "))]",
      "page": 95
    },
    {
      "level": "H1",
      "text": "(5.4)",
      "page": 95
    },
    {
      "level": "H1",
      "text": "𝑄(𝑠",
      "page": 95
    },
    {
      "level": "H1",
      "text": ") = 𝔼[𝑅",
      "page": 95
    },
    {
      "level": "H1",
      "text": "是状态",
      "page": 95
    },
    {
      "level": "H1",
      "text": "动作值函数，其中初始动作",
      "page": 95
    },
    {
      "level": "H1",
      "text": "用以计算自状",
      "page": 95
    },
    {
      "level": "H1",
      "text": "开始时的预期奖励。通常减去基线函数",
      "page": 95
    },
    {
      "level": "H1",
      "text": "𝑏(𝑠",
      "page": 95
    },
    {
      "level": "H1",
      "text": "以减小方差，同时不改变估计值",
      "page": 95
    },
    {
      "level": "H1",
      "text": "的梯度",
      "page": 95
    },
    {
      "level": "H1",
      "text": "[202][212]",
      "page": 95
    },
    {
      "level": "H1",
      "text": "。该基线可以是仅与状态值相关的函数",
      "page": 95
    },
    {
      "level": "H1",
      "text": "𝑉(𝑠",
      "page": 95
    },
    {
      "level": "H1",
      "text": "，其类似",
      "page": 95
    },
    {
      "level": "H1",
      "text": "，但不与",
      "page": 95
    },
    {
      "level": "H1",
      "text": "相关。优势函数可定义为",
      "page": 95
    },
    {
      "level": "H1",
      "text": "𝐴(𝑠",
      "page": 95
    },
    {
      "level": "H1",
      "text": ") = 𝑄(𝑠",
      "page": 95
    },
    {
      "level": "H1",
      "text": ") −𝑉(𝑠",
      "page": 95
    },
    {
      "level": "H1",
      "text": "[161]",
      "page": 95
    },
    {
      "level": "H1",
      "text": "方程（",
      "page": 95
    },
    {
      "level": "H1",
      "text": "）可写为：",
      "page": 95
    },
    {
      "level": "H1",
      "text": "是评论家。为了减少所需参数的数量，参数化时序差分（",
      "page": 95
    },
    {
      "level": "H1",
      "text": "parameterized temporal",
      "page": 95
    },
    {
      "level": "H1",
      "text": "difference, TD",
      "page": 95
    },
    {
      "level": "H1",
      "text": "）误差",
      "page": 95
    },
    {
      "level": "H1",
      "text": "= 𝑟",
      "page": 95
    },
    {
      "level": "H1",
      "text": "+ 𝛾𝑉",
      "page": 95
    },
    {
      "level": "H1",
      "text": "௦ାଵ",
      "page": 95
    },
    {
      "level": "H1",
      "text": ") −𝑉",
      "page": 95
    },
    {
      "level": "H1",
      "text": "可用于近似优势函数。使用两个",
      "page": 95
    },
    {
      "level": "H1",
      "text": "不同的符号",
      "page": 95
    },
    {
      "level": "H1",
      "text": "来表示演员和评论家函数，但是大多数这些参数在主干神经网",
      "page": 95
    },
    {
      "level": "H1",
      "text": "络中共享，然后分别用于策略和值预测的两个分支。",
      "page": 95
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 96
    },
    {
      "level": "H1",
      "text": "5.4",
      "page": 96
    },
    {
      "level": "H1",
      "text": "评论家增强学习的",
      "page": 96
    },
    {
      "level": "H1",
      "text": "DAC",
      "page": 96
    },
    {
      "level": "H1",
      "text": "异策略）前馈神经网络架构。",
      "page": 96
    },
    {
      "level": "H1",
      "text": "Figure 5.4  The feed-forward neural network architecture of DAC(on/off) which uses the",
      "page": 96
    },
    {
      "level": "H1",
      "text": "advantage actor-critic as the backbone.",
      "page": 96
    },
    {
      "level": "H1",
      "text": "中，采用两个维度均为",
      "page": 96
    },
    {
      "level": "H1",
      "text": "100",
      "page": 96
    },
    {
      "level": "H1",
      "text": "的全连接层，然后将两个子分支与两个",
      "page": 96
    },
    {
      "level": "H1",
      "text": "全连接层（分别为",
      "page": 96
    },
    {
      "level": "H1",
      "text": "维）级联，如图",
      "page": 96
    },
    {
      "level": "H1",
      "text": "所示。对于所有任务，在",
      "page": 96
    },
    {
      "level": "H1",
      "text": "范围内均匀地采样学习率，并设置",
      "page": 96
    },
    {
      "level": "H1",
      "text": "𝛾= 0.999",
      "page": 96
    },
    {
      "level": "H1",
      "text": "5.2.2",
      "page": 96
    },
    {
      "level": "H1",
      "text": "具有经验重播的异策略演员",
      "page": 96
    },
    {
      "level": "H1",
      "text": "评论家增强学习",
      "page": 96
    },
    {
      "level": "H1",
      "text": "同策略增强学习（",
      "page": 96
    },
    {
      "level": "H1",
      "text": "on-policy RL",
      "page": 96
    },
    {
      "level": "H1",
      "text": "）方法使用当前策略收集的样本更新模型。经",
      "page": 96
    },
    {
      "level": "H1",
      "text": "验重放（",
      "page": 96
    },
    {
      "level": "H1",
      "text": "experience replay , ER",
      "page": 96
    },
    {
      "level": "H1",
      "text": "）可用于提高样本效率，其中经验是从重放池",
      "page": 96
    },
    {
      "level": "H1",
      "text": "随机采样的",
      "page": 96
    },
    {
      "level": "H1",
      "text": "[213]",
      "page": 96
    },
    {
      "level": "H1",
      "text": "。由于这些过去的经验是从不同的策略中收集的，因此使用",
      "page": 96
    },
    {
      "level": "H1",
      "text": "进行异策略更新。",
      "page": 96
    },
    {
      "level": "H1",
      "text": "使用增强学习算法训练模型时，",
      "page": 96
    },
    {
      "level": "H1",
      "text": "贪婪动作选择",
      "page": 96
    },
    {
      "level": "H1",
      "text": "[197]",
      "page": 96
    },
    {
      "level": "H1",
      "text": "通常用于在对当前策略",
      "page": 96
    },
    {
      "level": "H1",
      "text": "的利用（",
      "page": 96
    },
    {
      "level": "H1",
      "text": "exploitation",
      "page": 96
    },
    {
      "level": "H1",
      "text": "）和对环境的探索（",
      "page": 96
    },
    {
      "level": "H1",
      "text": "exploration",
      "page": 96
    },
    {
      "level": "H1",
      "text": "）之间进行权衡，其以一定概",
      "page": 96
    },
    {
      "level": "H1",
      "text": "率选择随机动作，否则选择排名最高的动作。用于生成训练权重的策略被称为行",
      "page": 96
    },
    {
      "level": "H1",
      "text": "为策略（",
      "page": 96
    },
    {
      "level": "H1",
      "text": "behavior policy",
      "page": 96
    },
    {
      "level": "H1",
      "text": "，而待优化的策略称为目标策略（",
      "page": 96
    },
    {
      "level": "H1",
      "text": "target policy",
      "page": 96
    },
    {
      "level": "H1",
      "text": "第二节中描述的基本的优势演员",
      "page": 96
    },
    {
      "level": "H1",
      "text": "评论家（",
      "page": 96
    },
    {
      "level": "H1",
      "text": "advantage actor-critic, A2C",
      "page": 96
    },
    {
      "level": "H1",
      "text": "）训练",
      "page": 96
    },
    {
      "level": "H1",
      "text": "算法为同策略（",
      "page": 96
    },
    {
      "level": "H1",
      "text": "on-policy",
      "page": 96
    },
    {
      "level": "H1",
      "text": "）算法，因为它假设动作是从与要优化的目标相同的策",
      "page": 96
    },
    {
      "level": "H1",
      "text": "略中提取的（即",
      "page": 96
    },
    {
      "level": "H1",
      "text": "𝜇= 𝜋",
      "page": 96
    },
    {
      "level": "H1",
      "text": "）。然在此方法中，当前策略",
      "page": 96
    },
    {
      "level": "H1",
      "text": "是使用在异策略学习中从旧",
      "page": 96
    },
    {
      "level": "H1",
      "text": "行为策略",
      "page": 96
    },
    {
      "level": "H1",
      "text": "生成的样本来更新。因此，重要性采样（",
      "page": 96
    },
    {
      "level": "H1",
      "text": "importance sampling , IS",
      "page": 96
    },
    {
      "level": "H1",
      "text": "率用于重新缩放每个采样的奖励以在时间步骤",
      "page": 96
    },
    {
      "level": "H1",
      "text": "校正采样偏差：",
      "page": 96
    },
    {
      "level": "H1",
      "text": "= 𝜋(𝑎",
      "page": 96
    },
    {
      "level": "H1",
      "text": ")/𝜇(𝑎",
      "page": 96
    },
    {
      "level": "H1",
      "text": "[177]",
      "page": 96
    },
    {
      "level": "H1",
      "text": "。对于",
      "page": 96
    },
    {
      "level": "H1",
      "text": "A2C",
      "page": 96
    },
    {
      "level": "H1",
      "text": "，参数化的仅与状态相关的值函数",
      "page": 96
    },
    {
      "level": "H1",
      "text": "的异策略梯度",
      "page": 96
    },
    {
      "level": "H1",
      "text": "基于人脸图片集的身份识别",
      "page": 97
    },
    {
      "level": "H1",
      "text": "具有以下形式：",
      "page": 97
    },
    {
      "level": "H1",
      "text": "୭୤୤",
      "page": 97
    },
    {
      "level": "H1",
      "text": "= ∑",
      "page": 97
    },
    {
      "level": "H1",
      "text": "௧ୀଵ",
      "page": 97
    },
    {
      "level": "H1",
      "text": "))𝛻",
      "page": 97
    },
    {
      "level": "H1",
      "text": ") ∏",
      "page": 97
    },
    {
      "level": "H1",
      "text": "௜ୀଵ",
      "page": 97
    },
    {
      "level": "H1",
      "text": "(5.6)",
      "page": 97
    },
    {
      "level": "H1",
      "text": "是异策略蒙特卡洛总回报（",
      "page": 97
    },
    {
      "level": "H1",
      "text": "return",
      "page": 97
    },
    {
      "level": "H1",
      "text": "[215]:",
      "page": 97
    },
    {
      "level": "H1",
      "text": "= 𝑟",
      "page": 97
    },
    {
      "level": "H1",
      "text": "+ 𝛾𝑟",
      "page": 97
    },
    {
      "level": "H1",
      "text": "௧ାଵ",
      "page": 97
    },
    {
      "level": "H1",
      "text": "+ ⋯+ 𝛾",
      "page": 97
    },
    {
      "level": "H1",
      "text": "்ି௧",
      "page": 97
    },
    {
      "level": "H1",
      "text": "௧ା௜",
      "page": 97
    },
    {
      "level": "H1",
      "text": "(5.7)",
      "page": 97
    },
    {
      "level": "H1",
      "text": "更新后的梯度为",
      "page": 97
    },
    {
      "level": "H1",
      "text": "+ 𝛾𝑉",
      "page": 97
    },
    {
      "level": "H1",
      "text": "是使用",
      "page": 97
    },
    {
      "level": "H1",
      "text": "的估计值的时序差分（",
      "page": 97
    },
    {
      "level": "H1",
      "text": "）误差。",
      "page": 97
    },
    {
      "level": "H1",
      "text": "在此，引入了一个修改过的信任区域策略优化（",
      "page": 97
    },
    {
      "level": "H1",
      "text": "Trust Region Policy",
      "page": 97
    },
    {
      "level": "H1",
      "text": "Optimization",
      "page": 97
    },
    {
      "level": "H1",
      "text": "）方法",
      "page": 97
    },
    {
      "level": "H1",
      "text": "[203],[204]",
      "page": 97
    },
    {
      "level": "H1",
      "text": "。除了最大化累积奖励",
      "page": 97
    },
    {
      "level": "H1",
      "text": "𝐽(𝜃)",
      "page": 97
    },
    {
      "level": "H1",
      "text": "之外，优化还受更新后策略",
      "page": 97
    },
    {
      "level": "H1",
      "text": "与平均策略",
      "page": 97
    },
    {
      "level": "H1",
      "text": "之间的",
      "page": 97
    },
    {
      "level": "H1",
      "text": "Kullback-Leibler",
      "page": 97
    },
    {
      "level": "H1",
      "text": "）散度限制的约束。该平均策略表示",
      "page": 97
    },
    {
      "level": "H1",
      "text": "过去策略的平均值，并且限制更新的策略偏离具有权重",
      "page": 97
    },
    {
      "level": "H1",
      "text": "的平均",
      "page": 97
    },
    {
      "level": "H1",
      "text": "←[𝛼𝜃",
      "page": 97
    },
    {
      "level": "H1",
      "text": "(1 −𝛼)𝜃]",
      "page": 97
    },
    {
      "level": "H1",
      "text": "太远。因此，给定方程（",
      "page": 97
    },
    {
      "level": "H1",
      "text": "）中的异策略梯度",
      "page": 97
    },
    {
      "level": "H1",
      "text": "，具有信任区域",
      "page": 97
    },
    {
      "level": "H1",
      "text": "修改后的策略梯度计算如下：",
      "page": 97
    },
    {
      "level": "H1",
      "text": "௠௜௡௜௠௜௭௘",
      "page": 97
    },
    {
      "level": "H1",
      "text": "∥𝛥𝜃",
      "page": 97
    },
    {
      "level": "H1",
      "text": "−𝑧∥",
      "page": 97
    },
    {
      "level": "H1",
      "text": "Subject to:",
      "page": 97
    },
    {
      "level": "H1",
      "text": ") ∥𝜋",
      "page": 97
    },
    {
      "level": "H1",
      "text": "𝑧≤𝜉",
      "page": 97
    },
    {
      "level": "H1",
      "text": "(5.9)",
      "page": 97
    },
    {
      "level": "H1",
      "text": "参数化的策略，",
      "page": 97
    },
    {
      "level": "H1",
      "text": "约束的幅度。由于约束是线性",
      "page": 97
    },
    {
      "level": "H1",
      "text": "的，因此可以使用",
      "page": 97
    },
    {
      "level": "H1",
      "text": "KKT",
      "page": 97
    },
    {
      "level": "H1",
      "text": "条件求解该二次规划问题的闭式解。设",
      "page": 97
    },
    {
      "level": "H1",
      "text": "可以得到：",
      "page": 97
    },
    {
      "level": "H1",
      "text": "= 𝛥𝜃",
      "page": 97
    },
    {
      "level": "H1",
      "text": "−𝑚𝑎𝑥",
      "page": 97
    },
    {
      "level": "H1",
      "text": "౥౜౜",
      "page": 97
    },
    {
      "level": "H1",
      "text": "此操作也与自然梯度密切相关",
      "page": 97
    },
    {
      "level": "H1",
      "text": "[216],[217]",
      "page": 97
    },
    {
      "level": "H1",
      "text": "。上述增强功能可加速并稳定",
      "page": 97
    },
    {
      "level": "H1",
      "text": "A2C",
      "page": 97
    },
    {
      "level": "H1",
      "text": "络训练。在",
      "page": 97
    },
    {
      "level": "H1",
      "text": "DAC",
      "page": 97
    },
    {
      "level": "H1",
      "text": "的异策略版本中，",
      "page": 97
    },
    {
      "level": "H1",
      "text": "[0.1,2]",
      "page": 97
    },
    {
      "level": "H1",
      "text": "范围内均匀采样，截断阈值",
      "page": 97
    },
    {
      "level": "H1",
      "text": "设置为",
      "page": 97
    },
    {
      "level": "H1",
      "text": "，软更新",
      "page": 97
    },
    {
      "level": "H1",
      "text": "的速率设置为",
      "page": 97
    },
    {
      "level": "H1",
      "text": "0.995",
      "page": 97
    },
    {
      "level": "H1",
      "text": "5.2.3",
      "page": 97
    },
    {
      "level": "H1",
      "text": "与时序注意力模型相结合",
      "page": 97
    },
    {
      "level": "H1",
      "text": "视频在集合中起着重要作用。然而，上一小节中使用的",
      "page": 97
    },
    {
      "level": "H1",
      "text": "[11]",
      "page": 97
    },
    {
      "level": "H1",
      "text": "和传统的聚",
      "page": 97
    },
    {
      "level": "H1",
      "text": "合方法",
      "page": 97
    },
    {
      "level": "H1",
      "text": "[193]",
      "page": 97
    },
    {
      "level": "H1",
      "text": "都忽略了视频中的时序关系。本节提出分别处理无序图像和连续帧。",
      "page": 97
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 98
    },
    {
      "level": "H1",
      "text": "在此，两种基于视频的注意力方案被引入到集合的识别任务中。如图",
      "page": 98
    },
    {
      "level": "H1",
      "text": "5.5",
      "page": 98
    },
    {
      "level": "H1",
      "text": "所示，第一种方案基于",
      "page": 98
    },
    {
      "level": "H1",
      "text": "RNN",
      "page": 98
    },
    {
      "level": "H1",
      "text": "。具体来说，双向长短期记忆（",
      "page": 98
    },
    {
      "level": "H1",
      "text": "bi-directional long short-",
      "page": 98
    },
    {
      "level": "H1",
      "text": "term memory , LSTM",
      "page": 98
    },
    {
      "level": "H1",
      "text": "）被用作递归层，其将顺序特征向量作为输入并产生一系列",
      "page": 98
    },
    {
      "level": "H1",
      "text": "相应的激活值。然后，通过",
      "page": 98
    },
    {
      "level": "H1",
      "text": "softmax",
      "page": 98
    },
    {
      "level": "H1",
      "text": "函数对激活值进行归一化。",
      "page": 98
    },
    {
      "level": "H1",
      "text": "另一种方法为时间卷积，如图",
      "page": 98
    },
    {
      "level": "H1",
      "text": "）所示，作为",
      "page": 98
    },
    {
      "level": "H1",
      "text": "的更有效的替代方",
      "page": 98
    },
    {
      "level": "H1",
      "text": "案被引入。使用",
      "page": 98
    },
    {
      "level": "H1",
      "text": "个大小为",
      "page": 98
    },
    {
      "level": "H1",
      "text": "{3,128,1}",
      "page": 98
    },
    {
      "level": "H1",
      "text": "的卷积核作为第一层，随后为一个大小为",
      "page": 98
    },
    {
      "level": "H1",
      "text": "{3,64,1}",
      "page": 98
    },
    {
      "level": "H1",
      "text": "的卷积核，填充和步长大小均设置为",
      "page": 98
    },
    {
      "level": "H1",
      "text": "。输出向量的维数等于视频中的帧",
      "page": 98
    },
    {
      "level": "H1",
      "text": "数。使用",
      "page": 98
    },
    {
      "level": "H1",
      "text": "来获得归一化的注意力分数。与",
      "page": 98
    },
    {
      "level": "H1",
      "text": "DAC",
      "page": 98
    },
    {
      "level": "H1",
      "text": "相比，时间卷积",
      "page": 98
    },
    {
      "level": "H1",
      "text": "的感受野相对较小。但是视频中的冗余主要在于相邻帧。凭借这种分而治之的想",
      "page": 98
    },
    {
      "level": "H1",
      "text": "法，能够实现更高的性能和更少的计算量。",
      "page": 98
    },
    {
      "level": "H1",
      "text": "个连续帧作为输入并输出",
      "page": 98
    },
    {
      "level": "H1",
      "text": "个标量作为注意力分数的时序注意力方案的图",
      "page": 98
    },
    {
      "level": "H1",
      "text": "示。左：基于递归神经网络的时序注意方案。右：基于空间和时间卷积的注意力方案。",
      "page": 98
    },
    {
      "level": "H1",
      "text": "是神经网络，它们输入特征进行处理并输出标量。",
      "page": 98
    },
    {
      "level": "H1",
      "text": "Figure 5.5 Illustration of the temporal attention scheme which takes",
      "page": 98
    },
    {
      "level": "H1",
      "text": "continuous frames",
      "page": 98
    },
    {
      "level": "H1",
      "text": "as input and outputs",
      "page": 98
    },
    {
      "level": "H1",
      "text": "scalars as attention score. Left: recursive neural network-based",
      "page": 98
    },
    {
      "level": "H1",
      "text": "temporal attention scheme. Right: spatial and temporal convolution-based attention scheme.",
      "page": 98
    },
    {
      "level": "H1",
      "text": "R and R’ are the neural networks, which look at some input features and output a scalar.",
      "page": 98
    },
    {
      "level": "H1",
      "text": "5.3",
      "page": 98
    },
    {
      "level": "H1",
      "text": "姿态引导的集合间依赖模型",
      "page": 98
    },
    {
      "level": "H1",
      "text": "为了模拟集合间依赖性，提出了一种由姿态引导的方案。这种想法起源于",
      "page": 98
    },
    {
      "level": "H1",
      "text": "[218][219]",
      "page": 98
    },
    {
      "level": "H1",
      "text": "，其为每个角度分别构建了一个面部检测器。",
      "page": 98
    },
    {
      "level": "H1",
      "text": "基于人脸图片集的身份识别",
      "page": 99
    },
    {
      "level": "H1",
      "text": "5.3.1",
      "page": 99
    },
    {
      "level": "H1",
      "text": "无参数的姿态引导表达",
      "page": 99
    },
    {
      "level": "H1",
      "text": "首先提出一个无参数的",
      "page": 99
    },
    {
      "level": "H1",
      "text": "PGR",
      "page": 99
    },
    {
      "level": "H1",
      "text": "PF-PGR",
      "page": 99
    },
    {
      "level": "H1",
      "text": "），如图",
      "page": 99
    },
    {
      "level": "H1",
      "text": "5.6",
      "page": 99
    },
    {
      "level": "H1",
      "text": "所示。它不使用需要进行",
      "page": 99
    },
    {
      "level": "H1",
      "text": "训练的参数。给定一组面部图像，提取其总的特征聚合",
      "page": 99
    },
    {
      "level": "H1",
      "text": "，以及正面特征",
      "page": 99
    },
    {
      "level": "H1",
      "text": "廓面特征",
      "page": 99
    },
    {
      "level": "H1",
      "text": "的聚合。",
      "page": 99
    },
    {
      "level": "H1",
      "text": "分别是正面脸部图像",
      "page": 99
    },
    {
      "level": "H1",
      "text": "≤30",
      "page": 99
    },
    {
      "level": "H1",
      "text": "和侧面脸部图像",
      "page": 99
    },
    {
      "level": "H1",
      "text": "> 30",
      "page": 99
    },
    {
      "level": "H1",
      "text": "的加权特征平均。使用",
      "page": 99
    },
    {
      "level": "H1",
      "text": "Pose-invariant face alignment",
      "page": 99
    },
    {
      "level": "H1",
      "text": "PIFA",
      "page": 99
    },
    {
      "level": "H1",
      "text": "[220]",
      "page": 99
    },
    {
      "level": "H1",
      "text": "来估计面部左右",
      "page": 99
    },
    {
      "level": "H1",
      "text": "偏转角度，并使用正面和侧面样本训练两个独立的",
      "page": 99
    },
    {
      "level": "H1",
      "text": "CNN",
      "page": 99
    },
    {
      "level": "H1",
      "text": "。正面和轮廓特征",
      "page": 99
    },
    {
      "level": "H1",
      "text": "的权重之和反映了每个姿态组的质量。在预处理阶段，将左侧人面统一镜像到",
      "page": 99
    },
    {
      "level": "H1",
      "text": "右侧。对于",
      "page": 99
    },
    {
      "level": "H1",
      "text": "，两组样本之间的距离",
      "page": 99
    },
    {
      "level": "H1",
      "text": "计算如下：",
      "page": 99
    },
    {
      "level": "H1",
      "text": "𝑑= 𝑆(ℱ",
      "page": 99
    },
    {
      "level": "H1",
      "text": ", ℱ",
      "page": 99
    },
    {
      "level": "H1",
      "text": ") + ∑",
      "page": 99
    },
    {
      "level": "H1",
      "text": "𝑆(ℱ",
      "page": 99
    },
    {
      "level": "H1",
      "text": "௝ୀଵ",
      "page": 99
    },
    {
      "level": "H1",
      "text": "௜ୀଵ",
      "page": 99
    },
    {
      "level": "H1",
      "text": "(11)",
      "page": 99
    },
    {
      "level": "H1",
      "text": "是两个特征向量之间的",
      "page": 99
    },
    {
      "level": "H1",
      "text": "距离。距离评估复杂度降低到",
      "page": 99
    },
    {
      "level": "H1",
      "text": "𝒪(5𝑛)",
      "page": 99
    },
    {
      "level": "H1",
      "text": "无参数姿势引导表示方案的图示。",
      "page": 99
    },
    {
      "level": "H1",
      "text": "分别是正面和轮廓面图像的权重之和。",
      "page": 99
    },
    {
      "level": "H1",
      "text": "Figure 5.6  Illustration of the parameter-free pose-guided representation scheme. The",
      "page": 99
    },
    {
      "level": "H1",
      "text": "are the sum of weights of frontal and profile face images respectively.",
      "page": 99
    },
    {
      "level": "H1",
      "text": "5.3.2",
      "page": 99
    },
    {
      "level": "H1",
      "text": "基于尺度学习的姿态引导表达",
      "page": 99
    },
    {
      "level": "H1",
      "text": "无需训练参数，但在测试阶段需要进行姿态检测，这会增加",
      "page": 99
    },
    {
      "level": "H1",
      "text": "处理时间。此外，仅使用正面或者侧面面部图像训练",
      "page": 99
    },
    {
      "level": "H1",
      "text": "，而非全部图像。为了",
      "page": 99
    },
    {
      "level": "H1",
      "text": "解决这些问题，设计了一种新的度量学习框架（",
      "page": 99
    },
    {
      "level": "H1",
      "text": "ML-PGR",
      "page": 99
    },
    {
      "level": "H1",
      "text": "）来对齐具有不同姿态",
      "page": 99
    },
    {
      "level": "H1",
      "text": "的集合中的图像。",
      "page": 99
    },
    {
      "level": "H1",
      "text": "在训练阶段，使用",
      "page": 99
    },
    {
      "level": "H1",
      "text": "IJB",
      "page": 99
    },
    {
      "level": "H1",
      "text": "系列数据集中的训练数据和度量学习优化目标来进一",
      "page": 99
    },
    {
      "level": "H1",
      "text": "步微调（",
      "page": 99
    },
    {
      "level": "H1",
      "text": "fine-tuning",
      "page": 99
    },
    {
      "level": "H1",
      "text": "。将样本分为正面，左面和右面三组，并分别计算它",
      "page": 99
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 100
    },
    {
      "level": "H1",
      "text": "们的平均中心",
      "page": 100
    },
    {
      "level": "H1",
      "text": ", 𝑐",
      "page": 100
    },
    {
      "level": "H1",
      "text": "。与中心损失",
      "page": 100
    },
    {
      "level": "H1",
      "text": "[135]",
      "page": 100
    },
    {
      "level": "H1",
      "text": "(N+M)-",
      "page": 100
    },
    {
      "level": "H1",
      "text": "元组簇损失",
      "page": 100
    },
    {
      "level": "H1",
      "text": "[67]",
      "page": 100
    },
    {
      "level": "H1",
      "text": "不同，我们不要",
      "page": 100
    },
    {
      "level": "H1",
      "text": "求样本接近其平均中心，因为这可能导致其多样性的丧失。在此，要求不同的姿",
      "page": 100
    },
    {
      "level": "H1",
      "text": "态组彼此远离分布，并且查询和候选对相同时相接近，不同时相远离。在训练阶",
      "page": 100
    },
    {
      "level": "H1",
      "text": "段同时优化交叉熵损失和以下损失函数：",
      "page": 100
    },
    {
      "level": "H1",
      "text": "௜ୀଵ",
      "page": 100
    },
    {
      "level": "H1",
      "text": "𝑎𝑥(𝛽−𝐷",
      "page": 100
    },
    {
      "level": "H1",
      "text": ", 0)",
      "page": 100
    },
    {
      "level": "H1",
      "text": "+ ∑",
      "page": 100
    },
    {
      "level": "H1",
      "text": "{(1 −𝑙)𝑑",
      "page": 100
    },
    {
      "level": "H1",
      "text": "+ 𝑙⋅𝑚𝑎𝑥(𝜙−𝑑",
      "page": 100
    },
    {
      "level": "H1",
      "text": "(12)",
      "page": 100
    },
    {
      "level": "H1",
      "text": "是如图",
      "page": 100
    },
    {
      "level": "H1",
      "text": "5.7",
      "page": 100
    },
    {
      "level": "H1",
      "text": "所示的各个质心之间的距离，β和φ是分别定义",
      "page": 100
    },
    {
      "level": "H1",
      "text": "不同姿态组和查询",
      "page": 100
    },
    {
      "level": "H1",
      "text": "候选对的阈值的两个超参数。如果查询和候选集是同一个人，",
      "page": 100
    },
    {
      "level": "H1",
      "text": "l = 0",
      "page": 100
    },
    {
      "level": "H1",
      "text": "，对于不同的身份，",
      "page": 100
    },
    {
      "level": "H1",
      "text": "l = 1",
      "page": 100
    },
    {
      "level": "H1",
      "text": "。如果查询和候选集中缺少某些姿态组，则相应",
      "page": 100
    },
    {
      "level": "H1",
      "text": "被设置为",
      "page": 100
    },
    {
      "level": "H1",
      "text": "CNN",
      "page": 100
    },
    {
      "level": "H1",
      "text": "会同时根据其身份和姿态在特征空间中分布图像。",
      "page": 100
    },
    {
      "level": "H1",
      "text": "交叉熵损失也可以推动不同身份的样本远离彼此分布。",
      "page": 100
    },
    {
      "level": "H1",
      "text": "基于度量学习的姿态引导表示方案的图示。左：训练阶段。右：测试阶段。使用",
      "page": 100
    },
    {
      "level": "H1",
      "text": "蓝色，绿色和红色分别表示正面，左面和右面的特征空间。图像通过",
      "page": 100
    },
    {
      "level": "H1",
      "text": "（蓝色箭头）映",
      "page": 100
    },
    {
      "level": "H1",
      "text": "射到黑点。在训练阶段（",
      "page": 100
    },
    {
      "level": "H1",
      "text": "）中，每个姿势组的平均中心（红点）通过相等权重的平均值",
      "page": 100
    },
    {
      "level": "H1",
      "text": "计算，而测试阶段的加权平均中心（红色圆圈）使用",
      "page": 100
    },
    {
      "level": "H1",
      "text": "DAC",
      "page": 100
    },
    {
      "level": "H1",
      "text": "分配的权重计算。",
      "page": 100
    },
    {
      "level": "H1",
      "text": "Figure 5.7 Illustration of the metric learning based pose-guided representation scheme.",
      "page": 100
    },
    {
      "level": "H1",
      "text": "Left: training stage. Right: testing stage. We use blue, green and red to represent the frontal,",
      "page": 100
    },
    {
      "level": "H1",
      "text": "left and right face’s feature space respectively. The images map the black points via CNN",
      "page": 100
    },
    {
      "level": "H1",
      "text": "(blue arrows). In training stage (a), the average centers (red points) of each pose group are",
      "page": 100
    },
    {
      "level": "H1",
      "text": "calculated by average with equal weights, while the weighted average centers (red circle) in",
      "page": 100
    },
    {
      "level": "H1",
      "text": "testing stage are calculated using the weights assigned by DAC.",
      "page": 100
    },
    {
      "level": "H1",
      "text": "可以在实际应用中预先计算图库样本的姿势组及其质心",
      "page": 100
    },
    {
      "level": "H1",
      "text": "。在测试阶段，使",
      "page": 100
    },
    {
      "level": "H1",
      "text": "（或视频的时间模型）计算图库集中的",
      "page": 100
    },
    {
      "level": "H1",
      "text": "。通过搜索不使用姿势检测的最",
      "page": 100
    },
    {
      "level": "H1",
      "text": "基于人脸图片集的身份识别",
      "page": 101
    },
    {
      "level": "H1",
      "text": "来定义每个探测图像的姿势组。然后，通过",
      "page": 101
    },
    {
      "level": "H1",
      "text": "DAC",
      "page": 101
    },
    {
      "level": "H1",
      "text": "或时间注意模型计算",
      "page": 101
    },
    {
      "level": "H1",
      "text": "候选对的相似性被定义为最小中心间距离。",
      "page": 101
    },
    {
      "level": "H1",
      "text": "5.4",
      "page": 101
    },
    {
      "level": "H1",
      "text": "IJB-A",
      "page": 101
    },
    {
      "level": "H1",
      "text": "[36]",
      "page": 101
    },
    {
      "level": "H1",
      "text": "[37]",
      "page": 101
    },
    {
      "level": "H1",
      "text": "[38]",
      "page": 101
    },
    {
      "level": "H1",
      "text": "系列，",
      "page": 101
    },
    {
      "level": "H1",
      "text": "YTF",
      "page": 101
    },
    {
      "level": "H1",
      "text": "[35]",
      "page": 101
    },
    {
      "level": "H1",
      "text": "Celebrity-1000",
      "page": 101
    },
    {
      "level": "H1",
      "text": "[218]",
      "page": 101
    },
    {
      "level": "H1",
      "text": "等多个基于图片集和",
      "page": 101
    },
    {
      "level": "H1",
      "text": "视频的人脸识别数据集上评估了所提出的方法。文献",
      "page": 101
    },
    {
      "level": "H1",
      "text": "[193]",
      "page": 101
    },
    {
      "level": "H1",
      "text": "利用数百万可用的静态",
      "page": 101
    },
    {
      "level": "H1",
      "text": "图像对",
      "page": 101
    },
    {
      "level": "H1",
      "text": "CNN",
      "page": 101
    },
    {
      "level": "H1",
      "text": "嵌入模块进行预训练。如同，使用联合级联人脸检测和对齐（",
      "page": 101
    },
    {
      "level": "H1",
      "text": "Joint",
      "page": 101
    },
    {
      "level": "H1",
      "text": "cascade face detection and alignment, JDA",
      "page": 101
    },
    {
      "level": "H1",
      "text": "[221]",
      "page": 101
    },
    {
      "level": "H1",
      "text": "检测来自",
      "page": 101
    },
    {
      "level": "H1",
      "text": "50K",
      "page": 101
    },
    {
      "level": "H1",
      "text": "个个体的三百万面部",
      "page": 101
    },
    {
      "level": "H1",
      "text": "图像，并使用局部二进制特征（",
      "page": 101
    },
    {
      "level": "H1",
      "text": "Local binary features, LBF",
      "page": 101
    },
    {
      "level": "H1",
      "text": "[222]",
      "page": 101
    },
    {
      "level": "H1",
      "text": "方法对",
      "page": 101
    },
    {
      "level": "H1",
      "text": "GoogleNet",
      "page": 101
    },
    {
      "level": "H1",
      "text": "预训练进行配准，并应用于",
      "page": 101
    },
    {
      "level": "H1",
      "text": "和名人",
      "page": 101
    },
    {
      "level": "H1",
      "text": "-1000",
      "page": 101
    },
    {
      "level": "H1",
      "text": "数据集。",
      "page": 101
    },
    {
      "level": "H1",
      "text": "ResNet",
      "page": 101
    },
    {
      "level": "H1",
      "text": "VGGFace2",
      "page": 101
    },
    {
      "level": "H1",
      "text": "上进行了预训练，并应用于",
      "page": 101
    },
    {
      "level": "H1",
      "text": "IJB-B",
      "page": 101
    },
    {
      "level": "H1",
      "text": "IJB-C",
      "page": 101
    },
    {
      "level": "H1",
      "text": "数据集。当在每个集",
      "page": 101
    },
    {
      "level": "H1",
      "text": "视频人脸数据集",
      "page": 101
    },
    {
      "level": "H1",
      "text": "上训练",
      "page": 101
    },
    {
      "level": "H1",
      "text": "模块时，此",
      "page": 101
    },
    {
      "level": "H1",
      "text": "嵌入部分的参数是保持固定的。得益于高度紧凑",
      "page": 101
    },
    {
      "level": "H1",
      "text": "128",
      "page": 101
    },
    {
      "level": "H1",
      "text": "维特征表示和",
      "page": 101
    },
    {
      "level": "H1",
      "text": "的简单神经网络，所采用的异策略",
      "page": 101
    },
    {
      "level": "H1",
      "text": "据集上使用单个",
      "page": 101
    },
    {
      "level": "H1",
      "text": "Xeon E5 v4 CPU",
      "page": 101
    },
    {
      "level": "H1",
      "text": "的训练时间约为",
      "page": 101
    },
    {
      "level": "H1",
      "text": "小时，平均测试时间对于每",
      "page": 101
    },
    {
      "level": "H1",
      "text": "个用于验证的集合对是",
      "page": 101
    },
    {
      "level": "H1",
      "text": "62 ms",
      "page": 101
    },
    {
      "level": "H1",
      "text": "。使用",
      "page": 101
    },
    {
      "level": "H1",
      "text": "Titan Xp",
      "page": 101
    },
    {
      "level": "H1",
      "text": "嵌入处理。根据验证集",
      "page": 101
    },
    {
      "level": "H1",
      "text": "上的表现调整在",
      "page": 101
    },
    {
      "level": "H1",
      "text": "分别设定为",
      "page": 101
    },
    {
      "level": "H1",
      "text": "0.1",
      "page": 101
    },
    {
      "level": "H1",
      "text": "0.12",
      "page": 101
    },
    {
      "level": "H1",
      "text": "设定为",
      "page": 101
    },
    {
      "level": "H1",
      "text": "作为基线方法，",
      "page": 101
    },
    {
      "level": "H1",
      "text": "CNN + Mean L2",
      "page": 101
    },
    {
      "level": "H1",
      "text": "测量两组所有图像对的平均",
      "page": 101
    },
    {
      "level": "H1",
      "text": "距离，而",
      "page": 101
    },
    {
      "level": "H1",
      "text": "CNN+AvePool",
      "page": 101
    },
    {
      "level": "H1",
      "text": "对每个特征维度进行的平均池化来聚合各向量。本章与",
      "page": 101
    },
    {
      "level": "H1",
      "text": "NAN",
      "page": 101
    },
    {
      "level": "H1",
      "text": "相同的",
      "page": 101
    },
    {
      "level": "H1",
      "text": "结构，但",
      "page": 101
    },
    {
      "level": "H1",
      "text": "采用神经网络模块对每个图像进行独立的质量评",
      "page": 101
    },
    {
      "level": "H1",
      "text": "估。因此，",
      "page": 101
    },
    {
      "level": "H1",
      "text": "也可以作为比较的基线。将标准",
      "page": 101
    },
    {
      "level": "H1",
      "text": "A2C",
      "page": 101
    },
    {
      "level": "H1",
      "text": "版本称为",
      "page": 101
    },
    {
      "level": "H1",
      "text": "），并",
      "page": 101
    },
    {
      "level": "H1",
      "text": "将具有基于信任区域的经验重放方案的演员",
      "page": 101
    },
    {
      "level": "H1",
      "text": "评论家算法版本称为",
      "page": 101
    },
    {
      "level": "H1",
      "text": "off",
      "page": 101
    },
    {
      "level": "H1",
      "text": "5.4.1",
      "page": 101
    },
    {
      "level": "H1",
      "text": "IJB-A/B/C",
      "page": 101
    },
    {
      "level": "H1",
      "text": "数据集的测试结果",
      "page": 101
    },
    {
      "level": "H1",
      "text": "数据集",
      "page": 101
    },
    {
      "level": "H1",
      "text": "作为不受约束的环境捕获的图像集，其姿势和成像条件变化",
      "page": 101
    },
    {
      "level": "H1",
      "text": "较大。其收集自",
      "page": 101
    },
    {
      "level": "H1",
      "text": "500",
      "page": 101
    },
    {
      "level": "H1",
      "text": "个个体，共有",
      "page": 101
    },
    {
      "level": "H1",
      "text": "25,813",
      "page": 101
    },
    {
      "level": "H1",
      "text": "张图像（",
      "page": 101
    },
    {
      "level": "H1",
      "text": "5,397",
      "page": 101
    },
    {
      "level": "H1",
      "text": "张静态图片和",
      "page": 101
    },
    {
      "level": "H1",
      "text": "20,412",
      "page": 101
    },
    {
      "level": "H1",
      "text": "视频帧，来自",
      "page": 101
    },
    {
      "level": "H1",
      "text": "2,042",
      "page": 101
    },
    {
      "level": "H1",
      "text": "个视频）。用于判断身份的一组图像称为模板（",
      "page": 101
    },
    {
      "level": "H1",
      "text": "template",
      "page": 101
    },
    {
      "level": "H1",
      "text": "）。每",
      "page": 101
    },
    {
      "level": "H1",
      "text": "个模板可以是静止图像和采样视频帧的混合。模板中的图像（或帧）数量范围为",
      "page": 101
    },
    {
      "level": "H1",
      "text": "190",
      "page": 101
    },
    {
      "level": "H1",
      "text": "个训练和测试划分进行十折交叉验证。每折包含",
      "page": 101
    },
    {
      "level": "H1",
      "text": "333",
      "page": 101
    },
    {
      "level": "H1",
      "text": "个训练和",
      "page": 101
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 102
    },
    {
      "level": "H1",
      "text": "167",
      "page": 102
    },
    {
      "level": "H1",
      "text": "个测试身份。",
      "page": 102
    },
    {
      "level": "H1",
      "text": "IJB-A",
      "page": 102
    },
    {
      "level": "H1",
      "text": "数据集",
      "page": 102
    },
    {
      "level": "H1",
      "text": "[36]",
      "page": 102
    },
    {
      "level": "H1",
      "text": "上的标准测试规范，将提出的框架与面部验证和识别任",
      "page": 102
    },
    {
      "level": "H1",
      "text": "务的现有方法进行比较。对于",
      "page": 102
    },
    {
      "level": "H1",
      "text": "的验证任务，",
      "page": 102
    },
    {
      "level": "H1",
      "text": "Receiver operating characteristics",
      "page": 102
    },
    {
      "level": "H1",
      "text": "ROC",
      "page": 102
    },
    {
      "level": "H1",
      "text": "）曲线如图",
      "page": 102
    },
    {
      "level": "H1",
      "text": "5.8",
      "page": 102
    },
    {
      "level": "H1",
      "text": "）所示。在表",
      "page": 102
    },
    {
      "level": "H1",
      "text": "5.1",
      "page": 102
    },
    {
      "level": "H1",
      "text": "中展示了",
      "page": 102
    },
    {
      "level": "H1",
      "text": "True accept rate",
      "page": 102
    },
    {
      "level": "H1",
      "text": "TAR",
      "page": 102
    },
    {
      "level": "H1",
      "text": "False positive rate",
      "page": 102
    },
    {
      "level": "H1",
      "text": "FAR",
      "page": 102
    },
    {
      "level": "H1",
      "text": "）的关系。对于",
      "page": 102
    },
    {
      "level": "H1",
      "text": "鉴别任务，",
      "page": 102
    },
    {
      "level": "H1",
      "text": "Cumulative Match",
      "page": 102
    },
    {
      "level": "H1",
      "text": "Characteristics",
      "page": 102
    },
    {
      "level": "H1",
      "text": "CMC",
      "page": 102
    },
    {
      "level": "H1",
      "text": "）所示。",
      "page": 102
    },
    {
      "level": "H1",
      "text": "Rank-",
      "page": 102
    },
    {
      "level": "H1",
      "text": "识别率被定义为在前",
      "page": 102
    },
    {
      "level": "H1",
      "text": "匹配中有真实匹配的百分比。表",
      "page": 102
    },
    {
      "level": "H1",
      "text": "还报告了",
      "page": 102
    },
    {
      "level": "H1",
      "text": "positive identification rate",
      "page": 102
    },
    {
      "level": "H1",
      "text": "TPIR",
      "page": 102
    },
    {
      "level": "H1",
      "text": "false positive identification rate",
      "page": 102
    },
    {
      "level": "H1",
      "text": "FPIR",
      "page": 102
    },
    {
      "level": "H1",
      "text": "）的关系以及",
      "page": 102
    },
    {
      "level": "H1",
      "text": "rank-1",
      "page": 102
    },
    {
      "level": "H1",
      "text": "准确度。",
      "page": 102
    },
    {
      "level": "H1",
      "text": "数据集上的性能评估。真实接受率（",
      "page": 102
    },
    {
      "level": "H1",
      "text": "假阳性率（",
      "page": 102
    },
    {
      "level": "H1",
      "text": "）用于人脸",
      "page": 102
    },
    {
      "level": "H1",
      "text": "验证。真阳性识别率（",
      "page": 102
    },
    {
      "level": "H1",
      "text": "）与假阳性识别率（",
      "page": 102
    },
    {
      "level": "H1",
      "text": "Rank-1",
      "page": 102
    },
    {
      "level": "H1",
      "text": "准确度的关系用于人脸",
      "page": 102
    },
    {
      "level": "H1",
      "text": "鉴别。",
      "page": 102
    },
    {
      "level": "H1",
      "text": "* sd",
      "page": 102
    },
    {
      "level": "H1",
      "text": "：标准差。",
      "page": 102
    },
    {
      "level": "H1",
      "text": "Table 5.1 Performance evaluation on the IJB-A dataset. For verification, the true accept",
      "page": 102
    },
    {
      "level": "H1",
      "text": "rates (TAR) vs. false positive rates (FAR) are reported. For identification, the true positive",
      "page": 102
    },
    {
      "level": "H1",
      "text": "identification rate (TPIR) vs. false positive identification rate (FPIR) and the Rank-1",
      "page": 102
    },
    {
      "level": "H1",
      "text": "accuracy are presented. *sd: standard derivation.",
      "page": 102
    },
    {
      "level": "H1",
      "text": "Method",
      "page": 102
    },
    {
      "level": "H1",
      "text": "FAR=0.01",
      "page": 102
    },
    {
      "level": "H1",
      "text": "FAR=0.1",
      "page": 102
    },
    {
      "level": "H1",
      "text": "FPIR=0.01",
      "page": 102
    },
    {
      "level": "H1",
      "text": "FPIR=0.1",
      "page": 102
    },
    {
      "level": "H1",
      "text": "DAC(off)&PF-",
      "page": 102
    },
    {
      "level": "H1",
      "text": "PGR",
      "page": 102
    },
    {
      "level": "H1",
      "text": "DAC(off)/RNN",
      "page": 102
    },
    {
      "level": "H1",
      "text": "&PF-PGR",
      "page": 102
    },
    {
      "level": "H1",
      "text": "DAC(off)/Temp",
      "page": 102
    },
    {
      "level": "H1",
      "text": "conv&PF-PGR",
      "page": 102
    },
    {
      "level": "H1",
      "text": "onv&ML-PGR",
      "page": 102
    },
    {
      "level": "H3",
      "text": "5.1  IJB-A",
      "page": 102
    },
    {
      "level": "H1",
      "text": "基于人脸图片集的身份识别",
      "page": 103
    },
    {
      "level": "H1",
      "text": "这些结果表明，与基线方法相比，本章所提出的方法的验证和鉴别性能都得",
      "page": 103
    },
    {
      "level": "H1",
      "text": "到了很大改善。增强学习网络对低质量和冗余图像具有良好的鲁棒性。",
      "page": 103
    },
    {
      "level": "H1",
      "text": "DAC",
      "page": 103
    },
    {
      "level": "H1",
      "text": "在大多数操作点上优于先前的方法，表明本章方法比不考虑集内依赖性的情况下",
      "page": 103
    },
    {
      "level": "H1",
      "text": "的加权特征更具辨别力。经验重播可以进一步帮助稳定训练并获得最先进的性能",
      "page": 103
    },
    {
      "level": "H1",
      "text": "表现。结合异策略",
      "page": 103
    },
    {
      "level": "H1",
      "text": "和姿势引导表示",
      "page": 103
    },
    {
      "level": "H1",
      "text": "PGR",
      "page": 103
    },
    {
      "level": "H1",
      "text": "方案也有助于最终结果。此外基于",
      "page": 103
    },
    {
      "level": "H1",
      "text": "RNN",
      "page": 103
    },
    {
      "level": "H1",
      "text": "的时间注意力机制在",
      "page": 103
    },
    {
      "level": "H1",
      "text": "rank-1",
      "page": 103
    },
    {
      "level": "H1",
      "text": "指标上与仅适用",
      "page": 103
    },
    {
      "level": "H1",
      "text": "类似，而时间卷积显着",
      "page": 103
    },
    {
      "level": "H1",
      "text": "地提高了",
      "page": 103
    },
    {
      "level": "H1",
      "text": "准确性。此外，通过对视频部分使用基于时间卷积的时序注意机",
      "page": 103
    },
    {
      "level": "H1",
      "text": "制也可以降低复杂性。",
      "page": 103
    },
    {
      "level": "H1",
      "text": "5.8",
      "page": 103
    },
    {
      "level": "H1",
      "text": "十折划分的",
      "page": 103
    },
    {
      "level": "H1",
      "text": "IJB-A",
      "page": 103
    },
    {
      "level": "H1",
      "text": "数据集上所提出的方法及其基线的平均",
      "page": 103
    },
    {
      "level": "H1",
      "text": "ROC",
      "page": 103
    },
    {
      "level": "H1",
      "text": "曲线（左）和",
      "page": 103
    },
    {
      "level": "H1",
      "text": "CMC",
      "page": 103
    },
    {
      "level": "H1",
      "text": "（右）曲线。",
      "page": 103
    },
    {
      "level": "H1",
      "text": "Figure 5.8 Average ROC (Left) and CMC (Right) curves of the proposed method and its",
      "page": 103
    },
    {
      "level": "H1",
      "text": "baselines on the IJB-A dataset over 10 splits.",
      "page": 103
    },
    {
      "level": "H1",
      "text": "数据集上微调",
      "page": 103
    },
    {
      "level": "H1",
      "text": "CNN",
      "page": 103
    },
    {
      "level": "H1",
      "text": "嵌入模块并不能有效提高性能，因为基于静态",
      "page": 103
    },
    {
      "level": "H1",
      "text": "图像的预训练数据集要大得多。使用时间卷积和基于度量学习的",
      "page": 103
    },
    {
      "level": "H1",
      "text": "，平均验证",
      "page": 103
    },
    {
      "level": "H1",
      "text": "时间从",
      "page": 103
    },
    {
      "level": "H1",
      "text": "62ms",
      "page": 103
    },
    {
      "level": "H1",
      "text": "减少到",
      "page": 103
    },
    {
      "level": "H1",
      "text": "48ms",
      "page": 103
    },
    {
      "level": "H1",
      "text": "（减少了",
      "page": 103
    },
    {
      "level": "H1",
      "text": "22.5",
      "page": 103
    },
    {
      "level": "H1",
      "text": "％）。与",
      "page": 103
    },
    {
      "level": "H1",
      "text": "[191],[193]",
      "page": 103
    },
    {
      "level": "H1",
      "text": "相比，",
      "page": 103
    },
    {
      "level": "H1",
      "text": "off",
      "page": 103
    },
    {
      "level": "H1",
      "text": "/ TempConv",
      "page": 103
    },
    {
      "level": "H1",
      "text": "ML-PGR",
      "page": 103
    },
    {
      "level": "H1",
      "text": "TAR(FAR=0.01)",
      "page": 103
    },
    {
      "level": "H1",
      "text": "FPIP(TPIP = 0.01)",
      "page": 103
    },
    {
      "level": "H1",
      "text": "等指标上实现了超过",
      "page": 103
    },
    {
      "level": "H1",
      "text": "4.8",
      "page": 103
    },
    {
      "level": "H1",
      "text": "％的提升。",
      "page": 103
    },
    {
      "level": "H1",
      "text": "进一步在",
      "page": 103
    },
    {
      "level": "H1",
      "text": "IJB-B",
      "page": 103
    },
    {
      "level": "H1",
      "text": "数据集上进行了测试。",
      "page": 103
    },
    {
      "level": "H1",
      "text": "数据集是",
      "page": 103
    },
    {
      "level": "H1",
      "text": "的扩展，它收",
      "page": 103
    },
    {
      "level": "H1",
      "text": "集了来自",
      "page": 103
    },
    {
      "level": "H1",
      "text": "1845",
      "page": 103
    },
    {
      "level": "H1",
      "text": "个个体的",
      "page": 103
    },
    {
      "level": "H1",
      "text": "7011",
      "page": 103
    },
    {
      "level": "H1",
      "text": "个视频，其中具有",
      "page": 103
    },
    {
      "level": "H1",
      "text": "21800",
      "page": 103
    },
    {
      "level": "H1",
      "text": "个静止图像和",
      "page": 103
    },
    {
      "level": "H1",
      "text": "55000",
      "page": 103
    },
    {
      "level": "H1",
      "text": "频帧。注意到该数据集上常用的骨干网络结构与先前数据库略有不同。选择",
      "page": 103
    },
    {
      "level": "H1",
      "text": "ResNet50",
      "page": 103
    },
    {
      "level": "H1",
      "text": "作为的",
      "page": 103
    },
    {
      "level": "H1",
      "text": "嵌入模型，并使用",
      "page": 103
    },
    {
      "level": "H1",
      "text": "VGGFace2",
      "page": 103
    },
    {
      "level": "H1",
      "text": "静态人脸数据集进行本实验",
      "page": 103
    },
    {
      "level": "H1",
      "text": "的预训练。与使用相同设置的相关工作在表",
      "page": 103
    },
    {
      "level": "H1",
      "text": "5.3",
      "page": 103
    },
    {
      "level": "H1",
      "text": "中进行了比较，在",
      "page": 103
    },
    {
      "level": "H1",
      "text": "FAR = 1E-5",
      "page": 103
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 104
    },
    {
      "level": "H1",
      "text": "TAR",
      "page": 104
    },
    {
      "level": "H1",
      "text": "指标的改善大于",
      "page": 104
    },
    {
      "level": "H1",
      "text": "4.9",
      "page": 104
    },
    {
      "level": "H1",
      "text": "％。如表",
      "page": 104
    },
    {
      "level": "H1",
      "text": "5.2",
      "page": 104
    },
    {
      "level": "H1",
      "text": "所示，本章方法在",
      "page": 104
    },
    {
      "level": "H1",
      "text": "Rank-1/5/10",
      "page": 104
    },
    {
      "level": "H1",
      "text": "识别准确",
      "page": 104
    },
    {
      "level": "H1",
      "text": "度等指标上明显优于以前的方法。与基于双向",
      "page": 104
    },
    {
      "level": "H1",
      "text": "LSTM",
      "page": 104
    },
    {
      "level": "H1",
      "text": "的图像生成方法",
      "page": 104
    },
    {
      "level": "H1",
      "text": "[196]",
      "page": 104
    },
    {
      "level": "H1",
      "text": "相比，",
      "page": 104
    },
    {
      "level": "H1",
      "text": "DAC",
      "page": 104
    },
    {
      "level": "H1",
      "text": "off",
      "page": 104
    },
    {
      "level": "H1",
      "text": "/ TempConv&ML-PGR",
      "page": 104
    },
    {
      "level": "H1",
      "text": "实现了",
      "page": 104
    },
    {
      "level": "H1",
      "text": "％的提升。",
      "page": 104
    },
    {
      "level": "H1",
      "text": "鉴别精度用于",
      "page": 104
    },
    {
      "level": "H1",
      "text": "IJB-B",
      "page": 104
    },
    {
      "level": "H1",
      "text": "数据集的性能评估。",
      "page": 104
    },
    {
      "level": "H1",
      "text": "Table 5.2  Performance evaluation on the IJB-B dataset. For identification, the Rank-N",
      "page": 104
    },
    {
      "level": "H1",
      "text": "accuracy are presented.",
      "page": 104
    },
    {
      "level": "H1",
      "text": "Method",
      "page": 104
    },
    {
      "level": "H1",
      "text": "Rank-1",
      "page": 104
    },
    {
      "level": "H1",
      "text": "Rank-5",
      "page": 104
    },
    {
      "level": "H1",
      "text": "Rank-10",
      "page": 104
    },
    {
      "level": "H1",
      "text": "数据集的性能评估。对于人脸验证使用真实接受率（",
      "page": 104
    },
    {
      "level": "H1",
      "text": "误报率",
      "page": 104
    },
    {
      "level": "H1",
      "text": "FAR",
      "page": 104
    },
    {
      "level": "H1",
      "text": "）指标。",
      "page": 104
    },
    {
      "level": "H1",
      "text": "Table 5.3  Performance evaluation on the IJB-B dataset. For verification, the true accept",
      "page": 104
    },
    {
      "level": "H1",
      "text": "rates (TAR) vs. false positive rates (FAR) are reported.",
      "page": 104
    },
    {
      "level": "H1",
      "text": "Cao",
      "page": 104
    },
    {
      "level": "H1",
      "text": "𝑒𝑡𝑎𝑙",
      "page": 104
    },
    {
      "level": "H1",
      "text": "[227]",
      "page": 104
    },
    {
      "level": "H1",
      "text": "0.734",
      "page": 104
    },
    {
      "level": "H1",
      "text": "0.825",
      "page": 104
    },
    {
      "level": "H1",
      "text": "0.900",
      "page": 104
    },
    {
      "level": "H1",
      "text": "0.950",
      "page": 104
    },
    {
      "level": "H1",
      "text": "0.980",
      "page": 104
    },
    {
      "level": "H1",
      "text": "[228]",
      "page": 104
    },
    {
      "level": "H1",
      "text": "0.771",
      "page": 104
    },
    {
      "level": "H1",
      "text": "0.862",
      "page": 104
    },
    {
      "level": "H1",
      "text": "0.927",
      "page": 104
    },
    {
      "level": "H1",
      "text": "0.968",
      "page": 104
    },
    {
      "level": "H1",
      "text": "0.989",
      "page": 104
    },
    {
      "level": "H1",
      "text": "[229]",
      "page": 104
    },
    {
      "level": "H1",
      "text": "0.841",
      "page": 104
    },
    {
      "level": "H1",
      "text": "0.930",
      "page": 104
    },
    {
      "level": "H1",
      "text": "0.972",
      "page": 104
    },
    {
      "level": "H1",
      "text": "0.995",
      "page": 104
    },
    {
      "level": "H1",
      "text": "DAC(off)",
      "page": 104
    },
    {
      "level": "H1",
      "text": "0.811",
      "page": 104
    },
    {
      "level": "H1",
      "text": "0.869",
      "page": 104
    },
    {
      "level": "H1",
      "text": "0.938",
      "page": 104
    },
    {
      "level": "H1",
      "text": "DAC(off)/Temp",
      "page": 104
    },
    {
      "level": "H1",
      "text": "Conv&PF-PGR",
      "page": 104
    },
    {
      "level": "H1",
      "text": "0.818",
      "page": 104
    },
    {
      "level": "H1",
      "text": "0.872",
      "page": 104
    },
    {
      "level": "H1",
      "text": "0.943",
      "page": 104
    },
    {
      "level": "H1",
      "text": "0.978",
      "page": 104
    },
    {
      "level": "H1",
      "text": "0.996",
      "page": 104
    },
    {
      "level": "H1",
      "text": "Conv&ML-PGR",
      "page": 104
    },
    {
      "level": "H1",
      "text": "0.820",
      "page": 104
    },
    {
      "level": "H1",
      "text": "0.874",
      "page": 104
    },
    {
      "level": "H1",
      "text": "0.944",
      "page": 104
    },
    {
      "level": "H1",
      "text": "IJB-C",
      "page": 104
    },
    {
      "level": "H1",
      "text": "数据集进一步扩展了",
      "page": 104
    },
    {
      "level": "H1",
      "text": "，其来自",
      "page": 104
    },
    {
      "level": "H1",
      "text": "3531",
      "page": 104
    },
    {
      "level": "H1",
      "text": "个个体，包括",
      "page": 104
    },
    {
      "level": "H1",
      "text": "31300",
      "page": 104
    },
    {
      "level": "H1",
      "text": "个静止",
      "page": 104
    },
    {
      "level": "H1",
      "text": "图像和",
      "page": 104
    },
    {
      "level": "H1",
      "text": "11779",
      "page": 104
    },
    {
      "level": "H1",
      "text": "个视频的",
      "page": 104
    },
    {
      "level": "H1",
      "text": "117500",
      "page": 104
    },
    {
      "level": "H1",
      "text": "个帧。在其标准验证设置中，有",
      "page": 104
    },
    {
      "level": "H1",
      "text": "23124",
      "page": 104
    },
    {
      "level": "H1",
      "text": "个模板，",
      "page": 104
    },
    {
      "level": "H1",
      "text": "15639K",
      "page": 104
    },
    {
      "level": "H1",
      "text": "不同个体的匹配和",
      "page": 104
    },
    {
      "level": "H1",
      "text": "19557",
      "page": 104
    },
    {
      "level": "H1",
      "text": "个相同个体的匹配。也选择",
      "page": 104
    },
    {
      "level": "H1",
      "text": "ResNet50",
      "page": 104
    },
    {
      "level": "H1",
      "text": "CNN",
      "page": 104
    },
    {
      "level": "H1",
      "text": "的骨干网络，并使用",
      "page": 104
    },
    {
      "level": "H1",
      "text": "VGGFace2",
      "page": 104
    },
    {
      "level": "H1",
      "text": "进行预训练。结果如表",
      "page": 104
    },
    {
      "level": "H1",
      "text": "5.4",
      "page": 104
    },
    {
      "level": "H1",
      "text": "所示。",
      "page": 104
    },
    {
      "level": "H1",
      "text": "TempConv&ML-PGR",
      "page": 104
    },
    {
      "level": "H1",
      "text": "的性能在",
      "page": 104
    },
    {
      "level": "H1",
      "text": "FAR = 1E-5",
      "page": 104
    },
    {
      "level": "H1",
      "text": "）指标上优于文献",
      "page": 104
    },
    {
      "level": "H1",
      "text": "6.4",
      "page": 104
    },
    {
      "level": "H3",
      "text": "5.2  Rank-N",
      "page": 104
    },
    {
      "level": "H3",
      "text": "5.3  IJB-B",
      "page": 104
    },
    {
      "level": "H1",
      "text": "基于人脸图片集的身份识别",
      "page": 105
    },
    {
      "level": "H1",
      "text": "数据集的性能评估。对于人脸验证使用真实接受率（",
      "page": 105
    },
    {
      "level": "H1",
      "text": "TAR",
      "page": 105
    },
    {
      "level": "H1",
      "text": "误报率",
      "page": 105
    },
    {
      "level": "H1",
      "text": "FAR",
      "page": 105
    },
    {
      "level": "H1",
      "text": "）指标。",
      "page": 105
    },
    {
      "level": "H1",
      "text": "Table 5.4 Performance evaluation on the IJB-C dataset. For verification, the true accept",
      "page": 105
    },
    {
      "level": "H1",
      "text": "rates (TAR) vs. false positive rates (FAR) are reported.",
      "page": 105
    },
    {
      "level": "H1",
      "text": "Cao",
      "page": 105
    },
    {
      "level": "H1",
      "text": "𝑒𝑡𝑎𝑙",
      "page": 105
    },
    {
      "level": "H1",
      "text": "[227]",
      "page": 105
    },
    {
      "level": "H1",
      "text": "0.647",
      "page": 105
    },
    {
      "level": "H1",
      "text": "0.784",
      "page": 105
    },
    {
      "level": "H1",
      "text": "0.878",
      "page": 105
    },
    {
      "level": "H1",
      "text": "0.938",
      "page": 105
    },
    {
      "level": "H1",
      "text": "0.975",
      "page": 105
    },
    {
      "level": "H1",
      "text": "[228]",
      "page": 105
    },
    {
      "level": "H1",
      "text": "0.708",
      "page": 105
    },
    {
      "level": "H1",
      "text": "0.831",
      "page": 105
    },
    {
      "level": "H1",
      "text": "0.909",
      "page": 105
    },
    {
      "level": "H1",
      "text": "0.958",
      "page": 105
    },
    {
      "level": "H1",
      "text": "0.985",
      "page": 105
    },
    {
      "level": "H1",
      "text": "[229]",
      "page": 105
    },
    {
      "level": "H1",
      "text": "0.880",
      "page": 105
    },
    {
      "level": "H1",
      "text": "0.944",
      "page": 105
    },
    {
      "level": "H1",
      "text": "0.981",
      "page": 105
    },
    {
      "level": "H1",
      "text": "0.998",
      "page": 105
    },
    {
      "level": "H1",
      "text": "DAC(off)",
      "page": 105
    },
    {
      "level": "H1",
      "text": "0.754",
      "page": 105
    },
    {
      "level": "H1",
      "text": "0.882",
      "page": 105
    },
    {
      "level": "H1",
      "text": "DAC(off)/Temp",
      "page": 105
    },
    {
      "level": "H1",
      "text": "Conv&PF-PGR",
      "page": 105
    },
    {
      "level": "H1",
      "text": "0.768",
      "page": 105
    },
    {
      "level": "H1",
      "text": "0.885",
      "page": 105
    },
    {
      "level": "H1",
      "text": "0.960",
      "page": 105
    },
    {
      "level": "H1",
      "text": "0.999",
      "page": 105
    },
    {
      "level": "H1",
      "text": "Conv&ML-PGR",
      "page": 105
    },
    {
      "level": "H1",
      "text": "0.772",
      "page": 105
    },
    {
      "level": "H1",
      "text": "0.886",
      "page": 105
    },
    {
      "level": "H1",
      "text": "0.986",
      "page": 105
    },
    {
      "level": "H1",
      "text": "5.4.2",
      "page": 105
    },
    {
      "level": "H1",
      "text": "YouTube Face",
      "page": 105
    },
    {
      "level": "H1",
      "text": "数据集的测试结果",
      "page": 105
    },
    {
      "level": "H1",
      "text": "YTF",
      "page": 105
    },
    {
      "level": "H1",
      "text": "[35]",
      "page": 105
    },
    {
      "level": "H1",
      "text": "数据集是一个广泛使用的视频面部验证数据集，其",
      "page": 105
    },
    {
      "level": "H1",
      "text": "中包含",
      "page": 105
    },
    {
      "level": "H1",
      "text": "3,425",
      "page": 105
    },
    {
      "level": "H1",
      "text": "个不同个体的",
      "page": 105
    },
    {
      "level": "H1",
      "text": "个视频。该视频数据集包含许多具有挑战性的",
      "page": 105
    },
    {
      "level": "H1",
      "text": "因素，包括业余摄影，遮挡，有问题的照明，姿势和运动模糊。此数据集中面部",
      "page": 105
    },
    {
      "level": "H1",
      "text": "视频的长度从",
      "page": 105
    },
    {
      "level": "H1",
      "text": "6,070",
      "page": 105
    },
    {
      "level": "H1",
      "text": "帧不等，视频的平均长度为",
      "page": 105
    },
    {
      "level": "H1",
      "text": "181.3",
      "page": 105
    },
    {
      "level": "H1",
      "text": "帧。在实验中，遵循",
      "page": 105
    },
    {
      "level": "H1",
      "text": "其标准测试规范，使用其中给定的",
      "page": 105
    },
    {
      "level": "H1",
      "text": "5,000",
      "page": 105
    },
    {
      "level": "H1",
      "text": "个视频对测试无约束人脸",
      "page": 105
    },
    {
      "level": "H1",
      "text": "验证方",
      "page": 105
    },
    {
      "level": "H1",
      "text": "法。这些对进行十折划分，每折有大约",
      "page": 105
    },
    {
      "level": "H1",
      "text": "250",
      "page": 105
    },
    {
      "level": "H1",
      "text": "个同属一个人的视频对和",
      "page": 105
    },
    {
      "level": "H1",
      "text": "个不同",
      "page": 105
    },
    {
      "level": "H1",
      "text": "个体的视频对。",
      "page": 105
    },
    {
      "level": "H1",
      "text": "5.5",
      "page": 105
    },
    {
      "level": "H1",
      "text": "列出了本章提出的的",
      "page": 105
    },
    {
      "level": "H1",
      "text": "DAC",
      "page": 105
    },
    {
      "level": "H1",
      "text": "方法和以前的方法的对比结果。可以看出，",
      "page": 105
    },
    {
      "level": "H1",
      "text": "优于所有先前的最先进方法，而无需在",
      "page": 105
    },
    {
      "level": "H1",
      "text": "上微调",
      "page": 105
    },
    {
      "level": "H1",
      "text": "CNN",
      "page": 105
    },
    {
      "level": "H1",
      "text": "特征嵌入模块。",
      "page": 105
    },
    {
      "level": "H1",
      "text": "由于该数据集中的正面样本较多并且面部变化相对较小，因此没有使用姿势引导",
      "page": 105
    },
    {
      "level": "H1",
      "text": "的表示方案。很明显，视频序列是有较大冗余的，对视频内部关系进行考虑确实",
      "page": 105
    },
    {
      "level": "H1",
      "text": "有助于效果改进。与基于时间表示的方法相当的性能表明，在某些特定领域，",
      "page": 105
    },
    {
      "level": "H1",
      "text": "可能是",
      "page": 105
    },
    {
      "level": "H1",
      "text": "RNN",
      "page": 105
    },
    {
      "level": "H1",
      "text": "的潜在替代品。实际上，",
      "page": 105
    },
    {
      "level": "H1",
      "text": "本身在计算上较为复杂，有时较难以",
      "page": 105
    },
    {
      "level": "H1",
      "text": "训练。",
      "page": 105
    },
    {
      "level": "H1",
      "text": "直接模拟特征级别的依赖性，这比基于双向",
      "page": 105
    },
    {
      "level": "H1",
      "text": "LSTM",
      "page": 105
    },
    {
      "level": "H1",
      "text": "的模型（例如",
      "page": 105
    },
    {
      "level": "H1",
      "text": "基线）更快，并且比基于正面面部生成作为与处理的方法更有效。同时也证明了",
      "page": 105
    },
    {
      "level": "H1",
      "text": "时间卷积在视频识别任务中也很有前景。",
      "page": 105
    },
    {
      "level": "H3",
      "text": "5.4  IJB-C",
      "page": 105
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 106
    },
    {
      "level": "H1",
      "text": "数据集上平均验证准确度的比较。",
      "page": 106
    },
    {
      "level": "H1",
      "text": "YTF",
      "page": 106
    },
    {
      "level": "H1",
      "text": "CNN",
      "page": 106
    },
    {
      "level": "H1",
      "text": "模型。最好的结果用",
      "page": 106
    },
    {
      "level": "H1",
      "text": "粗体标出，第二好的结果用下划线标出。",
      "page": 106
    },
    {
      "level": "H1",
      "text": "Table 5.5  Comparisons of the average verification accuracy with the recently state-of-the-",
      "page": 106
    },
    {
      "level": "H1",
      "text": "art results on the YTF dataset.",
      "page": 106
    },
    {
      "level": "H1",
      "text": "fine-tuned the CNN model with YTF. The best results are",
      "page": 106
    },
    {
      "level": "H1",
      "text": "bolded, and the second best results are underlined.",
      "page": 106
    },
    {
      "level": "H1",
      "text": "Deep FR",
      "page": 106
    },
    {
      "level": "H1",
      "text": "[132]",
      "page": 106
    },
    {
      "level": "H1",
      "text": "0.915",
      "page": 106
    },
    {
      "level": "H1",
      "text": "0.973",
      "page": 106
    },
    {
      "level": "H1",
      "text": "DAC(on)",
      "page": 106
    },
    {
      "level": "H1",
      "text": "0.9597",
      "page": 106
    },
    {
      "level": "H1",
      "text": "0.0041",
      "page": 106
    },
    {
      "level": "H1",
      "text": "DAC(off)",
      "page": 106
    },
    {
      "level": "H1",
      "text": "RNN",
      "page": 106
    },
    {
      "level": "H1",
      "text": "0.9530",
      "page": 106
    },
    {
      "level": "H1",
      "text": "0.0040",
      "page": 106
    },
    {
      "level": "H1",
      "text": "TempConv",
      "page": 106
    },
    {
      "level": "H1",
      "text": "0.9680",
      "page": 106
    },
    {
      "level": "H1",
      "text": "0.0038",
      "page": 106
    },
    {
      "level": "H1",
      "text": "结果也表明，即使没有特意设计",
      "page": 106
    },
    {
      "level": "H1",
      "text": "嵌入模型，",
      "page": 106
    },
    {
      "level": "H1",
      "text": "DAC",
      "page": 106
    },
    {
      "level": "H1",
      "text": "也可以实现极具竞争",
      "page": 106
    },
    {
      "level": "H1",
      "text": "力的性能。请注意，",
      "page": 106
    },
    {
      "level": "H1",
      "text": "FaceNet",
      "page": 106
    },
    {
      "level": "H1",
      "text": "NAN",
      "page": 106
    },
    {
      "level": "H1",
      "text": "也使用",
      "page": 106
    },
    {
      "level": "H1",
      "text": "GoogleNet",
      "page": 106
    },
    {
      "level": "H1",
      "text": "样式结构。",
      "page": 106
    },
    {
      "level": "H1",
      "text": "TBE-",
      "page": 106
    },
    {
      "level": "H1",
      "text": "方法使用了",
      "page": 106
    },
    {
      "level": "H1",
      "text": "数据集对",
      "page": 106
    },
    {
      "level": "H1",
      "text": "嵌入模型进行额外的微调，并且在",
      "page": 106
    },
    {
      "level": "H1",
      "text": "中使用了更为先进的残差网络",
      "page": 106
    },
    {
      "level": "H1",
      "text": "[31]",
      "page": 106
    },
    {
      "level": "H1",
      "text": "。考虑到基于模块的结构，这些先进的",
      "page": 106
    },
    {
      "level": "H1",
      "text": "可以很容易地添加到",
      "page": 106
    },
    {
      "level": "H1",
      "text": "上并提高其性能。",
      "page": 106
    },
    {
      "level": "H1",
      "text": "可以在基于视频的面部验证数",
      "page": 106
    },
    {
      "level": "H1",
      "text": "据集中也有较好的适应性。",
      "page": 106
    },
    {
      "level": "H1",
      "text": "5.4.3",
      "page": 106
    },
    {
      "level": "H1",
      "text": "Celebrity-1000",
      "page": 106
    },
    {
      "level": "H1",
      "text": "数据集的测试结果",
      "page": 106
    },
    {
      "level": "H1",
      "text": "最后在",
      "page": 106
    },
    {
      "level": "H1",
      "text": "[218]",
      "page": 106
    },
    {
      "level": "H1",
      "text": "数据集上测试了本章提出的方法，该数据集专为无",
      "page": 106
    },
    {
      "level": "H1",
      "text": "约束的基于视频的人脸识别问题而设计。此数据集中包含来自",
      "page": 106
    },
    {
      "level": "H1",
      "text": "159,726",
      "page": 106
    },
    {
      "level": "H1",
      "text": "个面部视",
      "page": 106
    },
    {
      "level": "H1",
      "text": "频（每个序列约",
      "page": 106
    },
    {
      "level": "H1",
      "text": "个帧）的两百四十万帧，包含",
      "page": 106
    },
    {
      "level": "H1",
      "text": "1,000",
      "page": 106
    },
    {
      "level": "H1",
      "text": "个个体。它有两种标准测",
      "page": 106
    },
    {
      "level": "H1",
      "text": "试流程，即开集（",
      "page": 106
    },
    {
      "level": "H1",
      "text": "open-set",
      "page": 106
    },
    {
      "level": "H1",
      "text": "）和闭集（",
      "page": 106
    },
    {
      "level": "H1",
      "text": "closed-set",
      "page": 106
    },
    {
      "level": "H1",
      "text": "）。遵循标准的",
      "page": 106
    },
    {
      "level": "H1",
      "text": "鉴别设置，",
      "page": 106
    },
    {
      "level": "H1",
      "text": "并报告两种测试的结果。",
      "page": 106
    },
    {
      "level": "H1",
      "text": "对于闭集测试，使用来自奖励网络（",
      "page": 106
    },
    {
      "level": "H1",
      "text": "reward network",
      "page": 106
    },
    {
      "level": "H1",
      "text": "softmax",
      "page": 106
    },
    {
      "level": "H1",
      "text": "输出，并选",
      "page": 106
    },
    {
      "level": "H1",
      "text": "择具有最大分数的类别作为结果。由于基线方法只有特征向量输出而没有多类预",
      "page": 106
    },
    {
      "level": "H3",
      "text": "5.5  YTF",
      "page": 106
    },
    {
      "level": "H1",
      "text": "基于人脸图片集的身份识别",
      "page": 107
    },
    {
      "level": "H1",
      "text": "测单元，再次采用",
      "page": 107
    },
    {
      "level": "H1",
      "text": "[193]",
      "page": 107
    },
    {
      "level": "H1",
      "text": "中的方法进行比较。结果展示于表",
      "page": 107
    },
    {
      "level": "H1",
      "text": "5.6",
      "page": 107
    },
    {
      "level": "H1",
      "text": "以及图",
      "page": 107
    },
    {
      "level": "H1",
      "text": "5.9",
      "page": 107
    },
    {
      "level": "H1",
      "text": "）中的",
      "page": 107
    },
    {
      "level": "H1",
      "text": "CMC",
      "page": 107
    },
    {
      "level": "H1",
      "text": "曲线中。在",
      "page": 107
    },
    {
      "level": "H1",
      "text": "CNN",
      "page": 107
    },
    {
      "level": "H1",
      "text": "模型的端到端学习和大量训练数据的帮助下，深度学习方",
      "page": 107
    },
    {
      "level": "H1",
      "text": "法的表现远远超过了传统方法",
      "page": 107
    },
    {
      "level": "H1",
      "text": "[218],[232]",
      "page": 107
    },
    {
      "level": "H1",
      "text": "。可以看出，",
      "page": 107
    },
    {
      "level": "H1",
      "text": "DAC",
      "page": 107
    },
    {
      "level": "H1",
      "text": "与双向",
      "page": 107
    },
    {
      "level": "H1",
      "text": "LSTM",
      "page": 107
    },
    {
      "level": "H1",
      "text": "相当或更",
      "page": 107
    },
    {
      "level": "H1",
      "text": "好，而时间卷积通常在基于视频的任务中具有最佳性能。",
      "page": 107
    },
    {
      "level": "H1",
      "text": "对于封闭集测试，",
      "page": 107
    },
    {
      "level": "H1",
      "text": "Celebrity-1000",
      "page": 107
    },
    {
      "level": "H1",
      "text": "数据集的",
      "page": 107
    },
    {
      "level": "H1",
      "text": "Rank-1",
      "page": 107
    },
    {
      "level": "H1",
      "text": "识别精度。最好的结果用粗体",
      "page": 107
    },
    {
      "level": "H1",
      "text": "标出，第二好的结果用下划线标出。",
      "page": 107
    },
    {
      "level": "H1",
      "text": "Table 5.6  Rank-1 identification accuracies on the Celebrity-1000 dataset for closed-set",
      "page": 107
    },
    {
      "level": "H1",
      "text": "tests. The best results are bolded, and the second best results are underlined.",
      "page": 107
    },
    {
      "level": "H1",
      "text": "Method",
      "page": 107
    },
    {
      "level": "H1",
      "text": "100",
      "page": 107
    },
    {
      "level": "H1",
      "text": "200",
      "page": 107
    },
    {
      "level": "H1",
      "text": "500",
      "page": 107
    },
    {
      "level": "H1",
      "text": "1000",
      "page": 107
    },
    {
      "level": "H1",
      "text": "MTJSR",
      "page": 107
    },
    {
      "level": "H1",
      "text": "[218]",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.506",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.408",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.3546",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.3004",
      "page": 107
    },
    {
      "level": "H1",
      "text": "Eigen-PEP",
      "page": 107
    },
    {
      "level": "H1",
      "text": "[232]",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.4502",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.3997",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.3194",
      "page": 107
    },
    {
      "level": "H1",
      "text": "CNN+Mean L2",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.8526",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.7759",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.7457",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.6791",
      "page": 107
    },
    {
      "level": "H1",
      "text": "CNN+AvePool",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.8446",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.7893",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.7768",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.7341",
      "page": 107
    },
    {
      "level": "H1",
      "text": "NAN",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.9044",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.8333",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.8227",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.7717",
      "page": 107
    },
    {
      "level": "H1",
      "text": "DAC(on)",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.9125",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.8722",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.8475",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.8278",
      "page": 107
    },
    {
      "level": "H1",
      "text": "DAC(off)",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.9137",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.8783",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.8523",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.8353",
      "page": 107
    },
    {
      "level": "H1",
      "text": "RNN",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.9082",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.8642",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.8265",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.7863",
      "page": 107
    },
    {
      "level": "H1",
      "text": "TempConv",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.9160",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.8815",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.8661",
      "page": 107
    },
    {
      "level": "H1",
      "text": "5.7",
      "page": 107
    },
    {
      "level": "H1",
      "text": "对于开集测试，",
      "page": 107
    },
    {
      "level": "H1",
      "text": "识别精度。最好的结果用粗体标",
      "page": 107
    },
    {
      "level": "H1",
      "text": "出，第二好的结果用下划线标出。",
      "page": 107
    },
    {
      "level": "H1",
      "text": "Table 5.7  Rank-1 identification accuracies on the Celebrity-1000 dataset for open-set tests.",
      "page": 107
    },
    {
      "level": "H1",
      "text": "The best results are bolded, and the second best results are underlined.",
      "page": 107
    },
    {
      "level": "H1",
      "text": "800",
      "page": 107
    },
    {
      "level": "H1",
      "text": "MTJSR[218]",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.4612",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.3984",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.3751",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.3350",
      "page": 107
    },
    {
      "level": "H1",
      "text": "Eigen-PEP[232]",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.5155",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.4615",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.4233",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.2590",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.8488",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.7988",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.7676",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.7067",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.8411",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.7909",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.7840",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.7512",
      "page": 107
    },
    {
      "level": "H1",
      "text": "NAN[193]",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.8876",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.8521",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.8274",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.7987",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.8986",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.8706",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.8395",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.8205",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.9004",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.8715",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.8428",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.8264",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.8913",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.8332",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.8042",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.8810",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.8613",
      "page": 107
    },
    {
      "level": "H1",
      "text": "0.8405",
      "page": 107
    },
    {
      "level": "H1",
      "text": "基于深度学习的人脸图像识别技术的研究",
      "page": 108
    },
    {
      "level": "H1",
      "text": "对于开集测试，如",
      "page": 108
    },
    {
      "level": "H1",
      "text": "NAN",
      "page": 108
    },
    {
      "level": "H1",
      "text": "对每个图像序列提取一个高度紧凑的特征表示。然",
      "page": 108
    },
    {
      "level": "H1",
      "text": "后通过比较",
      "page": 108
    },
    {
      "level": "H1",
      "text": "距离来进行开集鉴别。图",
      "page": 108
    },
    {
      "level": "H1",
      "text": "5.9",
      "page": 108
    },
    {
      "level": "H1",
      "text": "）和表",
      "page": 108
    },
    {
      "level": "H1",
      "text": "5.7",
      "page": 108
    },
    {
      "level": "H1",
      "text": "展示了实验中不同方",
      "page": 108
    },
    {
      "level": "H1",
      "text": "法的结果。可以看到本章提出的方法优于以前的方法，这清楚地表明",
      "page": 108
    },
    {
      "level": "H1",
      "text": "DAC",
      "page": 108
    },
    {
      "level": "H1",
      "text": "效且稳健的。",
      "page": 108
    },
    {
      "level": "H1",
      "text": "上不同方法的",
      "page": 108
    },
    {
      "level": "H1",
      "text": "CMC",
      "page": 108
    },
    {
      "level": "H1",
      "text": "曲线。（",
      "page": 108
    },
    {
      "level": "H1",
      "text": "1000",
      "page": 108
    },
    {
      "level": "H1",
      "text": "名受试者进行闭集测试，",
      "page": 108
    },
    {
      "level": "H1",
      "text": "800",
      "page": 108
    },
    {
      "level": "H1",
      "text": "名受试者进行开集测试。",
      "page": 108
    },
    {
      "level": "H1",
      "text": "Figure 5.9 The CMC curves of different methods on Celebrity1000. (a) Close-set tests on",
      "page": 108
    },
    {
      "level": "H1",
      "text": "1000 subjects, (b) Open-set tests on 800 subjects.",
      "page": 108
    },
    {
      "level": "H1",
      "text": "5.10",
      "page": 108
    },
    {
      "level": "H1",
      "text": "IJB-A",
      "page": 108
    },
    {
      "level": "H1",
      "text": "YTF",
      "page": 108
    },
    {
      "level": "H1",
      "text": "Celebrity-1000",
      "page": 108
    },
    {
      "level": "H1",
      "text": "数据集的性能比较。较大的奖励表",
      "page": 108
    },
    {
      "level": "H1",
      "text": "示训练结果越好结果。阴影区域表示",
      "page": 108
    },
    {
      "level": "H1",
      "text": "个随机种子的标准差。",
      "page": 108
    },
    {
      "level": "H1",
      "text": "Figure 5.10 Performance comparison on (a) IJB-A, (b) YTF, and (c) Celebrity-1000 datasets.",
      "page": 108
    },
    {
      "level": "H1",
      "text": "The larger episode rewards, the better training results. The shaded region denotes the",
      "page": 108
    },
    {
      "level": "H1",
      "text": "standard deviation over 3 random seeds.",
      "page": 108
    },
    {
      "level": "H1",
      "text": "在三个实验中从深度强化学习角度展示了",
      "page": 108
    },
    {
      "level": "H1",
      "text": "off",
      "page": 108
    },
    {
      "level": "H1",
      "text": "）的性能",
      "page": 108
    },
    {
      "level": "H1",
      "text": "比较。另外，我们将动作空间二值化，这意味着图片集中的每个图像仅有两种操",
      "page": 108
    },
    {
      "level": "H3",
      "text": "5.9  Celebrity1000",
      "page": 108
    },
    {
      "level": "H1",
      "text": "基于人脸图片集的身份识别",
      "page": 109
    },
    {
      "level": "H1",
      "text": "作选择，即丢弃（",
      "page": 109
    },
    {
      "level": "H1",
      "text": "= 0",
      "page": 109
    },
    {
      "level": "H1",
      "text": "）和保留（",
      "page": 109
    },
    {
      "level": "H1",
      "text": "= 1",
      "page": 109
    },
    {
      "level": "H1",
      "text": "）。此设置类似于基于",
      "page": 109
    },
    {
      "level": "H1",
      "text": "学习的高效方",
      "page": 109
    },
    {
      "level": "H1",
      "text": "法。图",
      "page": 109
    },
    {
      "level": "H1",
      "text": "5.10",
      "page": 109
    },
    {
      "level": "H1",
      "text": "展示了每种方法的奖励。对于良好的学习算法，有较高的奖励。可以",
      "page": 109
    },
    {
      "level": "H1",
      "text": "看到，连续动作空间在几乎所有识别任务中都优于离散基线。异策略演员",
      "page": 109
    },
    {
      "level": "H1",
      "text": "员模型可以进一步实现更高的奖励和更稳定的收敛结果。",
      "page": 109
    },
    {
      "level": "H1",
      "text": "DAC",
      "page": 109
    },
    {
      "level": "H1",
      "text": "对于集合和视频",
      "page": 109
    },
    {
      "level": "H1",
      "text": "人脸识别数据集中具有的挑战性的姿势，表情和成像条件较为稳健。",
      "page": 109
    },
    {
      "level": "H1",
      "text": "5.5",
      "page": 109
    },
    {
      "level": "H1",
      "text": "本章小结",
      "page": 109
    },
    {
      "level": "H1",
      "text": "本章为视觉识别问题引入了演员评论强化学习（",
      "page": 109
    },
    {
      "level": "H1",
      "text": "）。将内部依赖性建模转",
      "page": 109
    },
    {
      "level": "H1",
      "text": "换为马尔可夫决策过程（",
      "page": 109
    },
    {
      "level": "H1",
      "text": "MDP",
      "page": 109
    },
    {
      "level": "H1",
      "text": "），并训练代理",
      "page": 109
    },
    {
      "level": "H1",
      "text": "以实现在每个步骤中对每个",
      "page": 109
    },
    {
      "level": "H1",
      "text": "图像进行注意力控制。时序注意力机制可以很容易地与",
      "page": 109
    },
    {
      "level": "H1",
      "text": "结合起来。基于参",
      "page": 109
    },
    {
      "level": "H1",
      "text": "数的度量和基于度量学习的",
      "page": 109
    },
    {
      "level": "H1",
      "text": "PGR",
      "page": 109
    },
    {
      "level": "H1",
      "text": "方案很好地平衡了计算成本和补充信息利用。",
      "page": 109
    },
    {
      "level": "H1",
      "text": "在未来，计划进一步开发更强大的",
      "page": 109
    },
    {
      "level": "H1",
      "text": "算法，并随后自适应地学习度量学习中的",
      "page": 109
    },
    {
      "level": "H1",
      "text": "阈值。虽然本章只是探索他们在基于集合",
      "page": 109
    },
    {
      "level": "H1",
      "text": "视频的人脸识别任务中的能力，但其是",
      "page": 109
    },
    {
      "level": "H1",
      "text": "一种通用且实用的方法，可以很容易地应用于其他问题，例如",
      "page": 109
    },
    {
      "level": "H1",
      "text": "Person Re-ID",
      "page": 109
    },
    {
      "level": "H1",
      "text": "作识别和事件检测等应用。",
      "page": 109
    },
    {
      "level": "H1",
      "text": "总结与展望",
      "page": 110
    },
    {
      "level": "H1",
      "text": "近年来随着计算机技术与人工智能算法的飞速发展，理解图像并提取与特定",
      "page": 110
    },
    {
      "level": "H1",
      "text": "任务相关的信息在大量应用中起到了重要作用。人脸中蕴含了丰富的身份以及表",
      "page": 110
    },
    {
      "level": "H1",
      "text": "情等信息，具有较大的研究价值。目前而言，基于人脸的安防系统是深度学习最",
      "page": 110
    },
    {
      "level": "H1",
      "text": "先落地的应用方向，而随着人机交互逐步被工业界重视，表情识别也吸引了大量",
      "page": 110
    },
    {
      "level": "H1",
      "text": "研究者。而人脸中的这些信息往往交织在一起互相干扰，如何有效地进行特征解",
      "page": 110
    },
    {
      "level": "H1",
      "text": "离日益成为当前研究的焦点。此外，随着图像与视频采集的日益便捷，数据量也",
      "page": 110
    },
    {
      "level": "H1",
      "text": "大大提升。现实安防系统中往往存在不止一张照片或一段视频，而是以一个图片",
      "page": 110
    },
    {
      "level": "H1",
      "text": "集的形式作为查询或候选样本。本论文针对以上问题与发展趋势，提出了一系列",
      "page": 110
    },
    {
      "level": "H1",
      "text": "可行的解决方案。",
      "page": 110
    },
    {
      "level": "H1",
      "text": "6.1",
      "page": 110
    },
    {
      "level": "H1",
      "text": "本文的主要工作",
      "page": 110
    },
    {
      "level": "H1",
      "text": "论文的主要贡献可概括为如下几点：",
      "page": 110
    },
    {
      "level": "H1",
      "text": "基于深度度量学习的身份感知人脸表情识别",
      "page": 110
    },
    {
      "level": "H1",
      "text": "面部表情识别（",
      "page": 110
    },
    {
      "level": "H1",
      "text": "FER",
      "page": 110
    },
    {
      "level": "H1",
      "text": "）的一个关键挑战是提取有效的特征表示来平衡类内和",
      "page": 110
    },
    {
      "level": "H1",
      "text": "类间变化。在第二章中，展示了结合交叉熵损失和度量学习可以有效的提升性能。",
      "page": 110
    },
    {
      "level": "H1",
      "text": "所提出的自适应",
      "page": 110
    },
    {
      "level": "H1",
      "text": "(N+M)",
      "page": 110
    },
    {
      "level": "H1",
      "text": "簇损失函数与身份感知的难负样本挖掘和在线正样本挖",
      "page": 110
    },
    {
      "level": "H1",
      "text": "掘方案可明确的去除身份信息，实现具有身份不变性的",
      "page": 110
    },
    {
      "level": "H1",
      "text": "。它缓解了锚点选择",
      "page": 110
    },
    {
      "level": "H1",
      "text": "问题，减少了深度度量学习的计算负担。通过构建两个全连接层分支对两个损失",
      "page": 110
    },
    {
      "level": "H1",
      "text": "函数进行联合优化可有效的考虑两个任务的难度与层次。",
      "page": 110
    },
    {
      "level": "H1",
      "text": "基于难样本生成的人脸表情识别",
      "page": 110
    },
    {
      "level": "H1",
      "text": "为进一步提高负样本的挖掘效率以及解决许多人脸表情数据集中并非每个",
      "page": 110
    },
    {
      "level": "H1",
      "text": "人都有所有表情类别的问题，第三章提出了一种新的人脸表情识别框架，称为身",
      "page": 110
    },
    {
      "level": "H1",
      "text": "份解开的面部表情识别机器（",
      "page": 110
    },
    {
      "level": "H1",
      "text": "IDFERM",
      "page": 110
    },
    {
      "level": "H1",
      "text": "），其通过与生成的中性参考脸进行对比来",
      "page": 110
    },
    {
      "level": "H1",
      "text": "获取较纯的表情特征。其展示了一种可能的“通过生成进行识别”的方案，该方",
      "page": 110
    },
    {
      "level": "H1",
      "text": "案由难样本生成（",
      "page": 110
    },
    {
      "level": "H1",
      "text": "HNG",
      "page": 110
    },
    {
      "level": "H1",
      "text": "）网络和径向度量学习（",
      "page": 110
    },
    {
      "level": "H1",
      "text": "RML",
      "page": 110
    },
    {
      "level": "H1",
      "text": "）网络组成。对于",
      "page": 110
    },
    {
      "level": "H1",
      "text": "成的保持身份的归一化人脸被用作度量学习的难负样本。与传统的深度度量学习",
      "page": 110
    },
    {
      "level": "H1",
      "text": "总结与展望",
      "page": 111
    },
    {
      "level": "H1",
      "text": "方法相比，在",
      "page": 111
    },
    {
      "level": "H1",
      "text": "RML",
      "page": 111
    },
    {
      "level": "H1",
      "text": "需要的距离比较更少。所提出的",
      "page": 111
    },
    {
      "level": "H1",
      "text": "CK +",
      "page": 111
    },
    {
      "level": "H1",
      "text": "MMI",
      "page": 111
    },
    {
      "level": "H1",
      "text": "Oulu-",
      "page": 111
    },
    {
      "level": "H1",
      "text": "CASIA",
      "page": 111
    },
    {
      "level": "H1",
      "text": "等数据集上实现了优异的表情识别性能。",
      "page": 111
    },
    {
      "level": "H1",
      "text": "基于对抗训练的人脸身份与属性特征剥离及识别",
      "page": 111
    },
    {
      "level": "H1",
      "text": "如何以可控的方式明确消除没有成对变换示例的的样本仍然是具有挑战性",
      "page": 111
    },
    {
      "level": "H1",
      "text": "的任务。第四章系统地总结了任务相关",
      "page": 111
    },
    {
      "level": "H1",
      "text": "不相关的语义变量和未指定的潜在变量",
      "page": 111
    },
    {
      "level": "H1",
      "text": "在识别任务中的作用。在本章中，通过特征空间中的极小极大对抗性博弈将输入",
      "page": 111
    },
    {
      "level": "H1",
      "text": "样本分解为三个互补部分的特征向量。具有判别力的特征表示不光具有充分的信",
      "page": 111
    },
    {
      "level": "H1",
      "text": "息用于主任务的识别，且可以由先验知识引导具有针对某些属性的不变性，其与",
      "page": 111
    },
    {
      "level": "H1",
      "text": "任务相关",
      "page": 111
    },
    {
      "level": "H1",
      "text": "不相关的语义和潜在变量相互边际独立。提出的框架在一系列照明，化",
      "page": 111
    },
    {
      "level": "H1",
      "text": "妆，伪装容忍人脸识别和面部属性识别任务中实现了最佳性能。",
      "page": 111
    },
    {
      "level": "H1",
      "text": "基于增强学习的人脸图片集身份识别",
      "page": 111
    },
    {
      "level": "H1",
      "text": "第五章考虑了基于图像集的人脸验证和鉴别问题。与传统的单个样本（图像",
      "page": 111
    },
    {
      "level": "H1",
      "text": "或视频）设置不同，图像集假定可以使用一组无序的图像和视频的集合。其样本",
      "page": 111
    },
    {
      "level": "H1",
      "text": "可以在不同场所的监控点以及各种的身份证件采集中得到。传统方法通常将每个",
      "page": 111
    },
    {
      "level": "H1",
      "text": "图像的重要性视作相等或基于单个图像的质量评估，而与该图像集中的其他图像",
      "page": 111
    },
    {
      "level": "H1",
      "text": "或视频无关。如何模拟集合中无序图像的关系仍然是一个挑战。通过将其视为潜",
      "page": 111
    },
    {
      "level": "H1",
      "text": "在空间中的马尔可夫决策过程（",
      "page": 111
    },
    {
      "level": "H1",
      "text": "MDP",
      "page": 111
    },
    {
      "level": "H1",
      "text": "）来解决这个问题。具体来说，首先提出依",
      "page": 111
    },
    {
      "level": "H1",
      "text": "赖感知注意力控制（",
      "page": 111
    },
    {
      "level": "H1",
      "text": "DAC",
      "page": 111
    },
    {
      "level": "H1",
      "text": "）网络，其使用演员",
      "page": 111
    },
    {
      "level": "H1",
      "text": "评论家强化学习将所有图片作为",
      "page": 111
    },
    {
      "level": "H1",
      "text": "状态来对每个图像作出动作即注意力分数来利用无序图像之间的相关性。进一步",
      "page": 111
    },
    {
      "level": "H1",
      "text": "引入了异策略经验重播，以加快学习过程。此外，",
      "page": 111
    },
    {
      "level": "H1",
      "text": "与针对视频的时序模型",
      "page": 111
    },
    {
      "level": "H1",
      "text": "以分而治之的策略相结合。还引入了姿态引导表示（",
      "page": 111
    },
    {
      "level": "H1",
      "text": "PGR",
      "page": 111
    },
    {
      "level": "H1",
      "text": "）方案。提出了无需训",
      "page": 111
    },
    {
      "level": "H1",
      "text": "练参数的无参数",
      "page": 111
    },
    {
      "level": "H1",
      "text": "以及无需在测试阶段进行姿态检测的基于度量学习的",
      "page": 111
    },
    {
      "level": "H1",
      "text": "用于姿态对准。在",
      "page": 111
    },
    {
      "level": "H1",
      "text": "IJB-A / B / C",
      "page": 111
    },
    {
      "level": "H1",
      "text": "YTF",
      "page": 111
    },
    {
      "level": "H1",
      "text": "Celebrity-1000",
      "page": 111
    },
    {
      "level": "H1",
      "text": "等数据集上的测试评估表",
      "page": 111
    },
    {
      "level": "H1",
      "text": "明了此方法对基于集合以及基于视频的人脸识别的有效性。",
      "page": 111
    },
    {
      "level": "H1",
      "text": "6.2",
      "page": 111
    },
    {
      "level": "H1",
      "text": "研究展望",
      "page": 111
    },
    {
      "level": "H1",
      "text": "在本文工作的基础上，后续工作可以沿着以下几个方向进行：",
      "page": 111
    },
    {
      "level": "H1",
      "text": "基于度量学习的视频人脸表情识别",
      "page": 111
    },
    {
      "level": "H1",
      "text": "总结与展望",
      "page": 112
    },
    {
      "level": "H1",
      "text": "虽然基于静态图片的表情识别在应用阶段无需采集较长的样本，但表情本身",
      "page": 112
    },
    {
      "level": "H1",
      "text": "是随着时间变化的动作。而时序信息往往能带来更充足的判断依据，以提高识别",
      "page": 112
    },
    {
      "level": "H1",
      "text": "的准确率。事实上有许多情感分析的应用无需实时分析，而准确度要求则更高。",
      "page": 112
    },
    {
      "level": "H1",
      "text": "此外，本论文所提出的自适应阈值学习也有潜力被用于行人或车辆重新识别等任",
      "page": 112
    },
    {
      "level": "H1",
      "text": "基于特征解构的图像生成与域适应",
      "page": 112
    },
    {
      "level": "H1",
      "text": "通过设置语义变量为域（",
      "page": 112
    },
    {
      "level": "H1",
      "text": "domain",
      "page": 112
    },
    {
      "level": "H1",
      "text": "）可以实现可控的提取对域不变的特征从而",
      "page": 112
    },
    {
      "level": "H1",
      "text": "进行域适应（",
      "page": 112
    },
    {
      "level": "H1",
      "text": "domain adaptation",
      "page": 112
    },
    {
      "level": "H1",
      "text": "）任务。在进行特征解构时使用了解码器网络用",
      "page": 112
    },
    {
      "level": "H1",
      "text": "于根据特征向量生成图片。图片风格转换可作为预处理并用于基于图片的域适应",
      "page": 112
    },
    {
      "level": "H1",
      "text": "方法此外，特征解构在公平识别等应用上也有较大潜力。",
      "page": 112
    },
    {
      "level": "H1",
      "text": "基于非局部网络的排列不变集表示",
      "page": 112
    },
    {
      "level": "H1",
      "text": "非局部神经网络（",
      "page": 112
    },
    {
      "level": "H1",
      "text": "Non-local Neural Networks",
      "page": 112
    },
    {
      "level": "H1",
      "text": "）从去噪算法中的",
      "page": 112
    },
    {
      "level": "H1",
      "text": "non-local means",
      "page": 112
    },
    {
      "level": "H1",
      "text": "self-attention",
      "page": 112
    },
    {
      "level": "H1",
      "text": "出发，依靠各空间位点的相似关系，捕捉大范围内数据相互之间",
      "page": 112
    },
    {
      "level": "H1",
      "text": "的依赖关系。其构造使得它对排列不敏感，可以完全满足图片集的无序性质。一",
      "page": 112
    },
    {
      "level": "H1",
      "text": "种可行的方法是将各图片的特征向量视为非局部算法中的某一点，并通过逐对比",
      "page": 112
    },
    {
      "level": "H1",
      "text": "较去除集内冗余，并强调有辨别力的特征向量。",
      "page": 112
    },
    {
      "level": "H1",
      "text": "参考文献",
      "page": 114
    },
    {
      "level": "H1",
      "text": "[1]",
      "page": 114
    },
    {
      "level": "H1",
      "text": "Lecun Y, Bengio Y, Hinton G. Deep learning[J]. Nature, 2015, 521(7553):436.",
      "page": 114
    },
    {
      "level": "H1",
      "text": "[2]",
      "page": 114
    },
    {
      "level": "H1",
      "text": "Russell S J, Norvig P. Artificial intelligence: a modern approach[M]. Artificial",
      "page": 114
    },
    {
      "level": "H1",
      "text": "Intelligence: A Modern Approach. 2002.",
      "page": 114
    },
    {
      "level": "H1",
      "text": "[3]",
      "page": 114
    },
    {
      "level": "H1",
      "text": "Russakovsky O, Deng J, Su H, et al. ImageNet Large Scale Visual Recognition",
      "page": 114
    },
    {
      "level": "H1",
      "text": "Challenge[J]. International Journal of Computer Vision, 2015, 115(3):211-252.",
      "page": 114
    },
    {
      "level": "H1",
      "text": "[4]",
      "page": 114
    },
    {
      "level": "H1",
      "text": "Sun Y, Wang X, Tang X. Deep Learning Face Representation from Predicting 10,000",
      "page": 114
    },
    {
      "level": "H1",
      "text": "Classes[C]. 2014 IEEE Conference on Computer Vision and Pattern Recognition",
      "page": 114
    },
    {
      "level": "H1",
      "text": "(CVPR). IEEE Computer Society, 2014.",
      "page": 114
    },
    {
      "level": "H1",
      "text": "[5]",
      "page": 114
    },
    {
      "level": "H1",
      "text": "Jain A K, Flynn P, Ross A A. Handbook of Biometrics[J]. 2008.",
      "page": 114
    },
    {
      "level": "H1",
      "text": "[6]",
      "page": 114
    },
    {
      "level": "H1",
      "text": "Yang, C., Song, Y., Liu, X., Tang, Q., & Kuo, C. C. J. Image Inpainting using Block-",
      "page": 114
    },
    {
      "level": "H1",
      "text": "wise Procedural Training with Annealed Adversarial Counterpar [J]. arXiv: 1803.08943.",
      "page": 114
    },
    {
      "level": "H1",
      "text": "[7]",
      "page": 114
    },
    {
      "level": "H1",
      "text": "Tome P, Fierrez J, Vera-Rodriguez R, et al. Soft Biometrics and Their Application in",
      "page": 114
    },
    {
      "level": "H1",
      "text": "Person Recognition at a Distance[J]. IEEE Transactions on Information Forensics &",
      "page": 114
    },
    {
      "level": "H1",
      "text": "Security, 2017, 9(3):464-475.",
      "page": 114
    },
    {
      "level": "H1",
      "text": "[8]",
      "page": 114
    },
    {
      "level": "H1",
      "text": "[D]. 2015.",
      "page": 114
    },
    {
      "level": "H1",
      "text": "[9]",
      "page": 114
    },
    {
      "level": "H1",
      "text": "[J].",
      "page": 114
    },
    {
      "level": "H1",
      "text": ", 2000, 5(11):885-894.",
      "page": 114
    },
    {
      "level": "H1",
      "text": "[10]",
      "page": 114
    },
    {
      "level": "H1",
      "text": "Liu X, Li S, Kong L, et al. Feature-level Frankenstein: Eliminating Variations for",
      "page": 114
    },
    {
      "level": "H1",
      "text": "Discriminative Recognition[C]. 2019 IEEE Conference on Computer Vision and Pattern",
      "page": 114
    },
    {
      "level": "H1",
      "text": "Recognition (CVPR). IEEE Computer Society, 2019.",
      "page": 114
    },
    {
      "level": "H1",
      "text": "[11]",
      "page": 114
    },
    {
      "level": "H1",
      "text": "Liu X, Kumar B.V.K, Yang C, et al. Dependency-aware Attention Control for",
      "page": 114
    },
    {
      "level": "H1",
      "text": "Unconstrained Face Recognition with Image Sets.\" Proceedings of the European",
      "page": 114
    },
    {
      "level": "H1",
      "text": "Conference on Computer Vision (ECCV), 2018, 548-565.",
      "page": 114
    },
    {
      "level": "H1",
      "text": "[12]",
      "page": 114
    },
    {
      "level": "H1",
      "text": "Mehrabian A. Silent Messages[J]. 1971.",
      "page": 114
    },
    {
      "level": "H1",
      "text": "[13]",
      "page": 114
    },
    {
      "level": "H1",
      "text": "None. Personal Identification and Descriptions[J]. Nature, 38(974):201-202.",
      "page": 114
    },
    {
      "level": "H1",
      "text": "[14]",
      "page": 114
    },
    {
      "level": "H1",
      "text": "Perlibakas V. Distance measures for PCA-based face recognition[J]. Pattern",
      "page": 114
    },
    {
      "level": "H1",
      "text": "Recognition Letters, 2004, 25(6):711-724.",
      "page": 114
    },
    {
      "level": "H1",
      "text": "[15]",
      "page": 114
    },
    {
      "level": "H1",
      "text": "Chen L F, Liao H Y M, Ko M T, et al. A new LDA-based face recognition system which",
      "page": 114
    },
    {
      "level": "H1",
      "text": "can solve the small sample size problem[J]. Pattern Recognition, 2000, 33(10):1713-",
      "page": 114
    },
    {
      "level": "H1",
      "text": "1726.",
      "page": 114
    },
    {
      "level": "H1",
      "text": "[16]",
      "page": 114
    },
    {
      "level": "H1",
      "text": "Bo Y, Chen S. A comparative study on local binary pattern (LBP) based face recognition:",
      "page": 114
    },
    {
      "level": "H1",
      "text": "LBP histogram versus LBP image[J]. Neurocomputing, 2013, 120(10):365-379.",
      "page": 114
    },
    {
      "level": "H1",
      "text": "[17]",
      "page": 114
    },
    {
      "level": "H1",
      "text": "Liu C, Wechsler H. A Gabor feature classifier for face recognition[C]. IEEE",
      "page": 114
    },
    {
      "level": "H1",
      "text": "International Conference on Computer Vision. 2001.",
      "page": 114
    },
    {
      "level": "H1",
      "text": "参考文献",
      "page": 115
    },
    {
      "level": "H1",
      "text": "[18]",
      "page": 115
    },
    {
      "level": "H1",
      "text": "Liu X, Li Z, Kong L, et al. A joint optimization framework of low-dimensional",
      "page": 115
    },
    {
      "level": "H1",
      "text": "projection and collaborative representation for discriminative classification[C]. 24th",
      "page": 115
    },
    {
      "level": "H1",
      "text": "International Conference on Pattern Recognition (ICPR), 2018.",
      "page": 115
    },
    {
      "level": "H1",
      "text": "[19]",
      "page": 115
    },
    {
      "level": "H1",
      "text": "Hearst M A. Support Vector Machines[J]. IEEE Intelligent Systems & Their",
      "page": 115
    },
    {
      "level": "H1",
      "text": "Applications, 1998, 13(4):18-28.",
      "page": 115
    },
    {
      "level": "H1",
      "text": "[20]",
      "page": 115
    },
    {
      "level": "H1",
      "text": ", et al.",
      "page": 115
    },
    {
      "level": "H1",
      "text": ": 201610344806.1.",
      "page": 115
    },
    {
      "level": "H1",
      "text": "[21]",
      "page": 115
    },
    {
      "level": "H1",
      "text": "Milborrow S, Nicolls F. Locating Facial Features with an Extended Active Shape",
      "page": 115
    },
    {
      "level": "H1",
      "text": "Model[C]. European Conference on Computer Vision. 2008.",
      "page": 115
    },
    {
      "level": "H1",
      "text": "[22]",
      "page": 115
    },
    {
      "level": "H1",
      "text": "Tirkaz C, Albayrak S. Face recognition using Active Appearance Model[C]. European",
      "page": 115
    },
    {
      "level": "H1",
      "text": "Conference on Computer Vision. Springer-Verlag, 1998.",
      "page": 115
    },
    {
      "level": "H1",
      "text": "[23]",
      "page": 115
    },
    {
      "level": "H1",
      "text": "Schmidhuber J. Deep learning in neural networks: an overview[J]. Neural Netw, 2015,",
      "page": 115
    },
    {
      "level": "H1",
      "text": "61:85-117.",
      "page": 115
    },
    {
      "level": "H1",
      "text": "[24]",
      "page": 115
    },
    {
      "level": "H1",
      "text": "Taigman Y, Ming Y, Ranzato M, et al. DeepFace: Closing the Gap to Human-Level",
      "page": 115
    },
    {
      "level": "H1",
      "text": "Performance in Face Verification[C]. IEEE Conference on Computer Vision Pattern",
      "page": 115
    },
    {
      "level": "H1",
      "text": "Recognition. 2014.",
      "page": 115
    },
    {
      "level": "H1",
      "text": "[25]",
      "page": 115
    },
    {
      "level": "H1",
      "text": "Learned-Miller E, Huang G B, Roychowdhury A, et al. Labeled Faces in the Wild: A",
      "page": 115
    },
    {
      "level": "H1",
      "text": "Survey[M]. Advances in Face Detection and Facial Image Analysis. Springer",
      "page": 115
    },
    {
      "level": "H1",
      "text": "International Publishing, 2016.",
      "page": 115
    },
    {
      "level": "H1",
      "text": "[26]",
      "page": 115
    },
    {
      "level": "H1",
      "text": "Zhao W, Chellappa R, Phillips PJ, et al. Face recognition: A literature survey[J]. ACM",
      "page": 115
    },
    {
      "level": "H1",
      "text": "computing surveys (CSUR) 35.4 (2003): 399-458.",
      "page": 115
    },
    {
      "level": "H1",
      "text": "[27]",
      "page": 115
    },
    {
      "level": "H1",
      "text": "Crosswhite N, Byrne J, Stauffer C, et al. Template Adaptation for Face Verification and",
      "page": 115
    },
    {
      "level": "H1",
      "text": "Identification[C]. IEEE International Conference on Automatic Face & Gesture",
      "page": 115
    },
    {
      "level": "H1",
      "text": "Recognition. 2017.",
      "page": 115
    },
    {
      "level": "H1",
      "text": "[28]",
      "page": 115
    },
    {
      "level": "H1",
      "text": "Krizhevsky A, Sutskever I, Hinton GE. Imagenet classification with deep convolutional",
      "page": 115
    },
    {
      "level": "H1",
      "text": "neural networks[C]. In Advances in neural information processing systems 2012.",
      "page": 115
    },
    {
      "level": "H1",
      "text": "[29]",
      "page": 115
    },
    {
      "level": "H1",
      "text": "Simonyan K, Zisserman A. Very Deep Convolutional Networks for Large-Scale Image",
      "page": 115
    },
    {
      "level": "H1",
      "text": "Recognition[J]. Computer Science, 2014.",
      "page": 115
    },
    {
      "level": "H1",
      "text": "[30]",
      "page": 115
    },
    {
      "level": "H1",
      "text": "Szegedy C, Liu W, Jia Y, et al. Going Deeper with Convolutions[C]. 2015 IEEE",
      "page": 115
    },
    {
      "level": "H1",
      "text": "Conference on Computer Vision and Pattern Recognition (CVPR). IEEE, 2015.",
      "page": 115
    },
    {
      "level": "H1",
      "text": "[31]",
      "page": 115
    },
    {
      "level": "H1",
      "text": "He K, Zhang X, Ren S, et al. Deep Residual Learning for Image Recognition[C]. IEEE",
      "page": 115
    },
    {
      "level": "H1",
      "text": "Conference on Computer Vision Pattern Recognition. 2016.",
      "page": 115
    },
    {
      "level": "H1",
      "text": "[32]",
      "page": 115
    },
    {
      "level": "H1",
      "text": "Lecun Y L, Bottou L, Bengio Y, et al. Gradient-Based Learning Applied to Document",
      "page": 115
    },
    {
      "level": "H1",
      "text": "Recognition[J]. Proceedings of the IEEE, 1998, 86(11):2278-2324.",
      "page": 115
    },
    {
      "level": "H1",
      "text": "[33]",
      "page": 115
    },
    {
      "level": "H1",
      "text": "Liu X, Zou Y, Song Y, Yang C, You J, Kumar BV. Ordinal Regression with Neuron",
      "page": 115
    },
    {
      "level": "H1",
      "text": "Stick-Breaking for Medical Diagnosis[C]. In European Conference on Computer Vision",
      "page": 115
    },
    {
      "level": "H1",
      "text": "Workshops (ECCVW), 2018.",
      "page": 115
    },
    {
      "level": "H1",
      "text": "[34]",
      "page": 115
    },
    {
      "level": "H1",
      "text": "Melekhov I, Kannala J, Rahtu E. Siamese network features for image matching[C].",
      "page": 115
    },
    {
      "level": "H1",
      "text": "International Conference on Pattern Recognition. 2017.",
      "page": 115
    },
    {
      "level": "H1",
      "text": "参考文献",
      "page": 116
    },
    {
      "level": "H1",
      "text": "[35]",
      "page": 116
    },
    {
      "level": "H1",
      "text": "Wolf L, Hassner T, Maoz I. Face recognition in unconstrained videos with matched",
      "page": 116
    },
    {
      "level": "H1",
      "text": "background similarity[C]. IEEE Conference on Computer Vision and Pattern",
      "page": 116
    },
    {
      "level": "H1",
      "text": "Recognition (CVPR), 2011.",
      "page": 116
    },
    {
      "level": "H1",
      "text": "[36]",
      "page": 116
    },
    {
      "level": "H1",
      "text": "Klare B F, Jain A K, Klein B, et al. Pushing the frontiers of unconstrained face detection",
      "page": 116
    },
    {
      "level": "H1",
      "text": "and recognition: IARPA Janus Benchmark A[C]. 2015 IEEE Conference on Computer",
      "page": 116
    },
    {
      "level": "H1",
      "text": "Vision and Pattern Recognition (CVPR). IEEE Computer Society, 2015.",
      "page": 116
    },
    {
      "level": "H1",
      "text": "[37]",
      "page": 116
    },
    {
      "level": "H1",
      "text": "Whitelam C, Taborsky E, Blanton A, et al. IARPA Janus Benchmark-B Face Dataset[C].",
      "page": 116
    },
    {
      "level": "H1",
      "text": "2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops",
      "page": 116
    },
    {
      "level": "H1",
      "text": "(CVPRW). IEEE, 2017.",
      "page": 116
    },
    {
      "level": "H1",
      "text": "[38]",
      "page": 116
    },
    {
      "level": "H1",
      "text": "Maze B, Adams J, Duncan JA, et al. IARPA janus benchmark-c: Face dataset and",
      "page": 116
    },
    {
      "level": "H1",
      "text": "protocol[C]. In 2018 International Conference on Biometrics (ICB) 2018.",
      "page": 116
    },
    {
      "level": "H1",
      "text": "[39]",
      "page": 116
    },
    {
      "level": "H1",
      "text": "Ekman P. Contacts across cultures in the face and emotion[J]. J Pers Soc Psychol, 1971,",
      "page": 116
    },
    {
      "level": "H1",
      "text": "17(2):124-129.",
      "page": 116
    },
    {
      "level": "H1",
      "text": "[40]",
      "page": 116
    },
    {
      "level": "H1",
      "text": "Suwa M. A preliminary note on pattern recognition of human emotional expression. In",
      "page": 116
    },
    {
      "level": "H1",
      "text": "Proc. of The 4th International Joint Conference on Pattern Recognition.",
      "page": 116
    },
    {
      "level": "H1",
      "text": "[41]",
      "page": 116
    },
    {
      "level": "H1",
      "text": "Polli E, Bersani F S, De R C, et al. Facial Action Coding System (FACS): an instrument",
      "page": 116
    },
    {
      "level": "H1",
      "text": "for the objective evaluation of facial expression and its potential applications to the",
      "page": 116
    },
    {
      "level": "H1",
      "text": "study of schizophrenia[J]. Rivista Di Psichiatria, 2012, 47(2):126.",
      "page": 116
    },
    {
      "level": "H1",
      "text": "[42]",
      "page": 116
    },
    {
      "level": "H1",
      "text": "Li J, Zhang D, Zhang J, et al. Facial Expression Recognition with Faster R-CNN[J].",
      "page": 116
    },
    {
      "level": "H1",
      "text": "Procedia Computer Science, 2017, 107(C):135-140.",
      "page": 116
    },
    {
      "level": "H1",
      "text": "[43]",
      "page": 116
    },
    {
      "level": "H1",
      "text": "Ren S, He K, Girshick R, et al. Faster R-CNN: Towards Real-Time Object Detection",
      "page": 116
    },
    {
      "level": "H1",
      "text": "with Region Proposal Networks[J]. IEEE Transactions on Pattern Analysis & Machine",
      "page": 116
    },
    {
      "level": "H1",
      "text": "Intelligence, 2017, 39(6):1137-1149.",
      "page": 116
    },
    {
      "level": "H1",
      "text": "[44]",
      "page": 116
    },
    {
      "level": "H1",
      "text": "Hinton, Geoffrey E., and Ruslan R. Salakhutdinov. Reducing the dimensionality of data",
      "page": 116
    },
    {
      "level": "H1",
      "text": "with neural networks[J]. science313.5786 (2006): 504-507.",
      "page": 116
    },
    {
      "level": "H1",
      "text": "[45]",
      "page": 116
    },
    {
      "level": "H1",
      "text": "Vincent P, Larochelle H, Bengio Y, et al. Extracting and Composing Robust Features",
      "page": 116
    },
    {
      "level": "H1",
      "text": "with Denoising Autoencoders[C]. International Conference on Machine Learning.",
      "page": 116
    },
    {
      "level": "H1",
      "text": "ACM, 2008.",
      "page": 116
    },
    {
      "level": "H1",
      "text": "[46]",
      "page": 116
    },
    {
      "level": "H1",
      "text": "Zeng N, Zhang H, Song B, et al. Facial expression recognition via learning deep sparse",
      "page": 116
    },
    {
      "level": "H1",
      "text": "autoencoders[J]. Neurocomputing, 2017.",
      "page": 116
    },
    {
      "level": "H1",
      "text": "[47]",
      "page": 116
    },
    {
      "level": "H1",
      "text": "Masci J, Meier U, Cireşan D, et al. Stacked convolutional auto-encoders for hierarchical",
      "page": 116
    },
    {
      "level": "H1",
      "text": "feature extraction[C]. International Conference on Artificial Neural Networks. 2011.",
      "page": 116
    },
    {
      "level": "H1",
      "text": "[48]",
      "page": 116
    },
    {
      "level": "H1",
      "text": "Doersch C. Tutorial on Variational Autoencoders[J]. arXiv:1606.05908, 2016.",
      "page": 116
    },
    {
      "level": "H1",
      "text": "[49]",
      "page": 116
    },
    {
      "level": "H1",
      "text": "Levi G, Hassner T. Emotion Recognition in the Wild via Convolutional Neural",
      "page": 116
    },
    {
      "level": "H1",
      "text": "Networks and Mapped Binary Patterns[C]. in Proceedings of the 2015 ACM on",
      "page": 116
    },
    {
      "level": "H1",
      "text": "international conference on multimodal interaction. ACM, 2015.",
      "page": 116
    },
    {
      "level": "H1",
      "text": "[50]",
      "page": 116
    },
    {
      "level": "H1",
      "text": "Lowe D G. Object recognition from local scale-invariant features[M]. IEEE",
      "page": 116
    },
    {
      "level": "H1",
      "text": "International Conference on Computer Vision, 1999.",
      "page": 116
    },
    {
      "level": "H1",
      "text": "参考文献",
      "page": 117
    },
    {
      "level": "H1",
      "text": "[51]",
      "page": 117
    },
    {
      "level": "H1",
      "text": "Zeng N, Zhang H, Song B, et al. Facial expression recognition via learning deep sparse",
      "page": 117
    },
    {
      "level": "H1",
      "text": "autoencoders[J]. Neurocomputing, 2017.",
      "page": 117
    },
    {
      "level": "H1",
      "text": "[52]",
      "page": 117
    },
    {
      "level": "H1",
      "text": "Luo Z, Chen J, Takiguchi T, et al. Facial Expression Recognition with deep age[C].",
      "page": 117
    },
    {
      "level": "H1",
      "text": "IEEE International Conference on Multimedia & Expo Workshops, 2017.",
      "page": 117
    },
    {
      "level": "H1",
      "text": "[53]",
      "page": 117
    },
    {
      "level": "H1",
      "text": "Chen L, Zhou M, Su W, et al. Softmax regression based deep sparse autoencoder",
      "page": 117
    },
    {
      "level": "H1",
      "text": "network for facial emotion recognition in human-robot interaction. Information",
      "page": 117
    },
    {
      "level": "H1",
      "text": "Sciences[J]. 2018, 428:49-61.",
      "page": 117
    },
    {
      "level": "H1",
      "text": "[54]",
      "page": 117
    },
    {
      "level": "H1",
      "text": "Mavani V, Raman S, Miyapuram K P. Facial Expression Recognition Using Visual",
      "page": 117
    },
    {
      "level": "H1",
      "text": "Saliency and Deep Learning[C]. IEEE International Conference on Computer Vision",
      "page": 117
    },
    {
      "level": "H1",
      "text": "Workshop. 2018.",
      "page": 117
    },
    {
      "level": "H1",
      "text": "[55]",
      "page": 117
    },
    {
      "level": "H1",
      "text": "Ciregan, Meier, Schmidhuber. Multi-column deep neural networks for image",
      "page": 117
    },
    {
      "level": "H1",
      "text": "classification[J]. Eprint Arxiv, 2012, 157(10):3642-3649.",
      "page": 117
    },
    {
      "level": "H1",
      "text": "[56]",
      "page": 117
    },
    {
      "level": "H1",
      "text": "Bargal S A, Barsoum E, Ferrer C C, et al. Emotion recognition in the wild from videos",
      "page": 117
    },
    {
      "level": "H1",
      "text": "using images[C]. Acm International Conference on Multimodal Interaction. 2016.",
      "page": 117
    },
    {
      "level": "H1",
      "text": "[57]",
      "page": 117
    },
    {
      "level": "H1",
      "text": "Kuang L, Zhang M, Pan Z. Facial Expression Recognition with CNN Ensemble[C].",
      "page": 117
    },
    {
      "level": "H1",
      "text": "International Conference on Cyberworlds. 2016.",
      "page": 117
    },
    {
      "level": "H1",
      "text": "[58]",
      "page": 117
    },
    {
      "level": "H1",
      "text": "Devries T, Biswaranjan K, Taylor G W. Multi-task Learning of Facial Landmarks and",
      "page": 117
    },
    {
      "level": "H1",
      "text": "Expression[C]. Computer & Robot Vision. 2014.",
      "page": 117
    },
    {
      "level": "H1",
      "text": "[59]",
      "page": 117
    },
    {
      "level": "H1",
      "text": "Pons G, Masip D. Multi-task, multi-label and multi-domain learning with residual",
      "page": 117
    },
    {
      "level": "H1",
      "text": "convolutional networks for emotion recognition[J]. arXiv:1802.06664, 2018.",
      "page": 117
    },
    {
      "level": "H1",
      "text": "[60]",
      "page": 117
    },
    {
      "level": "H1",
      "text": "Ekman P. Conclusion: What We Have Learned by Measuring Facial Behavior: Further",
      "page": 117
    },
    {
      "level": "H1",
      "text": "Comments and Clarifications[M]. What the Face Reveals Basic and Applied Studies of",
      "page": 117
    },
    {
      "level": "H1",
      "text": "Spontaneous Expression Using the Facial Action Coding System (FACS). 2005.",
      "page": 117
    },
    {
      "level": "H1",
      "text": "[61]",
      "page": 117
    },
    {
      "level": "H1",
      "text": "Reed S, Sohn K, Zhang Y, Lee H. Learning to disentangle factors of variation with",
      "page": 117
    },
    {
      "level": "H1",
      "text": "manifold interaction[C]. International Conference on Machine Learning 2014.",
      "page": 117
    },
    {
      "level": "H1",
      "text": "[62]",
      "page": 117
    },
    {
      "level": "H1",
      "text": "Ranjan R, Sankaranarayanan S, Castillo C D, et al. An All-In-One Convolutional Neural",
      "page": 117
    },
    {
      "level": "H1",
      "text": "Network for Face Analysis[J]. 2017 12th IEEE International Conference on Automatic",
      "page": 117
    },
    {
      "level": "H1",
      "text": "Face & Gesture Recognition (FG), 2017.",
      "page": 117
    },
    {
      "level": "H1",
      "text": "[63]",
      "page": 117
    },
    {
      "level": "H1",
      "text": "Werbos P J. Backpropagation through time: what it does and how to do it[J]. Proc IEEE,",
      "page": 117
    },
    {
      "level": "H1",
      "text": "1990, 78(10):1550-1560.",
      "page": 117
    },
    {
      "level": "H1",
      "text": "[64]",
      "page": 117
    },
    {
      "level": "H1",
      "text": "Hochreiter S, Schmidhuber J. Long short-term memory.[J]. Neural Computation, 1997,",
      "page": 117
    },
    {
      "level": "H1",
      "text": "9(8):1735-1780.",
      "page": 117
    },
    {
      "level": "H1",
      "text": "[65]",
      "page": 117
    },
    {
      "level": "H1",
      "text": "Ji S, Xu W, Yang M, et al. 3D Convolutional Neural Networks for Human Action",
      "page": 117
    },
    {
      "level": "H1",
      "text": "Recognition[J]. IEEE Transactions on Pattern Analysis & Machine Intelligence, 2013,",
      "page": 117
    },
    {
      "level": "H1",
      "text": "35(1):221-231.",
      "page": 117
    },
    {
      "level": "H1",
      "text": "[66]",
      "page": 117
    },
    {
      "level": "H1",
      "text": "Liu X, Kumar B.V.K, You J, et al. Adaptive Deep Metric Learning for Identity-Aware",
      "page": 117
    },
    {
      "level": "H1",
      "text": "Facial Expression Recognition[C]. 2017 IEEE Conference on Computer Vision and",
      "page": 117
    },
    {
      "level": "H1",
      "text": "Pattern Recognition Workshops (CVPRW). IEEE Computer Society, 2017.",
      "page": 117
    },
    {
      "level": "H1",
      "text": "参考文献",
      "page": 118
    },
    {
      "level": "H1",
      "text": "[67]",
      "page": 118
    },
    {
      "level": "H1",
      "text": "Liu X, Ge Y, Yang C, et al. Adaptive metric learning with deep neural networks for",
      "page": 118
    },
    {
      "level": "H1",
      "text": "video-based facial expression recognition[J]. Journal of Electronic Imaging, 2018.",
      "page": 118
    },
    {
      "level": "H1",
      "text": "[68]",
      "page": 118
    },
    {
      "level": "H1",
      "text": "Liu X, Vijaya Kumar B.V.K, Jia P, et al. Hard negative generation for identity-",
      "page": 118
    },
    {
      "level": "H1",
      "text": "disentangled facial expression recognition[J]. Pattern Recognition, 2019, 88:1-12.",
      "page": 118
    },
    {
      "level": "H1",
      "text": "[69]",
      "page": 118
    },
    {
      "level": "H1",
      "text": "Liu X, Kumar B.V.K, Ge Y, et al. Normalized face image generation with perceptron",
      "page": 118
    },
    {
      "level": "H1",
      "text": "generative adversarial networks[C]. 2018 IEEE 4th International Conference on Identity,",
      "page": 118
    },
    {
      "level": "H1",
      "text": "Security, and Behavior Analysis (ISBA), 2018.",
      "page": 118
    },
    {
      "level": "H1",
      "text": "[70]",
      "page": 118
    },
    {
      "level": "H1",
      "text": "Liu X, Kumar B V K, You J, et al. Data Augmentation via Latent Space Interpolation",
      "page": 118
    },
    {
      "level": "H1",
      "text": "for Image Classification. 2018 24th International Conference on Pattern Recognition",
      "page": 118
    },
    {
      "level": "H1",
      "text": "(ICPR), 2018.",
      "page": 118
    },
    {
      "level": "H1",
      "text": "[71]",
      "page": 118
    },
    {
      "level": "H1",
      "text": "Cohn J. F. and Ekman P. Measuring facial action[M]. The new handbook of methods in",
      "page": 118
    },
    {
      "level": "H1",
      "text": "nonverbal behavior research, 2005, pages 9–64.",
      "page": 118
    },
    {
      "level": "H1",
      "text": "[72]",
      "page": 118
    },
    {
      "level": "H1",
      "text": "Kotsia I, Zafeiriou S, Fotopoulos S. Affective Gaming: A Comprehensive Survey[C]//",
      "page": 118
    },
    {
      "level": "H1",
      "text": "Computer Vision & Pattern Recognition Workshops. 2013.",
      "page": 118
    },
    {
      "level": "H1",
      "text": "[73]",
      "page": 118
    },
    {
      "level": "H1",
      "text": "Valstar M F, Mehu M, Jiang B, et al. Meta-Analysis of the First Facial Expression",
      "page": 118
    },
    {
      "level": "H1",
      "text": "Recognition Challenge[J]. IEEE Transactions on Systems Man & Cybernetics Part B,",
      "page": 118
    },
    {
      "level": "H1",
      "text": "2012, 42(4):966-79.",
      "page": 118
    },
    {
      "level": "H1",
      "text": "[74]",
      "page": 118
    },
    {
      "level": "H1",
      "text": "Ding S, Lin L, Wang G, et al. Deep feature learning with relative distance comparison",
      "page": 118
    },
    {
      "level": "H1",
      "text": "for person re-identification[J]. Pattern Recognition, 2015, 48(10):2993-3003.",
      "page": 118
    },
    {
      "level": "H1",
      "text": "[75]",
      "page": 118
    },
    {
      "level": "H1",
      "text": "Sohn K. Improved deep metric learning with multi-class n-pair loss objective[C]. In",
      "page": 118
    },
    {
      "level": "H1",
      "text": "Advances in Neural Information Processing Systems, 2016.",
      "page": 118
    },
    {
      "level": "H1",
      "text": "[76]",
      "page": 118
    },
    {
      "level": "H1",
      "text": "Liu H, Tian Y, Wang Y, et al. Deep Relative Distance Learning: Tell the Difference",
      "page": 118
    },
    {
      "level": "H1",
      "text": "between Similar Vehicles[C]. Computer Vision & Pattern Recognition. 2016.",
      "page": 118
    },
    {
      "level": "H1",
      "text": "[77]",
      "page": 118
    },
    {
      "level": "H1",
      "text": "Tian Y L, Kanade T, Cohn J. Facial expression analysis[J]. Scholarpedia, 2005,",
      "page": 118
    },
    {
      "level": "H1",
      "text": "3723(4):1-1.",
      "page": 118
    },
    {
      "level": "H1",
      "text": "[78]",
      "page": 118
    },
    {
      "level": "H1",
      "text": "Jain S, Hu C, Aggarwal J K. Facial expression recognition with temporal modeling of",
      "page": 118
    },
    {
      "level": "H1",
      "text": "shapes[C]. IEEE International Conference on Computer Vision Workshops. 2011.",
      "page": 118
    },
    {
      "level": "H1",
      "text": "[79]",
      "page": 118
    },
    {
      "level": "H1",
      "text": "Shen J, Zafeiriou S, Chrysos G G, et al. The First Facial Landmark Tracking in-the-",
      "page": 118
    },
    {
      "level": "H1",
      "text": "Wild Challenge: Benchmark and Results[C]. IEEE International Conference on",
      "page": 118
    },
    {
      "level": "H1",
      "text": "Computer Vision Workshop. 2015.",
      "page": 118
    },
    {
      "level": "H1",
      "text": "[80]",
      "page": 118
    },
    {
      "level": "H1",
      "text": "Baltrušaitis T, Mahmoud M, Robinson P. Cross-dataset learning and person-specific",
      "page": 118
    },
    {
      "level": "H1",
      "text": "normalisation for automatic Action Unit detection[C]. IEEE International Conference",
      "page": 118
    },
    {
      "level": "H1",
      "text": "& Workshops on Automatic Face & Gesture Recognition. 2015.",
      "page": 118
    },
    {
      "level": "H1",
      "text": "[81]",
      "page": 118
    },
    {
      "level": "H1",
      "text": "Jiang B, Valstar M F, Pantic M. Action unit detection using sparse appearance",
      "page": 118
    },
    {
      "level": "H1",
      "text": "descriptors in space-time video volumes[C]. IEEE International Conference &",
      "page": 118
    },
    {
      "level": "H1",
      "text": "Workshops on Automatic Face & Gesture Recognition. 2011.",
      "page": 118
    },
    {
      "level": "H1",
      "text": "参考文献",
      "page": 119
    },
    {
      "level": "H1",
      "text": "[82]",
      "page": 119
    },
    {
      "level": "H1",
      "text": "Yüce A, Hua G, Thiran J P. Discriminant multi-label manifold embedding for facial",
      "page": 119
    },
    {
      "level": "H1",
      "text": "Action Unit detection[C]. IEEE International Conference & Workshops on Automatic",
      "page": 119
    },
    {
      "level": "H1",
      "text": "Face & Gesture Recognition. 2015.",
      "page": 119
    },
    {
      "level": "H1",
      "text": "[83]",
      "page": 119
    },
    {
      "level": "H1",
      "text": "Zhang L, Tjondronegoro D, Chandran V. Random Gabor based templates for facial",
      "page": 119
    },
    {
      "level": "H1",
      "text": "expression recognition in images with facial occlusion[J]. Neurocomputing, 2014,",
      "page": 119
    },
    {
      "level": "H1",
      "text": "145(18):451-464.",
      "page": 119
    },
    {
      "level": "H1",
      "text": "[84]",
      "page": 119
    },
    {
      "level": "H1",
      "text": "Sariyanidi E, Gunes H, Cavallaro A. Automatic Analysis of Facial Affect: A Survey of",
      "page": 119
    },
    {
      "level": "H1",
      "text": "Registration, Representation, and Recognition[J]. IEEE Transactions on Pattern",
      "page": 119
    },
    {
      "level": "H1",
      "text": "Analysis & Machine Intelligence, 2015, 37(6):1113-1133.",
      "page": 119
    },
    {
      "level": "H1",
      "text": "[85]",
      "page": 119
    },
    {
      "level": "H1",
      "text": "Mollahosseini A, Hassani B, Salvador M J, et al. Facial Expression Recognition from",
      "page": 119
    },
    {
      "level": "H1",
      "text": "World Wild Web[C]. Computer Vision & Pattern Recognition Workshops. 2016.",
      "page": 119
    },
    {
      "level": "H1",
      "text": "[86]",
      "page": 119
    },
    {
      "level": "H1",
      "text": "Chopra S, Hadsell R, Lecun Y. Learning a Similarity Metric Discriminatively, with",
      "page": 119
    },
    {
      "level": "H1",
      "text": "Application to Face Verification[C]. IEEE Computer Society Conference on Computer",
      "page": 119
    },
    {
      "level": "H1",
      "text": "Vision & Pattern Recognition. 2005.",
      "page": 119
    },
    {
      "level": "H1",
      "text": "[87]",
      "page": 119
    },
    {
      "level": "H1",
      "text": "Zhen L, Chang S, Feng L, et al. Learning Locally-Adaptive Decision Functions for",
      "page": 119
    },
    {
      "level": "H1",
      "text": "Person Verification[C]. IEEE Conference on Computer Vision and Pattern Recognition,",
      "page": 119
    },
    {
      "level": "H1",
      "text": "2013.",
      "page": 119
    },
    {
      "level": "H1",
      "text": "[88]",
      "page": 119
    },
    {
      "level": "H1",
      "text": "Goodfellow I J, Erhan D, Carrier P L, et al. Challenges in representation learning[J].",
      "page": 119
    },
    {
      "level": "H1",
      "text": "Neural Networks, 2015, 64(C):59-63.",
      "page": 119
    },
    {
      "level": "H1",
      "text": "[89]",
      "page": 119
    },
    {
      "level": "H1",
      "text": "Wang Q, Zuo W, Zhang L, Li P. Shrinkage expansion adaptive metric learning[C]. In",
      "page": 119
    },
    {
      "level": "H1",
      "text": "European Conference on Computer Vision, 2014.",
      "page": 119
    },
    {
      "level": "H1",
      "text": "[90]",
      "page": 119
    },
    {
      "level": "H1",
      "text": "Sun Y, Chen Y, Wang X, et al. Deep learning face representation by joint identification-",
      "page": 119
    },
    {
      "level": "H1",
      "text": "verification[C]. In Advances in neural information processing systems, 2014.",
      "page": 119
    },
    {
      "level": "H1",
      "text": "[91]",
      "page": 119
    },
    {
      "level": "H1",
      "text": "Yi D, Lei Z, Liao S, et al. Learning Face Representation from Scratch[J]. Computer",
      "page": 119
    },
    {
      "level": "H1",
      "text": "Science, 2014.",
      "page": 119
    },
    {
      "level": "H1",
      "text": "[92]",
      "page": 119
    },
    {
      "level": "H1",
      "text": "Zafeiriou S, Papaioannou A, Kotsia I, et al. Facial Affect “In-the-Wild”: A Survey and",
      "page": 119
    },
    {
      "level": "H1",
      "text": "a New Database[C]. Computer Vision & Pattern Recognition Workshops. 2016.",
      "page": 119
    },
    {
      "level": "H1",
      "text": "[93]",
      "page": 119
    },
    {
      "level": "H1",
      "text": "Barsoum E, Zhang C, Ferrer C C, et al. Training deep networks for facial expression",
      "page": 119
    },
    {
      "level": "H1",
      "text": "recognition with crowd-sourced label distribution[C]. Acm International Conference on",
      "page": 119
    },
    {
      "level": "H1",
      "text": "Multimodal Interaction. 2016.",
      "page": 119
    },
    {
      "level": "H1",
      "text": "[94]",
      "page": 119
    },
    {
      "level": "H1",
      "text": "S. Zafeiriou, A. Papaioannou, I. Kotsia, M. Nicolaou and G. Zhao. Facial Affect “In-",
      "page": 119
    },
    {
      "level": "H1",
      "text": "the-Wild”: A Survey and a New Database. In IEEE Conference on Computer Vision",
      "page": 119
    },
    {
      "level": "H1",
      "text": "and Pattern Recognition workshops, pages 1487-1498, 2016.",
      "page": 119
    },
    {
      "level": "H1",
      "text": "[95]",
      "page": 119
    },
    {
      "level": "H1",
      "text": "Mollahosseini A, Chan D, Mahoor M H. Going deeper in facial expression recognition",
      "page": 119
    },
    {
      "level": "H1",
      "text": "using deep neural networks[C]. IEEE Winter Conference on Applications of Computer",
      "page": 119
    },
    {
      "level": "H1",
      "text": "Vision. 2016.",
      "page": 119
    },
    {
      "level": "H1",
      "text": "[96]",
      "page": 119
    },
    {
      "level": "H1",
      "text": "Arora S, Bhaskara A, Ge R, Ma T. Provable bounds for learning some deep",
      "page": 119
    },
    {
      "level": "H1",
      "text": "representations[C]. International Conference on Machine Learning (ICML), 2014.",
      "page": 119
    },
    {
      "level": "H1",
      "text": "参考文献",
      "page": 120
    },
    {
      "level": "H1",
      "text": "[97]",
      "page": 120
    },
    {
      "level": "H1",
      "text": "Lucey P, Cohn J F, Kanade T, et al. The Extended Cohn-Kanade Dataset (CK+): A",
      "page": 120
    },
    {
      "level": "H1",
      "text": "complete dataset for action unit and emotion-specified expression[C]. Computer Vision",
      "page": 120
    },
    {
      "level": "H1",
      "text": "& Pattern Recognition Workshops. 2010.",
      "page": 120
    },
    {
      "level": "H1",
      "text": "[98]",
      "page": 120
    },
    {
      "level": "H1",
      "text": "Pantic M, Valstar M, Rademaker R, et al. Web-based database for facial expression",
      "page": 120
    },
    {
      "level": "H1",
      "text": "analysis[C]. Proc IEEE International Conference on Multimedia & Expo. 2005.",
      "page": 120
    },
    {
      "level": "H1",
      "text": "[99]",
      "page": 120
    },
    {
      "level": "H1",
      "text": "Dhall A, Murthy O R, Goecke R, et al. Video and Image based Emotion Recognition",
      "page": 120
    },
    {
      "level": "H1",
      "text": "Challenges in the Wild: EmotiW 2015[C]. ACM International Conference on",
      "page": 120
    },
    {
      "level": "H1",
      "text": "Multimodal Interaction. ACM, 2015.",
      "page": 120
    },
    {
      "level": "H1",
      "text": "[100]",
      "page": 120
    },
    {
      "level": "H1",
      "text": "Xiong X, Torre F D L. Supervised Descent Method and Its Applications to Face",
      "page": 120
    },
    {
      "level": "H1",
      "text": "Alignment[C]. IEEE Conference on Computer Vision & Pattern Recognition. 2013.",
      "page": 120
    },
    {
      "level": "H1",
      "text": "[101]",
      "page": 120
    },
    {
      "level": "H1",
      "text": "Yu Z, Zhang C. Image based Static Facial Expression Recognition with Multiple",
      "page": 120
    },
    {
      "level": "H1",
      "text": "Deep Network Learning[C]. Acm on International Conference on Multimodal",
      "page": 120
    },
    {
      "level": "H1",
      "text": "Interaction. 2015.",
      "page": 120
    },
    {
      "level": "H1",
      "text": "[102]",
      "page": 120
    },
    {
      "level": "H1",
      "text": "Gross R, Matthews I, Cohn J, et al. Multi-PIE[J]. Image Vis Comput, 2010,",
      "page": 120
    },
    {
      "level": "H1",
      "text": "28(5):807-813.",
      "page": 120
    },
    {
      "level": "H1",
      "text": "[103]",
      "page": 120
    },
    {
      "level": "H1",
      "text": "Rifai S, Bengio Y, Courville A, et al. Disentangling Factors of Variation for Facial",
      "page": 120
    },
    {
      "level": "H1",
      "text": "Expression Recognition[C]. European Conference on Computer Vision. Springer,",
      "page": 120
    },
    {
      "level": "H1",
      "text": "Berlin, Heidelberg, 2012.",
      "page": 120
    },
    {
      "level": "H1",
      "text": "[104]",
      "page": 120
    },
    {
      "level": "H1",
      "text": "Wang Z, Wang S, Ji Q. Capturing Complex Spatio-temporal Relations among Facial",
      "page": 120
    },
    {
      "level": "H1",
      "text": "Muscles for Facial Expression Recognition[C]. 2013 IEEE Conference on Computer",
      "page": 120
    },
    {
      "level": "H1",
      "text": "Vision and Pattern Recognition. IEEE, 2013.",
      "page": 120
    },
    {
      "level": "H1",
      "text": "[105]",
      "page": 120
    },
    {
      "level": "H1",
      "text": "Liu P, Han S, Meng Z, et al. Facial Expression Recognition via a Boosted Deep",
      "page": 120
    },
    {
      "level": "H1",
      "text": "Belief Network[C]. 2014 IEEE Conference on Computer Vision and Pattern",
      "page": 120
    },
    {
      "level": "H1",
      "text": "Recognition (CVPR), 2014.",
      "page": 120
    },
    {
      "level": "H1",
      "text": "[106]",
      "page": 120
    },
    {
      "level": "H1",
      "text": "Han S, Meng Z, Khan A S, et al. Incremental Boosting Convolutional Neural",
      "page": 120
    },
    {
      "level": "H1",
      "text": "Network for Facial Action Unit Recognition[C], Advances in neural information",
      "page": 120
    },
    {
      "level": "H1",
      "text": "processing systems. 2016.",
      "page": 120
    },
    {
      "level": "H1",
      "text": "[107]",
      "page": 120
    },
    {
      "level": "H1",
      "text": "Liu M, Li S, Shan S, et al. Deeply Learning Deformable Facial Action Parts Model",
      "page": 120
    },
    {
      "level": "H1",
      "text": "for Dynamic Expression Analysis[C]. Asian conference on computer vision. Springer,",
      "page": 120
    },
    {
      "level": "H1",
      "text": "Cham, 2014.",
      "page": 120
    },
    {
      "level": "H1",
      "text": "[108]",
      "page": 120
    },
    {
      "level": "H1",
      "text": "Liu M, Shan S, Wang R, et al. Learning Expressionlets on Spatio-Temporal Manifold",
      "page": 120
    },
    {
      "level": "H1",
      "text": "for Dynamic Facial Expression Recognition[C]. IEEE Conference on Computer Vision",
      "page": 120
    },
    {
      "level": "H1",
      "text": "& Pattern Recognition, 2014.",
      "page": 120
    },
    {
      "level": "H1",
      "text": "[109]",
      "page": 120
    },
    {
      "level": "H1",
      "text": "Jung H, Lee S, Yim J, et al. Joint Fine-Tuning in Deep Neural Networks for Facial",
      "page": 120
    },
    {
      "level": "H1",
      "text": "Expression Recognition[C]. 2015 IEEE International Conference on Computer Vision",
      "page": 120
    },
    {
      "level": "H1",
      "text": "(ICCV), 2015.",
      "page": 120
    },
    {
      "level": "H1",
      "text": "参考文献",
      "page": 121
    },
    {
      "level": "H1",
      "text": "100",
      "page": 121
    },
    {
      "level": "H1",
      "text": "[110]",
      "page": 121
    },
    {
      "level": "H1",
      "text": "Kim B K. Hierarchical committee of deep convolutional neural networks for robust",
      "page": 121
    },
    {
      "level": "H1",
      "text": "facial expression recognition[J]. Journal on Multimodal User Interfaces, 2016, 10(2):1-",
      "page": 121
    },
    {
      "level": "H1",
      "text": "17.",
      "page": 121
    },
    {
      "level": "H1",
      "text": "[111]",
      "page": 121
    },
    {
      "level": "H1",
      "text": "Ng H W, Nguyen D, Vonikakis V, et al. Deep Learning for Emotion Recognition on",
      "page": 121
    },
    {
      "level": "H1",
      "text": "Small Datasets Using Transfer Learning[C]. ACM International Conference on",
      "page": 121
    },
    {
      "level": "H1",
      "text": "Multimodal Interaction, 2015.",
      "page": 121
    },
    {
      "level": "H1",
      "text": "[112]",
      "page": 121
    },
    {
      "level": "H1",
      "text": "Yao A, Shao J, Ma N, et al. Capturing AU-Aware Facial Features and Their Latent",
      "page": 121
    },
    {
      "level": "H1",
      "text": "Relations for Emotion Recognition in the Wild[C]. 17th ACM International Conference",
      "page": 121
    },
    {
      "level": "H1",
      "text": "on Multimodal Interaction, 2015.",
      "page": 121
    },
    {
      "level": "H1",
      "text": "[113]",
      "page": 121
    },
    {
      "level": "H1",
      "text": "Bo S, Li L, Tian Z, et al. Combining Multimodal Features with Hierarchical",
      "page": 121
    },
    {
      "level": "H1",
      "text": "Classifier Fusion for Emotion Recognition in the Wild[C]. Acm on International",
      "page": 121
    },
    {
      "level": "H1",
      "text": "Conference on Multimodal Interaction, 2014.",
      "page": 121
    },
    {
      "level": "H1",
      "text": "[114]",
      "page": 121
    },
    {
      "level": "H1",
      "text": "Zong Y, Zheng W, Huang X, et al. Transductive Transfer LDA with Riesz-based",
      "page": 121
    },
    {
      "level": "H1",
      "text": "Volume LBP for Emotion Recognition in The Wild[C]. Acm on International",
      "page": 121
    },
    {
      "level": "H1",
      "text": "[115]",
      "page": 121
    },
    {
      "level": "H1",
      "text": "Kaya H, Salah A A. Combining Modality-Specific Extreme Learning Machines for",
      "page": 121
    },
    {
      "level": "H1",
      "text": "Emotion Recognition in the Wild[C]. Acm on International Conference on Multimodal",
      "page": 121
    },
    {
      "level": "H1",
      "text": "Interaction, 2014.",
      "page": 121
    },
    {
      "level": "H1",
      "text": "[116]",
      "page": 121
    },
    {
      "level": "H1",
      "text": "Mao Q, Rao Q, Yu Y, et al. Hierarchical Bayesian Theme Models for Multi-pose",
      "page": 121
    },
    {
      "level": "H1",
      "text": "Facial Expression Recognition[J]. IEEE Transactions on Multimedia, 2017, 19(4):861-",
      "page": 121
    },
    {
      "level": "H1",
      "text": "873.",
      "page": 121
    },
    {
      "level": "H1",
      "text": "[117]",
      "page": 121
    },
    {
      "level": "H1",
      "text": "Calder A J, Young A W. Understanding the recognition of facial identity and facial",
      "page": 121
    },
    {
      "level": "H1",
      "text": "expression[J]. Nature Reviews Neuroscience, 2005, 6(8):641-651.",
      "page": 121
    },
    {
      "level": "H1",
      "text": "[118]",
      "page": 121
    },
    {
      "level": "H1",
      "text": "Haxby J V, Hoffman E A, Gobbini M I. The distributed human neural system for",
      "page": 121
    },
    {
      "level": "H1",
      "text": "face perception[J]. Trends in Cognitive Sciences, 2000, 4(6):223-233.",
      "page": 121
    },
    {
      "level": "H1",
      "text": "[119]",
      "page": 121
    },
    {
      "level": "H1",
      "text": "Kotsia I, Pitas I. Facial Expression Recognition in Image Sequences Using",
      "page": 121
    },
    {
      "level": "H1",
      "text": "Geometric Deformation Features and Support Vector Machines[J]. IEEE Transactions",
      "page": 121
    },
    {
      "level": "H1",
      "text": "on Image Processing, 2006, 16(1):172-187.",
      "page": 121
    },
    {
      "level": "H1",
      "text": "[120]",
      "page": 121
    },
    {
      "level": "H1",
      "text": "Liu M, Shan S, Wang R, et al. Learning Expressionlets on Spatio-Temporal Manifold",
      "page": 121
    },
    {
      "level": "H1",
      "text": "for Dynamic Facial Expression Recognition[C]. IEEE Conference on Computer Vision",
      "page": 121
    },
    {
      "level": "H1",
      "text": "& Pattern Recognition. IEEE Computer Society, 2014.",
      "page": 121
    },
    {
      "level": "H1",
      "text": "[121]",
      "page": 121
    },
    {
      "level": "H1",
      "text": "Bishop C M. Pattern Recognition and Machine Learning (Information Science and",
      "page": 121
    },
    {
      "level": "H1",
      "text": "Statistics)[M]. springer, 2006",
      "page": 121
    },
    {
      "level": "H1",
      "text": "[122]",
      "page": 121
    },
    {
      "level": "H1",
      "text": "Lakemeyer G. Exploring Artificial Intelligence in the New Millennium[M].",
      "page": 121
    },
    {
      "level": "H1",
      "text": "Exploring artificial intelligence in the new millennium. 2002.",
      "page": 121
    },
    {
      "level": "H1",
      "text": "[123]",
      "page": 121
    },
    {
      "level": "H1",
      "text": "Vincent P, Larochelle H, Bengio Y, et al. Extracting and Composing Robust Features",
      "page": 121
    },
    {
      "level": "H1",
      "text": "with Denoising Autoencoders[C]. International Conference on Machine Learning.",
      "page": 121
    },
    {
      "level": "H1",
      "text": "ACM, 2008.",
      "page": 121
    },
    {
      "level": "H1",
      "text": "参考文献",
      "page": 122
    },
    {
      "level": "H1",
      "text": "101",
      "page": 122
    },
    {
      "level": "H1",
      "text": "[124]",
      "page": 122
    },
    {
      "level": "H1",
      "text": "Cole F, Belanger D, Krishnan D, et al. Synthesizing Normalized Faces from Facial",
      "page": 122
    },
    {
      "level": "H1",
      "text": "Identity Features[C]. In IEEE Conference on Computer Vision and Pattern Recognition,",
      "page": 122
    },
    {
      "level": "H1",
      "text": "2017.",
      "page": 122
    },
    {
      "level": "H1",
      "text": "[125]",
      "page": 122
    },
    {
      "level": "H1",
      "text": "Kingma D P, Welling M. Auto-Encoding Variational Bayes[J]. arXiv preprint",
      "page": 122
    },
    {
      "level": "H1",
      "text": "arXiv:1312.6114, 2013",
      "page": 122
    },
    {
      "level": "H1",
      "text": "[126]",
      "page": 122
    },
    {
      "level": "H1",
      "text": "Gregor K, Danihelka I, Graves A, et al. DRAW: A Recurrent Neural Network For",
      "page": 122
    },
    {
      "level": "H1",
      "text": "Image Generation[J]. Computer Science, 2015:1462-1471.",
      "page": 122
    },
    {
      "level": "H1",
      "text": "[127]",
      "page": 122
    },
    {
      "level": "H1",
      "text": "Goodfellow I J, Pouget-Abadie J, Mirza M, et al. Generative adversarial nets[C].",
      "page": 122
    },
    {
      "level": "H1",
      "text": "International Conference on Neural Information Processing Systems, 2014.",
      "page": 122
    },
    {
      "level": "H1",
      "text": "[128]",
      "page": 122
    },
    {
      "level": "H1",
      "text": "Gatys LA, Ecker AS, Bethge M. A neural algorithm of artistic style[J]. arXiv preprint",
      "page": 122
    },
    {
      "level": "H1",
      "text": "arXiv:1508.06576, 2015.",
      "page": 122
    },
    {
      "level": "H1",
      "text": "[129]",
      "page": 122
    },
    {
      "level": "H1",
      "text": "Goodfellow I. NIPS 2016 Tutorial: Generative Adversarial Networks[J]. In arXiv:",
      "page": 122
    },
    {
      "level": "H1",
      "text": "1701.00160, 2016",
      "page": 122
    },
    {
      "level": "H1",
      "text": "[130]",
      "page": 122
    },
    {
      "level": "H1",
      "text": "Tran L, Yin X, Liu X. Disentangled Representation Learning GAN for Pose-",
      "page": 122
    },
    {
      "level": "H1",
      "text": "Invariant Face Recognition[C]. IEEE Computer Vision and Pattern Recognition (CVPR",
      "page": 122
    },
    {
      "level": "H1",
      "text": "2017), IEEE, 2017.",
      "page": 122
    },
    {
      "level": "H1",
      "text": "[131]",
      "page": 122
    },
    {
      "level": "H1",
      "text": "Huang R, Zhang S, Li T, et al. Beyond Face Rotation: Global and Local Perception",
      "page": 122
    },
    {
      "level": "H1",
      "text": "GAN for Photorealistic and Identity Preserving Frontal View Synthesis[J]. In",
      "page": 122
    },
    {
      "level": "H1",
      "text": "arXiv:1704.04086v1, 2017.",
      "page": 122
    },
    {
      "level": "H1",
      "text": "[132]",
      "page": 122
    },
    {
      "level": "H1",
      "text": "Parkhi OM, Vedaldi A, Zisserman A. Deep face recognition[C]. In BMVC 2015 Sep",
      "page": 122
    },
    {
      "level": "H1",
      "text": "7 (Vol. 1, No. 3, p. 6).",
      "page": 122
    },
    {
      "level": "H1",
      "text": "[133]",
      "page": 122
    },
    {
      "level": "H1",
      "text": "Xiang W, Ran H, Sun Z, et al. A Light CNN for Deep Face Representation with",
      "page": 122
    },
    {
      "level": "H1",
      "text": "Noisy Labels[J]. IEEE Transactions on Information Forensics & Security, 2015,",
      "page": 122
    },
    {
      "level": "H1",
      "text": "PP(99):1-1.",
      "page": 122
    },
    {
      "level": "H1",
      "text": "[134]",
      "page": 122
    },
    {
      "level": "H1",
      "text": "Theis L, Oord, Aäron van den, Bethge M. A note on the evaluation of generative",
      "page": 122
    },
    {
      "level": "H1",
      "text": "models[J]. Computer Science, 2015.",
      "page": 122
    },
    {
      "level": "H1",
      "text": "[135]",
      "page": 122
    },
    {
      "level": "H1",
      "text": "Wen Y, Zhang K, Li Z, et al. A Discriminative Feature Learning Approach for Deep",
      "page": 122
    },
    {
      "level": "H1",
      "text": "Face Recognition[M]. In ECCV 2016, 2016.",
      "page": 122
    },
    {
      "level": "H1",
      "text": "[136]",
      "page": 122
    },
    {
      "level": "H1",
      "text": "Kingma DP, Ba J. Adam: A method for stochastic optimization[J]. arXiv preprint",
      "page": 122
    },
    {
      "level": "H1",
      "text": "arXiv:1412.6980, 2014.",
      "page": 122
    },
    {
      "level": "H1",
      "text": "[137]",
      "page": 122
    },
    {
      "level": "H1",
      "text": "He K, Zhang X, Ren S, et al. Delving Deep into Rectifiers: Surpassing Human-Level",
      "page": 122
    },
    {
      "level": "H1",
      "text": "Performance on ImageNet Classification[C]. In IEEE International Conference on",
      "page": 122
    },
    {
      "level": "H1",
      "text": "Computer Vision (ICCV), 2015.",
      "page": 122
    },
    {
      "level": "H1",
      "text": "[138]",
      "page": 122
    },
    {
      "level": "H1",
      "text": "Abadi M, Barham P, Chen J, et al. TensorFlow: A system for large-scale machine",
      "page": 122
    },
    {
      "level": "H1",
      "text": "learning[C], In OSDI, 2016.",
      "page": 122
    },
    {
      "level": "H1",
      "text": "[139]",
      "page": 122
    },
    {
      "level": "H1",
      "text": "Schroff F, Kalenichenko D, Philbin J. FaceNet: A unified embedding for face",
      "page": 122
    },
    {
      "level": "H1",
      "text": "recognition and clustering[C]. 2015 IEEE Conference on Computer Vision and Pattern",
      "page": 122
    },
    {
      "level": "H1",
      "text": "Recognition (CVPR), 2015:815-823.",
      "page": 122
    },
    {
      "level": "H1",
      "text": "参考文献",
      "page": 123
    },
    {
      "level": "H1",
      "text": "102",
      "page": 123
    },
    {
      "level": "H1",
      "text": "[140]",
      "page": 123
    },
    {
      "level": "H1",
      "text": "Rifai S, Bengio Y, Courville A, et al. Disentangling Factors of Variation for Facial",
      "page": 123
    },
    {
      "level": "H1",
      "text": "Expression Recognition[C]. European Conference on Computer Vision, Berlin,",
      "page": 123
    },
    {
      "level": "H1",
      "text": "Heidelberg, 2012.",
      "page": 123
    },
    {
      "level": "H1",
      "text": "[141]",
      "page": 123
    },
    {
      "level": "H1",
      "text": "Liu P, Han S, Meng Z, et al. Facial Expression Recognition via a Boosted Deep",
      "page": 123
    },
    {
      "level": "H1",
      "text": "Belief Network[C]. 2014 IEEE Conference on Computer Vision and Pattern",
      "page": 123
    },
    {
      "level": "H1",
      "text": "Recognition (CVPR), 2014.",
      "page": 123
    },
    {
      "level": "H1",
      "text": "[142]",
      "page": 123
    },
    {
      "level": "H1",
      "text": "Han S, Meng Z, Khan A S, et al. Incremental Boosting Convolutional Neural",
      "page": 123
    },
    {
      "level": "H1",
      "text": "Network for Facial Action Unit Recognition[C]. Advances in Neural Information",
      "page": 123
    },
    {
      "level": "H1",
      "text": "Processing Systems, 2016, pp. 109–117.",
      "page": 123
    },
    {
      "level": "H1",
      "text": "[143]",
      "page": 123
    },
    {
      "level": "H1",
      "text": "Liu M, Shan S, Wang R, et al. Learning Expressionlets on Spatio-Temporal Manifold",
      "page": 123
    },
    {
      "level": "H1",
      "text": "for Dynamic Facial Expression Recognition[C]. IEEE Conference on Computer Vision",
      "page": 123
    },
    {
      "level": "H1",
      "text": "& Pattern Recognition, 2014.",
      "page": 123
    },
    {
      "level": "H1",
      "text": "[144]",
      "page": 123
    },
    {
      "level": "H1",
      "text": "Jung H, Lee S, Yim J, et al. Joint Fine-Tuning in Deep Neural Networks for Facial",
      "page": 123
    },
    {
      "level": "H1",
      "text": "Expression Recognition[C]. 2015 IEEE International Conference on Computer Vision",
      "page": 123
    },
    {
      "level": "H1",
      "text": "(ICCV), 2015.",
      "page": 123
    },
    {
      "level": "H1",
      "text": "[145]",
      "page": 123
    },
    {
      "level": "H1",
      "text": "Meng Z, Liu P, Cai J, et al. Identity-Aware Convolutional Neural Network for Facial",
      "page": 123
    },
    {
      "level": "H1",
      "text": "Expression Recognition[C]. 12th IEEE International Conference on Automatic Face &",
      "page": 123
    },
    {
      "level": "H1",
      "text": "Gesture Recognition (FG 2017), 2017.",
      "page": 123
    },
    {
      "level": "H1",
      "text": "[146]",
      "page": 123
    },
    {
      "level": "H1",
      "text": "Liu M, Li S, Shan S, et al. AU-inspired Deep Networks for Facial Expression Feature",
      "page": 123
    },
    {
      "level": "H1",
      "text": "Learning[J]. Neurocomputing, 2015, 159(1):126-136.",
      "page": 123
    },
    {
      "level": "H1",
      "text": "[147]",
      "page": 123
    },
    {
      "level": "H1",
      "text": "Khorrami P, Paine T L, Huang T S. Do Deep Neural Networks Learn Facial Action",
      "page": 123
    },
    {
      "level": "H1",
      "text": "Units When Doing Expression Recognition?[C]. IEEE Interna- tional Conference on",
      "page": 123
    },
    {
      "level": "H1",
      "text": "Computer Vision Workshops, 2015, pp. 19–27.",
      "page": 123
    },
    {
      "level": "H1",
      "text": "[148]",
      "page": 123
    },
    {
      "level": "H1",
      "text": "Ding H, Zhou S K, Chellappa R. FaceNet2ExpNet: Regularizing a Deep Face",
      "page": 123
    },
    {
      "level": "H1",
      "text": "Recognition Net for Expression Recognition[C]. In FG, 2017.",
      "page": 123
    },
    {
      "level": "H1",
      "text": "[149]",
      "page": 123
    },
    {
      "level": "H1",
      "text": "Zhao G, Huang X, Taini M, et al. Facial expression recognition from near-infrared",
      "page": 123
    },
    {
      "level": "H1",
      "text": "videos[J]. Image and Vision Computing, 2011, 29(9):607-619.",
      "page": 123
    },
    {
      "level": "H1",
      "text": "[150]",
      "page": 123
    },
    {
      "level": "H1",
      "text": "Zhao X, Liang X, Liu L, et al. Peak-Piloted Deep Network for Facial Expression",
      "page": 123
    },
    {
      "level": "H1",
      "text": "Recognition[C]. European Conference on Computer Vision. Springer, Cham, 2016.",
      "page": 123
    },
    {
      "level": "H1",
      "text": "[151]",
      "page": 123
    },
    {
      "level": "H1",
      "text": "Dong H, Neekhara P, Wu C, et al. Unsupervised Image-to-Image Translation with",
      "page": 123
    },
    {
      "level": "H1",
      "text": "Generative Adversarial Networks[J]. arXiv:1701.02676, 2017.",
      "page": 123
    },
    {
      "level": "H1",
      "text": "[152]",
      "page": 123
    },
    {
      "level": "H1",
      "text": "Liu M Y, Breuel T, Kautz J. Unsupervised Image-to-Image Translation Networks[J].",
      "page": 123
    },
    {
      "level": "H1",
      "text": "In Advances in Neural Information Processing Systems, pages 700–708, 2017.",
      "page": 123
    },
    {
      "level": "H1",
      "text": "[153]",
      "page": 123
    },
    {
      "level": "H1",
      "text": "Jayaraman D, Sha F, Grauman K. Decorrelating Semantic Visual Attributes by",
      "page": 123
    },
    {
      "level": "H1",
      "text": "Resisting the Urge to Share[C]. IEEE Conference on Computer Vision & Pattern",
      "page": 123
    },
    {
      "level": "H1",
      "text": "Recognition. 2014.",
      "page": 123
    },
    {
      "level": "H1",
      "text": "参考文献",
      "page": 124
    },
    {
      "level": "H1",
      "text": "103",
      "page": 124
    },
    {
      "level": "H1",
      "text": "[154]",
      "page": 124
    },
    {
      "level": "H1",
      "text": "Mathieu M, Zhao J, Sprechmann P, et al. Disentangling factors of variation in deep",
      "page": 124
    },
    {
      "level": "H1",
      "text": "representations using adversarial training[J]. In Advances in neural information",
      "page": 124
    },
    {
      "level": "H1",
      "text": "processing systems",
      "page": 124
    },
    {
      "level": "H1",
      "text": "[155]",
      "page": 124
    },
    {
      "level": "H1",
      "text": "Peng P, Tian Y, Xiang T, et al. Joint Semantic and Latent Attribute Modelling for",
      "page": 124
    },
    {
      "level": "H1",
      "text": "Cross-Class Transfer Learning[J]. IEEE Transactions on Pattern Analysis and Machine",
      "page": 124
    },
    {
      "level": "H1",
      "text": "Intelligence, 2017:1-1.",
      "page": 124
    },
    {
      "level": "H1",
      "text": "[156]",
      "page": 124
    },
    {
      "level": "H1",
      "text": "Hu G, Hua Y, Yuan Y, et al. Attribute-Enhanced Face Recognition with Neural",
      "page": 124
    },
    {
      "level": "H1",
      "text": "Tensor Fusion Networks[C]. 2017 IEEE International Conference on Computer Vision",
      "page": 124
    },
    {
      "level": "H1",
      "text": "(ICCV), 2017.",
      "page": 124
    },
    {
      "level": "H1",
      "text": "[157]",
      "page": 124
    },
    {
      "level": "H1",
      "text": "Jiang H, Wang R, Shan S, et al. Learning Discriminative Latent Attributes for Zero-",
      "page": 124
    },
    {
      "level": "H1",
      "text": "Shot Classification[C]. IEEE International Conference on Computer Vision. 2017.",
      "page": 124
    },
    {
      "level": "H1",
      "text": "[158]",
      "page": 124
    },
    {
      "level": "H1",
      "text": "Fu Y, Hospedales T M, Xiang T, et al. Learning Multimodal Latent Attributes[J].",
      "page": 124
    },
    {
      "level": "H1",
      "text": "IEEE Transactions on Pattern Analysis & Machine Intelligence, 2014, 36(2):303.",
      "page": 124
    },
    {
      "level": "H1",
      "text": "[159]",
      "page": 124
    },
    {
      "level": "H1",
      "text": "Louizos C, Swersky K, Li Y, et al. The variational fair autoencoder[J]. arXiv preprint",
      "page": 124
    },
    {
      "level": "H1",
      "text": "arXiv:1511.00830, 2015.",
      "page": 124
    },
    {
      "level": "H1",
      "text": "[160]",
      "page": 124
    },
    {
      "level": "H1",
      "text": "Zellinger W, Grubinger T, Lughofer E, et al. Central Moment Discrepancy (CMD)",
      "page": 124
    },
    {
      "level": "H1",
      "text": "for Domain-Invariant Representation Learning[C]. arXiv:1702.08811, 2017.",
      "page": 124
    },
    {
      "level": "H1",
      "text": "[161]",
      "page": 124
    },
    {
      "level": "H1",
      "text": "Hadad N, Wolf L, Shahar M. Two-Step Disentanglement for Financial Data[J]. In",
      "page": 124
    },
    {
      "level": "H1",
      "text": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,",
      "page": 124
    },
    {
      "level": "H1",
      "text": "pages 772–780, 2018.",
      "page": 124
    },
    {
      "level": "H1",
      "text": "[162]",
      "page": 124
    },
    {
      "level": "H1",
      "text": "Cao J, Katzir O, Jiang P, et al. DiDA: Disentangled Synthesis for Domain",
      "page": 124
    },
    {
      "level": "H1",
      "text": "Adaptation[J]. arXiv preprint arXiv:1805.08019, 2018.",
      "page": 124
    },
    {
      "level": "H1",
      "text": "[163]",
      "page": 124
    },
    {
      "level": "H1",
      "text": "Li Y, Tian X, Gong M, et al. Deep Domain Generalization via Conditional Invariant",
      "page": 124
    },
    {
      "level": "H1",
      "text": "Adversarial Networks[C]. European Conference on Computer Vision. 2018.",
      "page": 124
    },
    {
      "level": "H1",
      "text": "[164]",
      "page": 124
    },
    {
      "level": "H1",
      "text": "Kingma D P, Rezende D J, Mohamed S, et al. Semi-Supervised Learning with Deep",
      "page": 124
    },
    {
      "level": "H1",
      "text": "Generative Models[J]. Advances in Neural Information Processing Systems, 2014,",
      "page": 124
    },
    {
      "level": "H1",
      "text": "4:3581-3589.",
      "page": 124
    },
    {
      "level": "H1",
      "text": "[165]",
      "page": 124
    },
    {
      "level": "H1",
      "text": "[166]",
      "page": 124
    },
    {
      "level": "H1",
      "text": "Foundations and Trends® in Machine Learning[M]. Now Publishers Inc. 2011.",
      "page": 124
    },
    {
      "level": "H1",
      "text": "[167]",
      "page": 124
    },
    {
      "level": "H1",
      "text": "Tenenbaum J B, Freeman W T. Separating style and content with bilinear models[J].",
      "page": 124
    },
    {
      "level": "H1",
      "text": "Neural Computation, 2014, 12(6):1247-1283.",
      "page": 124
    },
    {
      "level": "H1",
      "text": "[168]",
      "page": 124
    },
    {
      "level": "H1",
      "text": "Elgammal A, Lee C S. Separating Style and Content on a Nonlinear Manifold[C].",
      "page": 124
    },
    {
      "level": "H1",
      "text": "IEEE Computer Society Conference on Computer Vision & Pattern Recognition. 2004.",
      "page": 124
    },
    {
      "level": "H1",
      "text": "[169]",
      "page": 124
    },
    {
      "level": "H1",
      "text": "Zhao J, Mathieu M, Goroshin R, et al. Stacked What-Where Auto-encoders[J].",
      "page": 124
    },
    {
      "level": "H1",
      "text": "Computer Science, 2015, 15(1):3563-3593.",
      "page": 124
    },
    {
      "level": "H1",
      "text": "[170]",
      "page": 124
    },
    {
      "level": "H1",
      "text": "Xiao T, Hong J, Ma J. DNA-GAN: Learning Disentangled Representations from",
      "page": 124
    },
    {
      "level": "H1",
      "text": "Multi-Attribute Images[J]. arXiv:1711.05415, 2017. 3.",
      "page": 124
    },
    {
      "level": "H1",
      "text": "参考文献",
      "page": 125
    },
    {
      "level": "H1",
      "text": "104",
      "page": 125
    },
    {
      "level": "H1",
      "text": "[171]",
      "page": 125
    },
    {
      "level": "H1",
      "text": "Bao J, Chen D, Wen F, et al. Towards Open-Set Identity Preserving Face",
      "page": 125
    },
    {
      "level": "H1",
      "text": "Synthesis[C]. In Proceedings of the IEEE Conference on Computer Vision and Pattern",
      "page": 125
    },
    {
      "level": "H1",
      "text": "Recognition, pages 6713–6722, 2018.",
      "page": 125
    },
    {
      "level": "H1",
      "text": "[172]",
      "page": 125
    },
    {
      "level": "H1",
      "text": "Makhzani A, Shlens J, Jaitly N, et al. Adversarial autoencoders[J]. arXiv preprint",
      "page": 125
    },
    {
      "level": "H1",
      "text": "arXiv:1511.05644. 2015.",
      "page": 125
    },
    {
      "level": "H1",
      "text": "[173]",
      "page": 125
    },
    {
      "level": "H1",
      "text": "Tishby N, Zaslavsky N. Deep Learning and the Information Bottleneck Principle[C].",
      "page": 125
    },
    {
      "level": "H1",
      "text": "In Information Theory Workshop (ITW), 2015.",
      "page": 125
    },
    {
      "level": "H1",
      "text": "[174]",
      "page": 125
    },
    {
      "level": "H1",
      "text": "Georghiades A S, Belhumeur P N, Kriegman D J. From few to many: illumination",
      "page": 125
    },
    {
      "level": "H1",
      "text": "cone models for face recognition under variable lighting and pose[J]. IEEE Transactions",
      "page": 125
    },
    {
      "level": "H1",
      "text": "on Pattern Analysis and Machine Intelligence, 2001, 23(6):643-660.",
      "page": 125
    },
    {
      "level": "H1",
      "text": "[175]",
      "page": 125
    },
    {
      "level": "H1",
      "text": "Li Y, Swersky K, Zemel R. Learning unbiased features[J]. arXiv preprint",
      "page": 125
    },
    {
      "level": "H1",
      "text": "arXiv:1412.5244, 2014.",
      "page": 125
    },
    {
      "level": "H1",
      "text": "[176]",
      "page": 125
    },
    {
      "level": "H1",
      "text": "Moyer D, Gao S, Brekelmans R, et al. Invariant Representations without Adversarial",
      "page": 125
    },
    {
      "level": "H1",
      "text": "Training[C]. Advances in Neural Information Processing Systems, 2018.",
      "page": 125
    },
    {
      "level": "H1",
      "text": "[177]",
      "page": 125
    },
    {
      "level": "H1",
      "text": "Liu, Luo P, Wang X, et al. Deep Learning Face Attributes in the Wild[C]. In IEEE",
      "page": 125
    },
    {
      "level": "H1",
      "text": "International Conference on Computer Vision (ICCV), pages 3730–3738, 2015.",
      "page": 125
    },
    {
      "level": "H1",
      "text": "[178]",
      "page": 125
    },
    {
      "level": "H1",
      "text": "Sun Y, Ren L, Wei Z, et al. A weakly supervised method for makeup-invariant face",
      "page": 125
    },
    {
      "level": "H1",
      "text": "verification[J]. Pattern Recognition, 2017, 66:153-159.",
      "page": 125
    },
    {
      "level": "H1",
      "text": "[179]",
      "page": 125
    },
    {
      "level": "H1",
      "text": "Guo G, Wen L, Yan S. Face Authentication With Makeup Changes[J]. IEEE",
      "page": 125
    },
    {
      "level": "H1",
      "text": "Transactions on Circuits & Systems for Video Technology, 2014, 24(5):814-825.",
      "page": 125
    },
    {
      "level": "H1",
      "text": "[180]",
      "page": 125
    },
    {
      "level": "H1",
      "text": "Hu J, Ge Y, Lu J, et al. Makeup-robust face verification[C]. IEEE International",
      "page": 125
    },
    {
      "level": "H1",
      "text": "Conference on Acoustics. 2013.",
      "page": 125
    },
    {
      "level": "H1",
      "text": "[181]",
      "page": 125
    },
    {
      "level": "H1",
      "text": "Li Y, Song L, Wu X, et al. Anti-Makeup: Learning A Bi-Level Adversarial Network",
      "page": 125
    },
    {
      "level": "H1",
      "text": "for Makeup-Invariant Face Verification[C]. Thirty-Second AAAI Conference on",
      "page": 125
    },
    {
      "level": "H1",
      "text": "Artificial Intelligence, 2018.",
      "page": 125
    },
    {
      "level": "H1",
      "text": "[182]",
      "page": 125
    },
    {
      "level": "H1",
      "text": "Guo Y, Zhang L, Hu Y, et al. MS-Celeb-1M: A Dataset and Benchmark for Large-",
      "page": 125
    },
    {
      "level": "H1",
      "text": "Scale Face Recognition[J]. In ECCV, pages 87–102. Springer, 2016.",
      "page": 125
    },
    {
      "level": "H1",
      "text": "[183]",
      "page": 125
    },
    {
      "level": "H1",
      "text": "Zheng Z, Kambhamettu C. Multi-level Feature Learning for Face Recognition under",
      "page": 125
    },
    {
      "level": "H1",
      "text": "Makeup Changes[J]. 2017 12th IEEE International Conference on Automatic Face &",
      "page": 125
    },
    {
      "level": "H1",
      "text": "Gesture Recognition (FG 2017) -. 2017:918-923.",
      "page": 125
    },
    {
      "level": "H1",
      "text": "[184]",
      "page": 125
    },
    {
      "level": "H1",
      "text": "Lu Y, Kumar A, Zhai S, et al. Fully-adaptive Feature Sharing in Multi-Task",
      "page": 125
    },
    {
      "level": "H1",
      "text": "Networks with Applications in Person Attribute Classification[C]. In IEEE Conference",
      "page": 125
    },
    {
      "level": "H1",
      "text": "on Computer Vision and Pattern Recognition, 2017.",
      "page": 125
    },
    {
      "level": "H1",
      "text": "[185]",
      "page": 125
    },
    {
      "level": "H1",
      "text": "Liu Y, Wei F, Shao J, et al. Exploring Disentangled Feature Representation Beyond",
      "page": 125
    },
    {
      "level": "H1",
      "text": "Face Identification[J]. IEEE Conference on Computer Vision and Pattern Recognition,",
      "page": 125
    },
    {
      "level": "H1",
      "text": "2018.",
      "page": 125
    },
    {
      "level": "H1",
      "text": "参考文献",
      "page": 126
    },
    {
      "level": "H1",
      "text": "105",
      "page": 126
    },
    {
      "level": "H1",
      "text": "[186]",
      "page": 126
    },
    {
      "level": "H1",
      "text": "He K, Fu Y, Zhang W, Wang C, Jiang YG, Huang F, Xue X. Harnessing Synthesized",
      "page": 126
    },
    {
      "level": "H1",
      "text": "Abstraction Images to Improve Facial Attribute Recognition[C]. In IJCAI 2018 Jul 13",
      "page": 126
    },
    {
      "level": "H1",
      "text": "(pp. 733-740).",
      "page": 126
    },
    {
      "level": "H1",
      "text": "[187]",
      "page": 126
    },
    {
      "level": "H1",
      "text": "Szegedy C, Ioffe S, Vanhoucke V, et al. Inception-v4, Inception-ResNet and the",
      "page": 126
    },
    {
      "level": "H1",
      "text": "Impact of Residual Connections on Learning[C]. Thirty-First AAAI Conference on",
      "page": 126
    },
    {
      "level": "H1",
      "text": "Artificial Intelligence, 2017.",
      "page": 126
    },
    {
      "level": "H1",
      "text": "[188]",
      "page": 126
    },
    {
      "level": "H1",
      "text": "Kushwaha V, Singh M, Singh R, et al. Disguised Faces in the Wild[C]. 2018 IEEE",
      "page": 126
    },
    {
      "level": "H1",
      "text": "Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), 2018.",
      "page": 126
    },
    {
      "level": "H1",
      "text": "[189]",
      "page": 126
    },
    {
      "level": "H1",
      "text": "Crosswhite N, Byrne J, Stauffer C, et al. Template Adaptation for Face Verification",
      "page": 126
    },
    {
      "level": "H1",
      "text": "and Identification[C]. IEEE International Conference on Automatic Face & Gesture",
      "page": 126
    },
    {
      "level": "H1",
      "text": "Recognition. 2017.",
      "page": 126
    },
    {
      "level": "H1",
      "text": "[190]",
      "page": 126
    },
    {
      "level": "H1",
      "text": "Liu W, Wen Y, Yu Z, et al. SphereFace: Deep Hypersphere Embedding for Face",
      "page": 126
    },
    {
      "level": "H1",
      "text": "Recognition[C]. IEEE Conference on Computer Vision and Pattern Recognition, 2017.",
      "page": 126
    },
    {
      "level": "H1",
      "text": "[191]",
      "page": 126
    },
    {
      "level": "H1",
      "text": "Liu Y, Yan J, Ouyang W. Quality Aware Network for Set to Set Recognition[C].",
      "page": 126
    },
    {
      "level": "H1",
      "text": "IEEE Conference on Computer Vision and Pattern Recognition, 2017.",
      "page": 126
    },
    {
      "level": "H1",
      "text": "[192]",
      "page": 126
    },
    {
      "level": "H1",
      "text": "Chen J C, Ranjan R, Kumar A, et al. An End-to-End System for Unconstrained Face",
      "page": 126
    },
    {
      "level": "H1",
      "text": "Verification with Deep Convolutional Neural Networks[C]. 2015 IEEE International",
      "page": 126
    },
    {
      "level": "H1",
      "text": "Conference on Computer Vision Workshop (ICCVW), 2015.",
      "page": 126
    },
    {
      "level": "H1",
      "text": "[193]",
      "page": 126
    },
    {
      "level": "H1",
      "text": "Yang J, Ren P, Zhang D, et al. Neural Aggregation Network for Video Face",
      "page": 126
    },
    {
      "level": "H1",
      "text": "Recognition[C]. IEEE Conference on Computer Vision and Pattern Recognition",
      "page": 126
    },
    {
      "level": "H1",
      "text": "(CVPR), 2017.",
      "page": 126
    },
    {
      "level": "H1",
      "text": "[194]",
      "page": 126
    },
    {
      "level": "H1",
      "text": "Zhang J, Wang N, Zhang L. Multi-shot Pedestrian Re-identification via Sequential",
      "page": 126
    },
    {
      "level": "H1",
      "text": "Decision Making[J]. arXiv:1712.07257, 2017.",
      "page": 126
    },
    {
      "level": "H1",
      "text": "[195]",
      "page": 126
    },
    {
      "level": "H1",
      "text": "Rao Y, Lu J, Zhou J. Attention-Aware Deep Reinforcement Learning for Video Face",
      "page": 126
    },
    {
      "level": "H1",
      "text": "Recognition[C]. IEEE International Conference on Computer Vision, 2017.",
      "page": 126
    },
    {
      "level": "H1",
      "text": "[196]",
      "page": 126
    },
    {
      "level": "H1",
      "text": "Rao Y, Lu J, Zhou J. Learning Discriminative Aggregation Network for Video-",
      "page": 126
    },
    {
      "level": "H1",
      "text": "Based Face Recognition and Person Re-identification[J]. International Journal of",
      "page": 126
    },
    {
      "level": "H1",
      "text": "Computer Vision, 2018(2).",
      "page": 126
    },
    {
      "level": "H1",
      "text": "[197]",
      "page": 126
    },
    {
      "level": "H1",
      "text": "Mnih V, Kavukcuoglu K, Silver D, et al. Human-level control through deep",
      "page": 126
    },
    {
      "level": "H1",
      "text": "reinforcement learning[J]. Nature, 2015, 518(7540):529-533.",
      "page": 126
    },
    {
      "level": "H1",
      "text": "[198]",
      "page": 126
    },
    {
      "level": "H1",
      "text": "Li Y. Deep Reinforcement Learning: An Overview[J]. arXiv:1701.07274, 2017.",
      "page": 126
    },
    {
      "level": "H1",
      "text": "[199]",
      "page": 126
    },
    {
      "level": "H1",
      "text": "T. P. Lillicrap, J. J. Hunt, A. Pritzel, et al. Continuous control with deep",
      "page": 126
    },
    {
      "level": "H1",
      "text": "reinforcement learning[J]. arXiv preprint arXiv:1509.02971, 2015.",
      "page": 126
    },
    {
      "level": "H1",
      "text": "[200]",
      "page": 126
    },
    {
      "level": "H1",
      "text": "Mnih V, Badia, Adrià Puigdomènech, Mirza M, et al. Asynchronous Methods for",
      "page": 126
    },
    {
      "level": "H1",
      "text": "Deep Reinforcement Learning[C]. In International Conference on Machine Learning,",
      "page": 126
    },
    {
      "level": "H1",
      "text": "2016.",
      "page": 126
    },
    {
      "level": "H1",
      "text": "参考文献",
      "page": 127
    },
    {
      "level": "H1",
      "text": "106",
      "page": 127
    },
    {
      "level": "H1",
      "text": "[201]",
      "page": 127
    },
    {
      "level": "H1",
      "text": "Sutton RS, McAllester DA, Singh SP, et al. Policy gradient methods for",
      "page": 127
    },
    {
      "level": "H1",
      "text": "reinforcement learning with function approximation[C]. In Advances in neural",
      "page": 127
    },
    {
      "level": "H1",
      "text": "information processing systems 2000 (pp. 1057-1063).",
      "page": 127
    },
    {
      "level": "H1",
      "text": "[202]",
      "page": 127
    },
    {
      "level": "H1",
      "text": "Williams R J. Simple statistical gradient-following algorithms for connectionist",
      "page": 127
    },
    {
      "level": "H1",
      "text": "reinforcement learning[J]. Machine Learning, 1992, 8(3-4):229-256.",
      "page": 127
    },
    {
      "level": "H1",
      "text": "[203]",
      "page": 127
    },
    {
      "level": "H1",
      "text": "Schulman J, Levine S, Moritz P, et al. Trust Region Policy Optimization[J].",
      "page": 127
    },
    {
      "level": "H1",
      "text": "Computer Science, 2015:1889-1897.",
      "page": 127
    },
    {
      "level": "H1",
      "text": "[204]",
      "page": 127
    },
    {
      "level": "H1",
      "text": "Wang Z, Bapst V, Heess N, et al. Sample Efficient Actor-Critic with Experience",
      "page": 127
    },
    {
      "level": "H1",
      "text": "Replay[C]. In ICLR, 2016.",
      "page": 127
    },
    {
      "level": "H1",
      "text": "[205]",
      "page": 127
    },
    {
      "level": "H1",
      "text": "Mnih V, Heess N, Graves A, et al. Recurrent Models of Visual Attention[C].",
      "page": 127
    },
    {
      "level": "H1",
      "text": "Advances in neural information processing systems, 2014.",
      "page": 127
    },
    {
      "level": "H1",
      "text": "[206]",
      "page": 127
    },
    {
      "level": "H1",
      "text": "Lan X, Wang H, Gong S, et al. Identity Alignment by Noisy Pixel Removal[J].",
      "page": 127
    },
    {
      "level": "H1",
      "text": "arXiv:1707.02785, 2017.",
      "page": 127
    },
    {
      "level": "H1",
      "text": "[207]",
      "page": 127
    },
    {
      "level": "H1",
      "text": "Huang C, Lucey S, Ramanan D. Learning Policies for Adaptive Tracking with Deep",
      "page": 127
    },
    {
      "level": "H1",
      "text": "Feature Cascades[J]. arXiv:1708.02973, 2017.",
      "page": 127
    },
    {
      "level": "H1",
      "text": "[208]",
      "page": 127
    },
    {
      "level": "H1",
      "text": "Zhou Z, Huang Y, Wang W, et al. See the Forest for the Trees: Joint Spatial and",
      "page": 127
    },
    {
      "level": "H1",
      "text": "Temporal Recurrent Neural Networks for Video-Based Person Re-identification[C].",
      "page": 127
    },
    {
      "level": "H1",
      "text": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.",
      "page": 127
    },
    {
      "level": "H1",
      "text": "[209]",
      "page": 127
    },
    {
      "level": "H1",
      "text": "Tran D, Bourdev L, Fergus R, et al. Learning Spatiotemporal Features with 3D",
      "page": 127
    },
    {
      "level": "H1",
      "text": "Convolutional Networks[J]. In Proceedings of the IEEE international conference on",
      "page": 127
    },
    {
      "level": "H1",
      "text": "computer vision, pages 4489–4497, 2015.",
      "page": 127
    },
    {
      "level": "H1",
      "text": "[210]",
      "page": 127
    },
    {
      "level": "H1",
      "text": "Gao J, Nevatia R. Revisiting Temporal Modeling for Video-based Person ReID[J].",
      "page": 127
    },
    {
      "level": "H1",
      "text": "arXiv:1805.02104, 2018.",
      "page": 127
    },
    {
      "level": "H1",
      "text": "[211]",
      "page": 127
    },
    {
      "level": "H1",
      "text": "Szegedy C, Vanhoucke V, Ioffe S, et al. Rethinking the Inception Architecture for",
      "page": 127
    },
    {
      "level": "H1",
      "text": "Computer Vision[J]. 2016 IEEE Conference on Computer Vision and Pattern",
      "page": 127
    },
    {
      "level": "H1",
      "text": "Recognition (CVPR), 2016.",
      "page": 127
    },
    {
      "level": "H1",
      "text": "[212]",
      "page": 127
    },
    {
      "level": "H1",
      "text": "Arnold B. Reinforcement Learning: An Introduction[J]. IEEE Transactions on",
      "page": 127
    },
    {
      "level": "H1",
      "text": "Neural Networks, 1998, 9(5):1054.",
      "page": 127
    },
    {
      "level": "H1",
      "text": "[213]",
      "page": 127
    },
    {
      "level": "H1",
      "text": "Lin L J. Self-Improving Reactive Agents Based On Reinforcement Learning,",
      "page": 127
    },
    {
      "level": "H1",
      "text": "Planning and Teaching[J]. Machine Learning, 1992, 8(3-4):293-321.",
      "page": 127
    },
    {
      "level": "H1",
      "text": "[214]",
      "page": 127
    },
    {
      "level": "H1",
      "text": "N. Meuleau, L. Peshkin, L. P. Kaelbling, and K.-E. Kim. Off-policy policy search[M].",
      "page": 127
    },
    {
      "level": "H1",
      "text": "In MIT Articical Intelligence Laboratory, 2000.",
      "page": 127
    },
    {
      "level": "H1",
      "text": "[215]",
      "page": 127
    },
    {
      "level": "H1",
      "text": "Precup D, Sutton RS, Dasgupta S. Off-policy temporal-difference learning with",
      "page": 127
    },
    {
      "level": "H1",
      "text": "function approximation[C]. In International Conference on Machine Learning, 2001.",
      "page": 127
    },
    {
      "level": "H1",
      "text": "[216]",
      "page": 127
    },
    {
      "level": "H1",
      "text": "Amari S I. Natural Gradient Works Efficiently in Learning[M]. Unsupervised",
      "page": 127
    },
    {
      "level": "H1",
      "text": "learning. Bradford Company, 1999.",
      "page": 127
    },
    {
      "level": "H1",
      "text": "[217]",
      "page": 127
    },
    {
      "level": "H1",
      "text": "Peters J, Schaal S. Policy Gradient Methods for Robotics[C]. IEEE/RSJ International",
      "page": 127
    },
    {
      "level": "H1",
      "text": "Conference on Intelligent Robots & Systems. 2007.",
      "page": 127
    },
    {
      "level": "H1",
      "text": "参考文献",
      "page": 128
    },
    {
      "level": "H1",
      "text": "107",
      "page": 128
    },
    {
      "level": "H1",
      "text": "[218]",
      "page": 128
    },
    {
      "level": "H1",
      "text": "Liu L, Zhang L, Liu H, et al. Toward Large-Population Face Identification in",
      "page": 128
    },
    {
      "level": "H1",
      "text": "Unconstrained Videos[J]. IEEE Transactions on Circuits and Systems for Video",
      "page": 128
    },
    {
      "level": "H1",
      "text": "Technology, 2014, 24(11):1874-1884.",
      "page": 128
    },
    {
      "level": "H1",
      "text": "[219]",
      "page": 128
    },
    {
      "level": "H1",
      "text": "Yin X, Liu X. Multi-Task Convolutional Neural Network for Pose-Invariant Face",
      "page": 128
    },
    {
      "level": "H1",
      "text": "Recognition[J]. IEEE Transactions on Image Processing, 2017, 27(2):964-975.",
      "page": 128
    },
    {
      "level": "H1",
      "text": "[220]",
      "page": 128
    },
    {
      "level": "H1",
      "text": "Jourabloo A, Liu X. Pose-Invariant Face Alignment via CNN-Based Dense 3D",
      "page": 128
    },
    {
      "level": "H1",
      "text": "Model Fitting[J]. International Journal of Computer Vision, 2017, 124(2):187-203.",
      "page": 128
    },
    {
      "level": "H1",
      "text": "[221]",
      "page": 128
    },
    {
      "level": "H1",
      "text": "Chen D, Ren S, Wei Y, et al. Joint Cascade Face Detection and Alignment[C].",
      "page": 128
    },
    {
      "level": "H1",
      "text": "European Conference on Computer Vision, 2014.",
      "page": 128
    },
    {
      "level": "H1",
      "text": "[222]",
      "page": 128
    },
    {
      "level": "H1",
      "text": "Ren S, Cao X, Wei Y, et al. Face Alignment at 3000 FPS via Regressing Local Binary",
      "page": 128
    },
    {
      "level": "H1",
      "text": "Features[C]. 2014 IEEE Conference on Computer Vision and Pattern Recognition",
      "page": 128
    },
    {
      "level": "H1",
      "text": "(CVPR), 2014.",
      "page": 128
    },
    {
      "level": "H1",
      "text": "[223]",
      "page": 128
    },
    {
      "level": "H1",
      "text": "Roychowdhury A, Lin T Y, Maji S, et al. One-to-many face recognition with bilinear",
      "page": 128
    },
    {
      "level": "H1",
      "text": "CNNs[C]. In WACV, 2016.",
      "page": 128
    },
    {
      "level": "H1",
      "text": "[224]",
      "page": 128
    },
    {
      "level": "H1",
      "text": "Wang D, Otto C, Jain A K. Face Search at Scale[J]. IEEE Transactions on Pattern",
      "page": 128
    },
    {
      "level": "H1",
      "text": "Analysis & Machine Intelligence, 2016.",
      "page": 128
    },
    {
      "level": "H1",
      "text": "[225]",
      "page": 128
    },
    {
      "level": "H1",
      "text": "Masi I, Rawls S, Medioni G, et al. Pose-Aware Face Recognition in the Wild[C].",
      "page": 128
    },
    {
      "level": "H1",
      "text": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEE,",
      "page": 128
    },
    {
      "level": "H1",
      "text": "2016.",
      "page": 128
    },
    {
      "level": "H1",
      "text": "[226]",
      "page": 128
    },
    {
      "level": "H1",
      "text": "Masi I, Tran A T, Leksut J T, et al. Do We Really Need to Collect Millions of Faces",
      "page": 128
    },
    {
      "level": "H1",
      "text": "for Effective Face Recognition?[J]. In ECCV, pages 579–596. Springer, 2016.",
      "page": 128
    },
    {
      "level": "H1",
      "text": "[227]",
      "page": 128
    },
    {
      "level": "H1",
      "text": "Cao Q, Shen L, Xie W, et al. VGGFace2: A dataset for recognising faces across pose",
      "page": 128
    },
    {
      "level": "H1",
      "text": "and age[J]. In Automatic Face & Gesture Recognition, 2018.",
      "page": 128
    },
    {
      "level": "H1",
      "text": "[228]",
      "page": 128
    },
    {
      "level": "H1",
      "text": "Xie W, Zisserman A. Multicolumn Networks for Face Recognition[J].",
      "page": 128
    },
    {
      "level": "H1",
      "text": "arXiv:1807.09192, 2018.",
      "page": 128
    },
    {
      "level": "H1",
      "text": "[229]",
      "page": 128
    },
    {
      "level": "H1",
      "text": "Xie W, Li S, Zisserman A. Comparator Networks[J]. In Proceedings of the European",
      "page": 128
    },
    {
      "level": "H1",
      "text": "Conference on Computer Vision (ECCV), 2018.",
      "page": 128
    },
    {
      "level": "H1",
      "text": "[230]",
      "page": 128
    },
    {
      "level": "H1",
      "text": "Ding C, Tao D. Trunk-Branch Ensemble Convolutional Neural Networks for Video-",
      "page": 128
    },
    {
      "level": "H1",
      "text": "based Face Recognition[J]. IEEE Transactions on Pattern Analysis & Machine",
      "page": 128
    },
    {
      "level": "H1",
      "text": "Intelligence, 2016, PP(99):1-1.",
      "page": 128
    },
    {
      "level": "H1",
      "text": "[231]",
      "page": 128
    },
    {
      "level": "H1",
      "text": "Cevikalp H, Triggs B. Face recognition based on image sets[C]. 2010 IEEE",
      "page": 128
    },
    {
      "level": "H1",
      "text": "Computer Society Conference on Computer Vision and Pattern Recognition. IEEE,",
      "page": 128
    },
    {
      "level": "H1",
      "text": "2010.",
      "page": 128
    },
    {
      "level": "H1",
      "text": "[232]",
      "page": 128
    },
    {
      "level": "H1",
      "text": "Li H, Hua G, Shen X, et al. Eigen-PEP for Video Face Recognition[C]. Asian",
      "page": 128
    },
    {
      "level": "H1",
      "text": "Conference on Computer Vision, 2015.",
      "page": 128
    },
    {
      "level": "H1",
      "text": "108",
      "page": 130
    },
    {
      "level": "H1",
      "text": "首先，我要向我的三位导师表达我的敬意和感谢。本论文是在我硕博连读前",
      "page": 130
    },
    {
      "level": "H1",
      "text": "期阶段导师贾平研究员，博士阶段导师尤佳教授，以及联合培养博士期间导师",
      "page": 130
    },
    {
      "level": "H1",
      "text": "V. K. Vijaya Kumar",
      "page": 130
    },
    {
      "level": "H1",
      "text": "教授的指导下完成的。贾平老师对研究项目的高瞻远瞩，素未",
      "page": 130
    },
    {
      "level": "H1",
      "text": "谋面的尤佳老师无私的支持与鼓励，",
      "page": 130
    },
    {
      "level": "H1",
      "text": "Kumar",
      "page": 130
    },
    {
      "level": "H1",
      "text": "教授渊博的专业知识以及严谨的治学",
      "page": 130
    },
    {
      "level": "H1",
      "text": "态度，不仅培养了我的科研能力，树立了远大的学术目标，他们对所指导学生的",
      "page": 130
    },
    {
      "level": "H1",
      "text": "悉心指导与关怀更是我今后的榜样。",
      "page": 130
    },
    {
      "level": "H1",
      "text": "以师兄相称的孔令胜、刁志辉、闫俊良老师引领我进入研究领域，一年半的",
      "page": 130
    },
    {
      "level": "H1",
      "text": "相处是我选题，解决问题，展示成果等基本科研能力的启蒙。此外，本论文的顺",
      "page": 130
    },
    {
      "level": "H1",
      "text": "利完成离不开我的共同作者们：",
      "page": 130
    },
    {
      "level": "H1",
      "text": "Site Li (CMU), Yang Zou (CMU), Zhiding Yu",
      "page": 130
    },
    {
      "level": "H1",
      "text": "(CMU), Harry Yang (Facebook)",
      "page": 130
    },
    {
      "level": "H1",
      "text": "Prof. C. - C. Jay Kuo (USC), Yuhang Song (USC),",
      "page": 130
    },
    {
      "level": "H1",
      "text": "Prof. Hao Li (USC), Gerry Che (MILA), Zhe Lin (Adobe), Qingming Tang (TTIC),",
      "page": 130
    },
    {
      "level": "H1",
      "text": "Yubin Ge (PITT), Prof. Wendy Xie (Harvard), Prof. Zhenhua Guo (Tsinghua),",
      "page": 130
    },
    {
      "level": "H1",
      "text": "Zhaofeng Li (Oulu), Jun Wang (CIOMP)",
      "page": 130
    },
    {
      "level": "H1",
      "text": "等。能与学识渊博又有耐心的你们合作完",
      "page": 130
    },
    {
      "level": "H1",
      "text": "成项目、克服困难是我的荣幸。",
      "page": 130
    },
    {
      "level": "H1",
      "text": "此外，国家留学基金委的支持让我得以在卡内基梅隆大学和哈佛大学学习交",
      "page": 130
    },
    {
      "level": "H1",
      "text": "流，希望日后能为祖国的飞速发展尽一份力。在此还要感谢我的家人们，是你们",
      "page": 130
    },
    {
      "level": "H1",
      "text": "无私的支持和陪伴让我有信心有勇气直面难题，沉着应对。",
      "page": 130
    },
    {
      "level": "H1",
      "text": "最后，我要向各位在百忙之中参加答辩和评阅论文的专家、教授致以真诚的",
      "page": 130
    },
    {
      "level": "H1",
      "text": "2019",
      "page": 130
    },
    {
      "level": "H1",
      "text": "作者简历及攻读学位期间发表的学术论文与研究成果",
      "page": 132
    },
    {
      "level": "H1",
      "text": "109",
      "page": 132
    },
    {
      "level": "H1",
      "text": "作者简历：",
      "page": 132
    },
    {
      "level": "H1",
      "text": "2010",
      "page": 132
    },
    {
      "level": "H1",
      "text": "2014",
      "page": 132
    },
    {
      "level": "H1",
      "text": "月，在中国科学技术大学信息科学技术学院（自动化",
      "page": 132
    },
    {
      "level": "H1",
      "text": "系）获得工学学士学位。",
      "page": 132
    },
    {
      "level": "H1",
      "text": "2011",
      "page": 132
    },
    {
      "level": "H1",
      "text": "月，在中国科学技术大学人文院（科技传播系）获得文",
      "page": 132
    },
    {
      "level": "H1",
      "text": "学学士学位。",
      "page": 132
    },
    {
      "level": "H1",
      "text": "2019",
      "page": 132
    },
    {
      "level": "H1",
      "text": "月，在中国科学院长春光学精密机械与物理研究所攻",
      "page": 132
    },
    {
      "level": "H1",
      "text": "读博士学位。",
      "page": 132
    },
    {
      "level": "H1",
      "text": "2016",
      "page": 132
    },
    {
      "level": "H1",
      "text": "月，在卡内基梅隆大学工程学院（电子与计算机科学",
      "page": 132
    },
    {
      "level": "H1",
      "text": "系）进行联合培养博士项目。",
      "page": 132
    },
    {
      "level": "H1",
      "text": "月—至今，在哈佛大学担任",
      "page": 132
    },
    {
      "level": "H1",
      "text": "Research Fellow",
      "page": 132
    },
    {
      "level": "H1",
      "text": "获奖情况：",
      "page": 132
    },
    {
      "level": "H1",
      "text": "作为第一作者论文获",
      "page": 132
    },
    {
      "level": "H1",
      "text": "2018",
      "page": 132
    },
    {
      "level": "H1",
      "text": "IEEE Identity, Security and Behavior Analysis (ISBA)",
      "page": 132
    },
    {
      "level": "H1",
      "text": "会议“最佳论文奖”（",
      "page": 132
    },
    {
      "level": "H1",
      "text": "1/238",
      "page": 132
    },
    {
      "level": "H1",
      "text": "篇）。",
      "page": 132
    },
    {
      "level": "H1",
      "text": "年度博士研究生国家奖学金。",
      "page": 132
    },
    {
      "level": "H1",
      "text": "2014-2018",
      "page": 132
    },
    {
      "level": "H1",
      "text": "年度中国科学院大学学业奖学金。",
      "page": 132
    },
    {
      "level": "H1",
      "text": "年度中国科学院大学三好学生。",
      "page": 132
    },
    {
      "level": "H1",
      "text": "工作经历：",
      "page": 132
    },
    {
      "level": "H1",
      "text": "月，在",
      "page": 132
    },
    {
      "level": "H1",
      "text": "Facebook Research",
      "page": 132
    },
    {
      "level": "H1",
      "text": "Research Intern",
      "page": 132
    },
    {
      "level": "H1",
      "text": "Harvard University",
      "page": 132
    },
    {
      "level": "H1",
      "text": "Research Assistant",
      "page": 132
    },
    {
      "level": "H1",
      "text": "月—至今，在",
      "page": 132
    },
    {
      "level": "H1",
      "text": "作者简历及攻读学位期间发表的学术论文与研究成果",
      "page": 133
    },
    {
      "level": "H1",
      "text": "110",
      "page": 133
    },
    {
      "level": "H1",
      "text": "Vijaya",
      "page": 133
    },
    {
      "level": "H1",
      "text": "Kumar.",
      "page": 133
    },
    {
      "level": "H1",
      "text": "Feature-level",
      "page": 133
    },
    {
      "level": "H1",
      "text": "Frankenstein:",
      "page": 133
    },
    {
      "level": "H1",
      "text": "Eliminating",
      "page": 133
    },
    {
      "level": "H1",
      "text": "Variations",
      "page": 133
    },
    {
      "level": "H1",
      "text": "for",
      "page": 133
    },
    {
      "level": "H1",
      "text": "Discriminative Recognition [C]. In Proceedings of the IEEE Conference on",
      "page": 133
    },
    {
      "level": "H1",
      "text": "Computer Vision and Pattern Recognition (",
      "page": 133
    },
    {
      "level": "H1",
      "text": "CVPR",
      "page": 133
    },
    {
      "level": "H1",
      "text": "): 2019",
      "page": 133
    },
    {
      "level": "H1",
      "text": "Xiaofeng Liu, BVK Vijaya Kumar, Ping Jia, Jane You. Hard negative generation for",
      "page": 133
    },
    {
      "level": "H1",
      "text": "identity-disentangled facial expression recognition[J].",
      "page": 133
    },
    {
      "level": "H1",
      "text": "Pattern Recognition",
      "page": 133
    },
    {
      "level": "H1",
      "text": ": 2019,",
      "page": 133
    },
    {
      "level": "H1",
      "text": "1;88:1-2.",
      "page": 133
    },
    {
      "level": "H1",
      "text": "Zhihui Diao, Lingsheng Kong, Junliang Yan, Junda Guo, Xiaofeng Liu, Li Xuan, Lei",
      "page": 133
    },
    {
      "level": "H1",
      "text": "Yu. Electrically tunable holographic waveguide display based on holographic",
      "page": 133
    },
    {
      "level": "H1",
      "text": "polymer dispersed liquid crystal grating[J].",
      "page": 133
    },
    {
      "level": "H1",
      "text": "Chinese Optics Letters",
      "page": 133
    },
    {
      "level": "H1",
      "text": "17 (1), 012301.",
      "page": 133
    },
    {
      "level": "H1",
      "text": "Xiaofeng Liu, B. V. K. Vijaya Kumar, Chao Yang, Qingming Tang, Jane You.",
      "page": 133
    },
    {
      "level": "H1",
      "text": "Dependency-Aware Attention Control for Unconstrained Face Recognition with",
      "page": 133
    },
    {
      "level": "H1",
      "text": "Image Sets[C]. In Proceedings of the European Conference on Computer Vision",
      "page": 133
    },
    {
      "level": "H1",
      "text": "ECCV",
      "page": 133
    },
    {
      "level": "H1",
      "text": "): 2018, 573-590.",
      "page": 133
    },
    {
      "level": "H1",
      "text": "Yuhang Song, Chao Yang, Zhe Lin, Xiaofeng Liu, Qin Huang, Hao Li, C-C Jay Kuo.",
      "page": 133
    },
    {
      "level": "H1",
      "text": "Contextual-based Image Inpainting: Infer, Match, and Translate[C]. In Proceedings",
      "page": 133
    },
    {
      "level": "H1",
      "text": "of the European Conference on Computer Vision (",
      "page": 133
    },
    {
      "level": "H1",
      "text": "): 2018, 3-19.",
      "page": 133
    },
    {
      "level": "H1",
      "text": "Xiaofeng Liu, Yang Zou, Yuhang Song, Chao Yang, Jane You, BVK Vijaya Kumar.",
      "page": 133
    },
    {
      "level": "H1",
      "text": "Ordinal Regression with Neuron Stick-breaking for Medical Diagnosis[C].",
      "page": 133
    },
    {
      "level": "H1",
      "text": "Proceedings of the European Conference on Computer Vision (",
      "page": 133
    },
    {
      "level": "H1",
      "text": "Workshops",
      "page": 133
    },
    {
      "level": "H1",
      "text": "oral presentation",
      "page": 133
    },
    {
      "level": "H1",
      "text": ": 2018",
      "page": 133
    },
    {
      "level": "H1",
      "text": "335-344.",
      "page": 133
    },
    {
      "level": "H1",
      "text": "Xiaofeng Liu, Yang Zou, Lingsheng Kong, Zhihui Diao, Junliang Yan, Jun Wang,",
      "page": 133
    },
    {
      "level": "H1",
      "text": "Site Li, Ping Jia, Jane You.",
      "page": 133
    },
    {
      "level": "H1",
      "text": "Data Augmentation via Latent Space Interpolation for",
      "page": 133
    },
    {
      "level": "H1",
      "text": "Image Classification[C]. In Proceedings of the International Conference on Pattern",
      "page": 133
    },
    {
      "level": "H1",
      "text": "Recognition (",
      "page": 133
    },
    {
      "level": "H1",
      "text": "ICPR",
      "page": 133
    },
    {
      "level": "H1",
      "text": "): 2018.",
      "page": 133
    },
    {
      "level": "H1",
      "text": "Xiaofeng Liu, Zhaofeng Li, Lingsheng Kong, Zhihui Diao, Junliang Yan, Yang Zou,",
      "page": 133
    },
    {
      "level": "H1",
      "text": "Chao Yang, Ping Jia, Jane You. A joint optimization framework of low-dimensional",
      "page": 133
    },
    {
      "level": "H1",
      "text": "projection and collaborative representation for discriminative classification[C]. In",
      "page": 133
    },
    {
      "level": "H1",
      "text": "Proceedings of the International Conference on Pattern Recognition (",
      "page": 133
    },
    {
      "level": "H1",
      "text": "): 2018,",
      "page": 133
    },
    {
      "level": "H1",
      "text": "1493-1498.",
      "page": 133
    },
    {
      "level": "H1",
      "text": "Xiaofeng Liu, Yubin Ge, Chao Yang, Ping Jia. Adaptive metric learning with deep",
      "page": 133
    },
    {
      "level": "H1",
      "text": "neural networks for video-based facial expression recognition[J]. Journal of",
      "page": 133
    },
    {
      "level": "H1",
      "text": "作者简历及攻读学位期间发表的学术论文与研究成果",
      "page": 134
    },
    {
      "level": "H1",
      "text": "111",
      "page": 134
    },
    {
      "level": "H1",
      "text": "Electronic Imaging: 2018, 27(1):013022.",
      "page": 134
    },
    {
      "level": "H1",
      "text": "Junliang Yan, Lingsheng Kong, Zhihui Diao, Xiaofeng Liu, Lilu Zhu, Ping Jia.",
      "page": 134
    },
    {
      "level": "H1",
      "text": "Panoramic stereo imaging system for efficient mosaicking: parallax analyses and",
      "page": 134
    },
    {
      "level": "H1",
      "text": "system design[J].",
      "page": 134
    },
    {
      "level": "H1",
      "text": "Applied optics",
      "page": 134
    },
    {
      "level": "H1",
      "text": ": 2018, 57(3):396-403.",
      "page": 134
    },
    {
      "level": "H1",
      "text": "11*",
      "page": 134
    },
    {
      "level": "H1",
      "text": "Xiaofeng Liu, BVK Vijaya Kumar, Yubin Ge, Chao Yang, Jane You, Ping Jia.",
      "page": 134
    },
    {
      "level": "H1",
      "text": "Normalized face image generation with perceptron generative adversarial",
      "page": 134
    },
    {
      "level": "H1",
      "text": "networks[C]. In Proceedings of the IEEE Identity, Security, and Behavior Analysis",
      "page": 134
    },
    {
      "level": "H1",
      "text": "ISBA",
      "page": 134
    },
    {
      "level": "H1",
      "text": "): 2018, 1-8.",
      "page": 134
    },
    {
      "level": "H1",
      "text": "12*",
      "page": 134
    },
    {
      "level": "H1",
      "text": "Xiaofeng Liu, BVK Vijaya Kumar, Jane You, Ping Jia. Adaptive Deep Metric",
      "page": 134
    },
    {
      "level": "H1",
      "text": "Learning for Identity-Aware Facial Expression Recognition[C]. In Proceedings of",
      "page": 134
    },
    {
      "level": "H1",
      "text": "the IEEE Conference on Computer Vision and Pattern Recognition (",
      "page": 134
    },
    {
      "level": "H1",
      "text": "CVPR",
      "page": 134
    },
    {
      "level": "H1",
      "text": "Workshops 20min oral presentation",
      "page": 134
    },
    {
      "level": "H1",
      "text": ": 2017, 522-531.",
      "page": 134
    },
    {
      "level": "H1",
      "text": "13*",
      "page": 134
    },
    {
      "level": "H1",
      "text": "Xiaofeng Liu, Lingsheng Kong, Zhihui Diao, Ping Jia.",
      "page": 134
    },
    {
      "level": "H1",
      "text": "Line-scan system for",
      "page": 134
    },
    {
      "level": "H1",
      "text": "continuous hand authentication[J].",
      "page": 134
    },
    {
      "level": "H1",
      "text": "Optical Engineering",
      "page": 134
    },
    {
      "level": "H1",
      "text": ": 2017, 56(3):033106.",
      "page": 134
    },
    {
      "level": "H1",
      "text": "申请或已获得的专利：",
      "page": 134
    },
    {
      "level": "H1",
      "text": "孔令胜",
      "page": 134
    },
    {
      "level": "H1",
      "text": "刘小沣",
      "page": 134
    },
    {
      "level": "H1",
      "text": "刁志辉",
      "page": 134
    },
    {
      "level": "H1",
      "text": "闫俊良",
      "page": 134
    },
    {
      "level": "H1",
      "text": "一种确定图像采集设备最优排布的方",
      "page": 134
    },
    {
      "level": "H1",
      "text": "法及系统",
      "page": 134
    },
    {
      "level": "H1",
      "text": ". 201610394014.5.",
      "page": 134
    },
    {
      "level": "H1",
      "text": "已授权：",
      "page": 134
    },
    {
      "level": "H1",
      "text": "2019.03.11",
      "page": 134
    },
    {
      "level": "H1",
      "text": "一种人脸配准方法及装置",
      "page": 134
    },
    {
      "level": "H1",
      "text": "201610344806.1.",
      "page": 134
    },
    {
      "level": "H1",
      "text": "2019.02.13",
      "page": 134
    },
    {
      "level": "H1",
      "text": "一种三维姿态识别方法及系统",
      "page": 134
    },
    {
      "level": "H1",
      "text": "CN106056089A.",
      "page": 134
    },
    {
      "level": "H1",
      "text": "申请日：",
      "page": 134
    },
    {
      "level": "H1",
      "text": "2016.06.06",
      "page": 134
    },
    {
      "level": "H1",
      "text": "参加的研究项目及获奖情况：",
      "page": 134
    },
    {
      "level": "H1",
      "text": "国家留学基金资助项目（",
      "page": 134
    },
    {
      "level": "H1",
      "text": "201704910715",
      "page": 134
    },
    {
      "level": "H1",
      "text": "国家重点研发计划（",
      "page": 134
    },
    {
      "level": "H1",
      "text": "2016YFB0501003)",
      "page": 134
    },
    {
      "level": "H1",
      "text": "国家自然科学基金资助项目（",
      "page": 134
    },
    {
      "level": "H1",
      "text": "61308099, 61304032,61675202",
      "page": 134
    },
    {
      "level": "H1",
      "text": "国家自然科学基金重大科研仪器研制项目（",
      "page": 134
    },
    {
      "level": "H1",
      "text": "61627819,61727818",
      "page": 134
    },
    {
      "level": "H1",
      "text": "Hong Kong Government General Research Fund",
      "page": 134
    },
    {
      "level": "H1",
      "text": "GRF 152202/14E",
      "page": 134
    },
    {
      "level": "H1",
      "text": "Hong Kong PolyU Central Research Grant",
      "page": 134
    },
    {
      "level": "H1",
      "text": "G-YBJW",
      "page": 134
    },
    {
      "level": "H1",
      "text": "作者简历及攻读学位期间发表的学术论文与研究成果",
      "page": 135
    },
    {
      "level": "H1",
      "text": "112",
      "page": 135
    },
    {
      "level": "H1",
      "text": "中国科学院青促会（",
      "page": 135
    },
    {
      "level": "H1",
      "text": "2017264",
      "page": 135
    },
    {
      "level": "H1",
      "text": "中科院长春光机所创新基金（",
      "page": 135
    },
    {
      "level": "H1",
      "text": "Y586320150",
      "page": 135
    },
    {
      "level": "H1",
      "text": "中国科学院基金（",
      "page": 135
    },
    {
      "level": "H1",
      "text": "CXJJ-16S038,CXJJ-17S017",
      "page": 135
    },
    {
      "level": "H1",
      "text": "吉林省重大科技攻关专项（",
      "page": 135
    },
    {
      "level": "H1",
      "text": "11ZDGG001",
      "page": 135
    },
    {
      "level": "H1",
      "text": "General Motors-Carnegie Mellon Autonomous Driving Collaborative Research",
      "page": 135
    },
    {
      "level": "H1",
      "text": "参与“长春光机所高性能航空光电成像与制造技术”项目，获",
      "page": 135
    },
    {
      "level": "H1",
      "text": "2018",
      "page": 135
    },
    {
      "level": "H1",
      "text": "年国家科学技",
      "page": 135
    },
    {
      "level": "H1",
      "text": "术进步一等奖。",
      "page": 135
    },
    {
      "level": "H1",
      "text": "View publication stats",
      "page": 135
    }
  ]
}